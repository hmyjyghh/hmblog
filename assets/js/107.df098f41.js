(window.webpackJsonp=window.webpackJsonp||[]).push([[107],{552:function(t,s,a){"use strict";a.r(s);var _=a(3),r=Object(_.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"具体痛点问题总结"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#具体痛点问题总结"}},[t._v("#")]),t._v(" 具体痛点问题总结")]),t._v(" "),s("h3",{attrs:{id:"_1-index-process-文本向量化构建索引的过程"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-index-process-文本向量化构建索引的过程"}},[t._v("#")]),t._v(" 1. Index Process（⽂本向量化构建索引的过程）")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("MIssing Content(内容缺失)")]),t._v(": 原本的⽂本中就没有问题的答案")]),t._v(" "),s("li",[s("strong",[t._v("⽂档加载准确性和效率")]),t._v("： ⽐如pdf⽂件的加载，如何提取其中的有⽤⽂字信息和图⽚信息等")]),t._v(" "),s("li",[s("strong",[t._v("⽂档切分的粒度")]),t._v("： ⽂本切分的⼤⼩和位置会影响后⾯检索出来的上下⽂完整性和与⼤模型交互的token数量，怎么控制好⽂档切分的度，是个难题。")])]),t._v(" "),s("h3",{attrs:{id:"_2-query-process-检索增强回答的过程中"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-query-process-检索增强回答的过程中"}},[t._v("#")]),t._v(" 2. Query Process（检索增强回答的过程中）")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("Missed Top Ranked")]),t._v(": 错过排名靠前的⽂档")]),t._v(" "),s("li",[s("strong",[t._v("Not in Context")]),t._v(": 提取上下⽂与答案⽆关")]),t._v(" "),s("li",[s("strong",[t._v("Wrong Format(格式错误)")]),t._v(": 例如需要Json，给了字符串")]),t._v(" "),s("li",[s("strong",[t._v("Incomplete(答案不完整)")]),t._v(": 答案只回答了问题的⼀部分")]),t._v(" "),s("li",[s("strong",[t._v("Not Extracted(未提取到答案)")]),t._v(": 提取的上下⽂中有答案，但⼤模型没有提取出来")]),t._v(" "),s("li",[s("strong",[t._v("Incorrect Specificity")]),t._v(": 答案不够具体或过于具体")])]),t._v(" "),s("h2",{attrs:{id:"痛点问题策略分析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#痛点问题策略分析"}},[t._v("#")]),t._v(" 痛点问题策略分析")]),t._v(" "),s("h3",{attrs:{id:"_1-文档加载准确性和效率"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-文档加载准确性和效率"}},[t._v("#")]),t._v(" 1. ⽂档加载准确性和效率")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("优化⽂档读取器")])])]),t._v(" "),s("div",{staticClass:"language-Text extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("⼀般知识库中的⽂档格式都不尽相同，HTML、PDF、MarkDown、TXT、CSV等。每种格式⽂档都有其都有的数据组织⽅式。\n怎么在读取这些数据时将⼲扰项去除（如⼀些特殊符号等），同时还保留原⽂本之间的关联关系（如csv⽂件保留其原有的表格结构），是主要的优化⽅向。 \n⽬前针对这⽅⾯的探索为：针对每⼀类⽂档，涉及⼀个专⻔的读取器。\n如LangChain中提供的WebBaseLoader专⻔⽤来加载HTML⽂本等。\n")])])]),s("ul",[s("li",[t._v("数据清洗与增强")])]),t._v(" "),s("p",[s("strong",[t._v("任何RAG⼯作流程想要获得优良表现，都必须先清洗数据。")])]),t._v(" "),s("div",{staticClass:"language-Text extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("如果你的源数据质量低劣，⽐如包含互相冲突的信息，那不管你的 RAG ⼯作构建得多么好，它都不可能\n⽤你输⼊的垃圾神奇地输出⾼质量结果。这个解决⽅案不仅适⽤于这个痛点，任何RAG⼯作流程想要获得优良表现，都必须先清洗数据。\n")])])]),s("h3",{attrs:{id:"_2-文档切分的粒度"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-文档切分的粒度"}},[t._v("#")]),t._v(" 2. ⽂档切分的粒度")]),t._v(" "),s("p",[s("strong",[t._v("粒度太⼤可能导致检索到的⽂本包含太多不相关的信息，降低检索准确性，粒度太⼩可能导致信息不全⾯，导致答案的⽚⾯性。问题的答案可能跨越两个甚⾄多个⽚段")])]),t._v(" "),s("ul",[s("li",[t._v("固定⻓度的分块：直接设定块中的字数，每个⽂本块有多少字。")]),t._v(" "),s("li",[t._v("内容重叠分块：在固定⼤⼩分块的基础上，为了保持⽂本块之间语义上下⽂的连贯性，在分块时，保持⽂本块之间有⼀定的内容重叠。")]),t._v(" "),s("li",[t._v("基于结构的分块：基于结构的分块⽅法利⽤⽂档的固有结构，如HTML或Markdown中的标题和段落，以保持内容的逻辑性和完整性。")]),t._v(" "),s("li",[t._v("基于递归的分块：")])]),t._v(" "),s("div",{staticClass:"language-Text extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("重复的利⽤分块规则不断细分⽂本块。在langchain中会先通过段落换⾏符（\\n\\n）进⾏分割。然后，检查这些块的⼤⼩。\n如果⼤⼩不超过⼀定阈值，则该块被保留。\n对于⼤⼩超过标准的块，使⽤单换⾏符（\\n）再次分割。\n以此类推，不断根据块⼤⼩更新更⼩的分块规则（如空格，句号）。\n")])])]),s("ul",[s("li",[t._v("分块⼤⼩的选择：")])]),t._v(" "),s("div",{staticClass:"language-Text extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("1. 不同的嵌⼊模型有其最佳输⼊⼤⼩。⽐如Openai的text-embedding-ada-002的模型在256 或 512⼤⼩的块上效果更好。\n\n2. ⽂档的类型和⽤户查询的⻓度及复杂性也是决定分块⼤⼩的重要因素。处理⻓篇⽂章或书籍时，\n较⼤的分块有助于保留更多的上下⽂和主题连贯性；\n⽽对于社交媒体帖⼦，较⼩的分块可能更适合捕捉每个帖⼦的精确语义。\n如果⽤户的查询通常是简短和具体的，较⼩的分块可能更为合适；\n相反，如果查询较为复杂，可能需要更⼤的分块。\n")])])]),s("h3",{attrs:{id:"_3-内容缺失"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-内容缺失"}},[t._v("#")]),t._v(" 3. 内容缺失")]),t._v(" "),s("p",[s("strong",[t._v("准备的外挂⽂本中没有回答问题所需的知识。这时候，RAG可能会提供⼀个⾃⼰编造的答案。")])]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("增加相应知识库")]),t._v("：将相应的知识⽂本加⼊到向量知识库中。")]),t._v(" "),s("li",[s("strong",[t._v("数据清洗与增强")]),t._v("：输⼊垃圾，那也必定输出垃圾。如果你的源数据质量低劣，⽐如包含互相冲突的信息，那不管你的 RAG ⼯作构建得多么好，它都不可能⽤你输⼊的垃圾神奇地输出⾼质量结果。\n"),s("ul",[s("li",[t._v("这个解决⽅案不仅适⽤于这个痛点，任何RAG⼯作流程想要获得优良表现，都必须先清洁数据。")])])]),t._v(" "),s("li",[s("strong",[t._v("更好的Prompt设计")]),t._v("：通过Prompts，让⼤模型在找不到答案的情况下，输出“根据当前知识库，⽆法回答该问题”等提示。这样的提示，就能⿎励模型承认⾃⼰的局限，并更透明地向⽤户传达它的不确定。\n"),s("ul",[s("li",[t._v("虽然不能保证 100% 准确度，但在清洗数据之后，精⼼设计 prompt 是最好的做法之⼀。")])])])]),t._v(" "),s("h3",{attrs:{id:"_4-错过排名靠前的文档"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-错过排名靠前的文档"}},[t._v("#")]),t._v(" 4. 错过排名靠前的⽂档")]),t._v(" "),s("p",[s("strong",[t._v("外挂知识库中存在回答问题所需的知识，但是可能这个知识块与问题的向量相似度排名并不是靠前的，导致⽆法召回该知识块传给⼤模型，导致⼤模型始终⽆法得到正确的答案")])]),t._v(" "),s("ul",[s("li",[t._v("增加召回数量：增加召回的 topK 数量，也就是说，例如原来召回前3个知识块，修改为召回前5个知识块。不推荐此种⽅法，因为知识块多了，不光会增加token消耗，也会增加⼤模型回答问题的⼲扰。")]),t._v(" "),s("li",[t._v("重排（Reranking）：该⽅法的步骤是，⾸先检索出 topN 个知识块（N > K，过召回），然后再对这 topN 个知识块进⾏重排序，取重排序后的 K 个知识块当作上下⽂。\n"),s("ul",[s("li",[t._v("重排是利⽤另⼀个排序模型或排序策略，对知识块和问题之间进⾏关系计算与排序。")])])])]),t._v(" "),s("h3",{attrs:{id:"_5-提取上下文与答案无关"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5-提取上下文与答案无关"}},[t._v("#")]),t._v(" 5. 提取上下⽂与答案⽆关")]),t._v(" "),s("p",[t._v("详见 内容缺失或 错过排名靠前的⽂档的具体体现")])])}),[],!1,null,null,null);s.default=r.exports}}]);