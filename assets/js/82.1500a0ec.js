(window.webpackJsonp=window.webpackJsonp||[]).push([[82],{527:function(t,s,a){"use strict";a.r(s);var n=a(3),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("p",[s("code",[t._v("BM25Retriever")]),t._v(" 是 LangChain 社区提供的基于 "),s("strong",[t._v("BM25 算法")]),t._v(" 的检索器，适用于无向量依赖的文本匹配场景（无需嵌入模型），核心是通过词频、文档长度等统计特征计算文本相似度，快速召回相关文档。")]),t._v(" "),s("h2",{attrs:{id:"bm25retriever"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#bm25retriever"}},[t._v("#")]),t._v(" BM25Retriever")]),t._v(" "),s("h3",{attrs:{id:"一、安装依赖"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#一、安装依赖"}},[t._v("#")]),t._v(" 一、安装依赖")]),t._v(" "),s("p",[t._v("首先确保安装 "),s("code",[t._v("langchain-community")]),t._v("（"),s("code",[t._v("BM25Retriever")]),t._v(" 所在包），若需处理中文可额外安装分词库（如 "),s("code",[t._v("jieba")]),t._v("）：")]),t._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[t._v("pip "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("install")]),t._v(" langchain-community  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 核心依赖")]),t._v("\npip "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("install")]),t._v(" jieba  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 中文分词（可选，默认英文分词）")]),t._v("\n")])])]),s("h3",{attrs:{id:"二、核心概念"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#二、核心概念"}},[t._v("#")]),t._v(" 二、核心概念")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("BM25 算法")]),t._v("：一种经典的信息检索排序算法，优化了 TF-IDF 对长文档的惩罚问题，通过 "),s("code",[t._v("k1")]),t._v("（词频饱和度）、"),s("code",[t._v("b")]),t._v("（文档长度归一化系数）等参数调节匹配效果。")]),t._v(" "),s("li",[s("strong",[t._v("文档格式")]),t._v("：输入需为 "),s("code",[t._v("List[Document]")]),t._v("（LangChain 的文档类，包含 "),s("code",[t._v("page_content")]),t._v(" 文本内容和 "),s("code",[t._v("metadata")]),t._v(" 元数据）。")]),t._v(" "),s("li",[s("strong",[t._v("分词逻辑")]),t._v("：默认使用英文分词（按空格分割），中文需自定义分词函数。")])]),t._v(" "),s("h3",{attrs:{id:"三、基础用法-英文场景"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#三、基础用法-英文场景"}},[t._v("#")]),t._v(" 三、基础用法（英文场景）")]),t._v(" "),s("h4",{attrs:{id:"步骤-1-导入依赖-准备文档"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#步骤-1-导入依赖-准备文档"}},[t._v("#")]),t._v(" 步骤 1：导入依赖 & 准备文档")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain_community"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("retrievers "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" BM25Retriever\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain_core"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("documents "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Document\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1. 准备文档（List[Document] 格式，必须包含 page_content）")]),t._v("\ndocuments "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    Document"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        page_content"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"LangChain is a framework for building LLM applications"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        metadata"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"source"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"langchain-docs"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    Document"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        page_content"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"BM25Retriever is a statistical retriever in LangChain"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        metadata"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"source"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"langchain-retrievers"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    Document"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        page_content"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"LLMs are powerful language models like GPT-4"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        metadata"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"source"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"llm-intro"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    Document"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        page_content"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"LangChain supports various retrievers: BM25, VectorStore, etc."')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        metadata"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"source"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"langchain-features"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])])]),s("h4",{attrs:{id:"步骤-2-初始化-bm25retriever-并添加文档"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#步骤-2-初始化-bm25retriever-并添加文档"}},[t._v("#")]),t._v(" 步骤 2：初始化 BM25Retriever 并添加文档")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2. 初始化检索器（默认英文分词）")]),t._v("\nretriever "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BM25Retriever"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_documents"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("documents"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 或分步初始化（先创建实例，再添加文档）")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# retriever = BM25Retriever()")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# retriever.add_documents(documents)")]),t._v("\n")])])]),s("h4",{attrs:{id:"步骤-3-检索相关文档"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#步骤-3-检索相关文档"}},[t._v("#")]),t._v(" 步骤 3：检索相关文档")]),t._v(" "),s("p",[t._v("使用 "),s("code",[t._v("get_relevant_documents(query)")]),t._v(" 方法，返回按相似度排序的文档列表：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3. 检索查询")]),t._v("\nquery "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"What retrievers does LangChain support?"')]),t._v("\nrelevant_docs "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" retriever"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_relevant_documents"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("query"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 4. 打印结果")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" doc "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("enumerate")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("relevant_docs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"\\n=== 相关文档 ')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v(' ==="')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"文本内容：')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("doc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("page_content"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"元数据：')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("doc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("metadata"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[s("strong",[t._v("输出示例")]),t._v("（按相似度降序）：")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("=== 相关文档 1 ===\n文本内容：LangChain supports various retrievers: BM25, VectorStore, etc.\n元数据：{'source': 'langchain-features'}\n\n=== 相关文档 2 ===\n文本内容：BM25Retriever is a statistical retriever in LangChain\n元数据：{'source': 'langchain-retrievers'}\n\n=== 相关文档 3 ===\n文本内容：LangChain is a framework for building LLM applications\n元数据：{'source': 'langchain-docs'}\n")])])]),s("h3",{attrs:{id:"四、中文场景适配-自定义分词"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#四、中文场景适配-自定义分词"}},[t._v("#")]),t._v(" 四、中文场景适配（自定义分词）")]),t._v(" "),s("p",[t._v("BM25Retriever 默认按空格分词，中文需替换为中文分词函数（如 "),s("code",[t._v("jieba")]),t._v("），通过 "),s("code",[t._v("preprocess_func")]),t._v(" 参数配置：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" jieba\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain_community"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("retrievers "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" BM25Retriever\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain_core"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("documents "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Document\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1. 中文文档")]),t._v("\nchinese_docs "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    Document"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("page_content"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"LangChain 是一个用于构建大语言模型应用的框架"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" metadata"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"来源"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"LangChain 官方文档"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    Document"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("page_content"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"BM25Retriever 是 LangChain 中的统计型检索器，无需嵌入模型"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" metadata"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"来源"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"LangChain 社区"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    Document"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("page_content"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"大语言模型（LLM）如 GPT-4、文心一言，具备强大的文本生成能力"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" metadata"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"来源"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"AI 百科"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    Document"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("page_content"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"LangChain 支持多种检索器：BM25、向量数据库检索器等"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" metadata"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"来源"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"LangChain 特性文档"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2. 定义中文分词函数（输入字符串，返回分词列表）")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("chinese_tokenizer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("text"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("jieba"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cut"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("text"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# jieba 分词，返回列表")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3. 初始化检索器（指定 preprocess_func 为中文分词）")]),t._v("\nchinese_retriever "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BM25Retriever"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_documents"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    chinese_docs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    preprocess_func"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("chinese_tokenizer  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 关键：替换分词逻辑")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 4. 中文查询检索")]),t._v("\nquery "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"LangChain 支持哪些检索器？"')]),t._v("\nrelevant_docs "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" chinese_retriever"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_relevant_documents"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("query"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 打印结果")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" doc "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("enumerate")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("relevant_docs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"\\n=== 相关文档 ')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v(' ==="')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"文本内容：')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("doc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("page_content"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"元数据：')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("doc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("metadata"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"五、核心参数配置-优化检索效果"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#五、核心参数配置-优化检索效果"}},[t._v("#")]),t._v(" 五、核心参数配置（优化检索效果）")]),t._v(" "),s("p",[s("code",[t._v("BM25Retriever")]),t._v(" 的初始化参数可调节匹配逻辑，核心参数如下：")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[t._v("参数名")]),t._v(" "),s("th",[t._v("作用说明")]),t._v(" "),s("th",[t._v("默认值")]),t._v(" "),s("th",[t._v("推荐范围")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[s("code",[t._v("k1")])]),t._v(" "),s("td",[t._v("词频饱和度系数（控制词频对相似度的影响，越大词频权重越高）")]),t._v(" "),s("td",[t._v("1.5")]),t._v(" "),s("td",[t._v("1.0 ~ 2.0")])]),t._v(" "),s("tr",[s("td",[s("code",[t._v("b")])]),t._v(" "),s("td",[t._v("文档长度归一化系数（控制文档长度对相似度的惩罚，b=0不惩罚，b=1最大惩罚）")]),t._v(" "),s("td",[t._v("0.75")]),t._v(" "),s("td",[t._v("0.5 ~ 0.8")])]),t._v(" "),s("tr",[s("td",[s("code",[t._v("epsilon")])]),t._v(" "),s("td",[t._v("平滑参数（避免零概率）")]),t._v(" "),s("td",[t._v("0.25")]),t._v(" "),s("td",[t._v("0.1 ~ 0.5")])]),t._v(" "),s("tr",[s("td",[s("code",[t._v("preprocess_func")])]),t._v(" "),s("td",[t._v("分词函数（输入文本字符串，返回分词列表）")]),t._v(" "),s("td",[t._v("英文分词")]),t._v(" "),s("td",[t._v("自定义中文分词")])]),t._v(" "),s("tr",[s("td",[s("code",[t._v("max_documents")])]),t._v(" "),s("td",[t._v("每次检索返回的最大文档数")]),t._v(" "),s("td",[t._v("4")]),t._v(" "),s("td",[t._v("根据需求调整")])])])]),t._v(" "),s("h4",{attrs:{id:"示例-调节参数优化效果"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#示例-调节参数优化效果"}},[t._v("#")]),t._v(" 示例：调节参数优化效果")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 初始化时指定参数")]),t._v("\nretriever "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BM25Retriever"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    k1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 降低词频权重，避免过度依赖高频词")]),t._v("\n    b"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.6")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 减轻文档长度惩罚")]),t._v("\n    epsilon"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    preprocess_func"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("chinese_tokenizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    max_documents"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 最多返回5篇相关文档")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nretriever"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_documents"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("chinese_docs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 手动添加文档")]),t._v("\n")])])]),s("h3",{attrs:{id:"六、进阶用法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#六、进阶用法"}},[t._v("#")]),t._v(" 六、进阶用法")]),t._v(" "),s("h4",{attrs:{id:"_1-动态添加-删除文档"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-动态添加-删除文档"}},[t._v("#")]),t._v(" 1. 动态添加/删除文档")]),t._v(" "),s("p",[t._v("支持后续补充文档或清空文档库：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 添加新文档")]),t._v("\nnew_doc "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Document"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("page_content"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"LangChain 还支持自定义检索器扩展"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" metadata"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"来源"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"扩展文档"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nretriever"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_documents"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("new_doc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 接收 List[Document]")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 清空所有文档")]),t._v("\nretriever"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("clear"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h4",{attrs:{id:"_2-结合-langchain-管道-chain-使用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-结合-langchain-管道-chain-使用"}},[t._v("#")]),t._v(" 2. 结合 LangChain 管道（Chain）使用")]),t._v(" "),s("p",[t._v("可与 "),s("code",[t._v("RetrievalQA")]),t._v(" 等链结合，快速搭建问答系统：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("chains "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" RetrievalQA\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain_community"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("llms "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" OpenAI  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 或其他LLM（如本地化模型）")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1. 初始化LLM（示例用OpenAI，可替换为本地化模型如通义千问）")]),t._v("\nllm "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" OpenAI"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("api_key"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"your-api-key"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2. 构建问答链")]),t._v("\nqa_chain "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RetrievalQA"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_chain_type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    llm"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("llm"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    chain_type"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"stuff"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 直接将文档内容传入LLM")]),t._v("\n    retriever"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("retriever"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 关联BM25Retriever")]),t._v("\n    return_source_documents"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 返回检索到的原始文档")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3. 提问")]),t._v("\nresult "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" qa_chain"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("invoke"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"LangChain 支持哪些检索器？"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"回答："')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"result"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"来源文档："')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("doc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("page_content "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" doc "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"source_documents"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h4",{attrs:{id:"_3-批量检索与相似度分数"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-批量检索与相似度分数"}},[t._v("#")]),t._v(" 3. 批量检索与相似度分数")]),t._v(" "),s("p",[t._v("默认 "),s("code",[t._v("get_relevant_documents")]),t._v(" 仅返回文档，若需获取相似度分数，可通过 "),s("code",[t._v("similarity_search_with_score")]),t._v(" 方法：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 批量检索（支持多个查询）")]),t._v("\nqueries "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"LangChain 框架"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"大语言模型应用"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" q "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" queries"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    docs_with_scores "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" retriever"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("similarity_search_with_score"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("q"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# k=返回Top2")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"\\n查询：')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("q"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" doc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" score "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" docs_with_scores"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"  文档：')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("doc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("page_content"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("，相似度分数：")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("score"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token format-spec"}},[t._v(".4f")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"七、适用场景与注意事项"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#七、适用场景与注意事项"}},[t._v("#")]),t._v(" 七、适用场景与注意事项")]),t._v(" "),s("h4",{attrs:{id:"适用场景"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#适用场景"}},[t._v("#")]),t._v(" 适用场景")]),t._v(" "),s("ul",[s("li",[t._v("无嵌入模型（如 BERT）时的快速检索；")]),t._v(" "),s("li",[t._v("英文/中文短文本匹配（文档长度不宜过长，建议单文档≤500字）；")]),t._v(" "),s("li",[t._v("对检索速度要求高，无需复杂语义理解的场景。")])]),t._v(" "),s("h4",{attrs:{id:"注意事项"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#注意事项"}},[t._v("#")]),t._v(" 注意事项")]),t._v(" "),s("ul",[s("li",[t._v("不支持语义理解：仅基于词频、字面匹配，无法处理同义词（如“检索器”和“搜索工具”视为不同词）；")]),t._v(" "),s("li",[t._v("长文档效果差：文档过长会导致词频分散，建议先拆分长文档为短片段；")]),t._v(" "),s("li",[t._v("中文需分词：必须自定义中文分词函数（如 jieba、THULAC），否则按单个汉字分词，效果极差。")])]),t._v(" "),s("h3",{attrs:{id:"八、常见问题排查"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#八、常见问题排查"}},[t._v("#")]),t._v(" 八、常见问题排查")]),t._v(" "),s("ol",[s("li",[s("p",[s("strong",[t._v("中文检索无结果/效果差")]),t._v("：")]),t._v(" "),s("ul",[s("li",[t._v("检查是否配置了 "),s("code",[t._v("preprocess_func")]),t._v(" 中文分词；")]),t._v(" "),s("li",[t._v("确认分词函数返回的是列表（如 "),s("code",[t._v("list(jieba.cut(text))")]),t._v("），而非字符串。")])])]),t._v(" "),s("li",[s("p",[s("strong",[t._v("检索返回文档数不足")]),t._v("：")]),t._v(" "),s("ul",[s("li",[t._v("调整 "),s("code",[t._v("max_documents")]),t._v(" 参数（默认4）；")]),t._v(" "),s("li",[t._v("检查文档总数是否少于 "),s("code",[t._v("k")]),t._v("（"),s("code",[t._v("similarity_search_with_score")]),t._v(" 的 "),s("code",[t._v("k")]),t._v(" 参数）。")])])]),t._v(" "),s("li",[s("p",[s("strong",[t._v("词频过高的词影响结果")]),t._v("：")]),t._v(" "),s("ul",[s("li",[t._v("降低 "),s("code",[t._v("k1")]),t._v(" 参数（如从1.5调整为1.0）；")]),t._v(" "),s("li",[t._v("预处理文档，过滤停用词（如“的、是、在”等无意义词）。")])])])]),t._v(" "),s("p",[t._v("通过以上用法，可快速上手 "),s("code",[t._v("BM25Retriever")]),t._v(" "),s("strong",[t._v("并适配中英文场景")]),t._v("，根据实际需求调节参数优化检索效果。")])])}),[],!1,null,null,null);s.default=e.exports}}]);