(window.webpackJsonp=window.webpackJsonp||[]).push([[46],{532:function(t,s,a){"use strict";a.r(s);var n=a(3),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"lora-微调"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#lora-微调"}},[t._v("#")]),t._v(" LoRA 微调")]),t._v(" "),s("h3",{attrs:{id:"训练参数详解"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#训练参数详解"}},[t._v("#")]),t._v(" 训练参数详解")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[t._v("args "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" TrainingArguments"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  output_dir"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"./output/llama3_1_instruct_lora"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  per_device_train_batch_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  gradient_accumulation_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  logging_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  num_train_epochs"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  save_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 为了快速演示，这里设置10，建议你设置成100")]),t._v("\n  learning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e-4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  save_on_each_node"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  gradient_checkpointing"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("当然可以！这些参数是使用 Hugging Face 的 "),s("code",[t._v("Transformers")]),t._v(" 库进行模型训练（尤其是 LoRA 微调）时的核心配置。下面我将为你详细解释每一个参数的作用和意义。")]),t._v(" "),s("hr"),t._v(" "),s("h3",{attrs:{id:"_1-output-dir-output-llama3-1-instruct-lora"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-output-dir-output-llama3-1-instruct-lora"}},[t._v("#")]),t._v(" 1. "),s("code",[t._v('output_dir="./output/llama3_1_instruct_lora"')])]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("作用")]),t._v("：指定训练过程中所有输出文件的保存目录。")]),t._v(" "),s("li",[s("strong",[t._v("详细解释")]),t._v("：\n"),s("ul",[s("li",[t._v("这里设置的路径是 "),s("code",[t._v("./output/llama3_1_instruct_lora")]),t._v("，意味着在当前工作目录下创建一个名为 "),s("code",[t._v("output")]),t._v(" 的文件夹，并在其中再创建一个 "),s("code",[t._v("llama3_1_instruct_lora")]),t._v(" 子文件夹。")]),t._v(" "),s("li",[t._v("这个目录将会保存：\n"),s("ul",[s("li",[s("strong",[t._v("模型检查点")]),t._v("：在 "),s("code",[t._v("save_steps")]),t._v(" 或每个 epoch 结束时保存的模型权重。")]),t._v(" "),s("li",[s("strong",[t._v("训练日志")]),t._v("：包含损失、学习率等信息的日志文件。")]),t._v(" "),s("li",[s("strong",[t._v("训练器状态")]),t._v("：如优化器状态、当前的训练步数等，用于中断后恢复训练。")]),t._v(" "),s("li",[s("strong",[t._v("最终模型")]),t._v("：训练完成后的最终模型文件。")])])])])])]),t._v(" "),s("h3",{attrs:{id:"_2-per-device-train-batch-size-4"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-per-device-train-batch-size-4"}},[t._v("#")]),t._v(" 2. "),s("code",[t._v("per_device_train_batch_size=4")])]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("作用")]),t._v("：指定"),s("strong",[t._v("每个 GPU/CPU 上")]),t._v("的训练批次大小。")]),t._v(" "),s("li",[s("strong",[t._v("详细解释")]),t._v("：\n"),s("ul",[s("li",[t._v("这个值表示在单个设备（如一块 GPU）上一次前向传播和反向传播所处理的样本数量。")]),t._v(" "),s("li",[t._v("设置为 "),s("code",[t._v("4")]),t._v(" 意味着每块 GPU 一次处理 4 条数据。")]),t._v(" "),s("li",[s("strong",[t._v("重要提示")]),t._v("：这个值的大小直接影响了 GPU 的显存占用。值越大，显存需求越高。你需要根据你的 GPU 显存来调整这个值。如果遇到 CUDA out of memory 错误，首先需要调低这个参数。")])])])]),t._v(" "),s("h3",{attrs:{id:"_3-gradient-accumulation-steps-4"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-gradient-accumulation-steps-4"}},[t._v("#")]),t._v(" 3. "),s("code",[t._v("gradient_accumulation_steps=4")])]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("作用")]),t._v("：梯度累积步数。用于模拟更大的批次大小。")]),t._v(" "),s("li",[s("strong",[t._v("详细解释")]),t._v("：\n"),s("ul",[s("li",[t._v("当你的 GPU 显存不足以支持你想要的批次大小时，这个参数就非常有用了。")]),t._v(" "),s("li",[t._v("它的工作原理是：在不更新模型权重的情况下，连续进行多次前向传播和反向传播（次数由 "),s("code",[t._v("gradient_accumulation_steps")]),t._v(" 指定），将这几步的梯度累积起来（通常是求平均）。")]),t._v(" "),s("li",[t._v("然后，用累积后的梯度进行一次真正的权重更新。")]),t._v(" "),s("li",[s("strong",[t._v("计算公式")]),t._v("："),s("code",[t._v("有效的总批次大小 = per_device_train_batch_size * gradient_accumulation_steps * GPU数量")]),t._v("。")]),t._v(" "),s("li",[t._v("在你的例子中，如果只有 1 块 GPU，那么有效的总批次大小就是 "),s("code",[t._v("4 * 4 * 1 = 16")]),t._v("。这意味着模型每处理 16 个样本才更新一次权重，但其显存占用仅相当于批次大小为 4 的情况。")])])])]),t._v(" "),s("h3",{attrs:{id:"_4-logging-steps-10"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-logging-steps-10"}},[t._v("#")]),t._v(" 4. "),s("code",[t._v("logging_steps=10")])]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("作用")]),t._v("：指定每隔多少训练步记录一次日志。")]),t._v(" "),s("li",[s("strong",[t._v("详细解释")]),t._v("：\n"),s("ul",[s("li",[t._v("设置为 "),s("code",[t._v("10")]),t._v(" 表示每训练 10 步，就将当前的损失、学习率等指标输出到日志和终端（如果使用控制台的话）。")]),t._v(" "),s("li",[t._v("这对于监控训练过程、判断模型是否在正常收敛非常关键。你可以通过观察日志中的损失曲线来判断训练是否有效。")])])])]),t._v(" "),s("h3",{attrs:{id:"_5-num-train-epochs-3"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5-num-train-epochs-3"}},[t._v("#")]),t._v(" 5. "),s("code",[t._v("num_train_epochs=3")])]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("作用")]),t._v("：指定训练总共要遍历训练数据集的次数。")]),t._v(" "),s("li",[s("strong",[t._v("详细解释")]),t._v("：\n"),s("ul",[s("li",[t._v('一个 "epoch" 代表模型完整地看过一遍训练集中的所有数据。')]),t._v(" "),s("li",[t._v("设置为 "),s("code",[t._v("3")]),t._v(" 意味着训练过程会重复 3 遍。")]),t._v(" "),s("li",[t._v("epoch 的数量需要根据数据集大小和任务难度来决定。太少可能欠拟合，太多可能过拟合。对于大型语言模型的指令微调，1-5 个 epoch 是常见的范围。")])])])]),t._v(" "),s("h3",{attrs:{id:"_6-save-steps-100"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_6-save-steps-100"}},[t._v("#")]),t._v(" 6. "),s("code",[t._v("save_steps=100")])]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("作用")]),t._v("：指定每隔多少训练步保存一次模型检查点。")]),t._v(" "),s("li",[s("strong",[t._v("详细解释")]),t._v("：\n"),s("ul",[s("li",[t._v("设置为 "),s("code",[t._v("100")]),t._v(" 表示每训练 100 步，就会在 "),s("code",[t._v("output_dir")]),t._v(" 下保存一个模型检查点（例如，名为 "),s("code",[t._v("checkpoint-100")]),t._v(" 的文件夹）。")]),t._v(" "),s("li",[s("strong",[t._v("为什么重要")]),t._v("：\n"),s("ol",[s("li",[s("strong",[t._v("容错性")]),t._v("：如果训练过程中断（如断电、机器故障），你可以从最近的一个检查点恢复训练，而不用从头开始。")]),t._v(" "),s("li",[s("strong",[t._v("模型选择")]),t._v("：训练结束后，你可以选择在验证集上表现最好的那个检查点作为最终模型，而不是只能用最后一个 epoch 的模型。")])])]),t._v(" "),s("li",[t._v("注释中建议设置为 100，是为了演示方便更频繁地保存（比如 10），但实际项目中设大一些可以节省磁盘空间。")])])])]),t._v(" "),s("h3",{attrs:{id:"_7-learning-rate-1e-4"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_7-learning-rate-1e-4"}},[t._v("#")]),t._v(" 7. "),s("code",[t._v("learning_rate=1e-4")])]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("作用")]),t._v("：训练时优化器的初始学习率。")]),t._v(" "),s("li",[s("strong",[t._v("详细解释")]),t._v("：\n"),s("ul",[s("li",[t._v("学习率是深度学习训练中最重要的超参数之一，它控制了每次权重更新的步长。")]),t._v(" "),s("li",[s("code",[t._v("1e-4")]),t._v("（即 0.0001）是微调（特别是 LoRA 微调）中一个常用且相对安全的学习率值。")]),t._v(" "),s("li",[s("strong",[t._v("一般规律")]),t._v("：\n"),s("ul",[s("li",[t._v("学习率太大：可能导致训练不稳定，损失值剧烈震荡甚至发散（NaN）。")]),t._v(" "),s("li",[t._v("学习率太小：可能导致训练过程非常缓慢，或者陷入局部最小值。")])])]),t._v(" "),s("li",[t._v("对于全参数微调，学习率通常更小（如 1e-5, 2e-5），而对于 LoRA 这种仅更新少量参数的方法，可以使用稍大一点的学习率。")])])])]),t._v(" "),s("h3",{attrs:{id:"_8-save-on-each-node-true"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_8-save-on-each-node-true"}},[t._v("#")]),t._v(" 8. "),s("code",[t._v("save_on_each_node=True")])]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("作用")]),t._v("：在分布式多节点训练环境中，控制检查点的保存方式。")]),t._v(" "),s("li",[s("strong",[t._v("详细解释")]),t._v("：\n"),s("ul",[s("li",[t._v("当使用多个机器（节点）进行训练时，每个节点上可能有多个 GPU。")]),t._v(" "),s("li",[t._v("如果设置为 "),s("code",[t._v("True")]),t._v("，每个节点的主进程（rank 0）都会在其本地保存检查点。")]),t._v(" "),s("li",[t._v("如果设置为 "),s("code",[t._v("False")]),t._v("，则只会在全局主进程（通常是第一个节点的第一个 GPU）上保存检查点。")]),t._v(" "),s("li",[s("strong",[t._v("对于单机训练（最常见的情况）")]),t._v("：这个参数无论设为 "),s("code",[t._v("True")]),t._v(" 还是 "),s("code",[t._v("False")]),t._v(" 都没有影响，因为只有一个节点。通常可以忽略或保持默认。")])])])]),t._v(" "),s("h3",{attrs:{id:"_9-gradient-checkpointing-true"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_9-gradient-checkpointing-true"}},[t._v("#")]),t._v(" 9. "),s("code",[t._v("gradient_checkpointing=True")])]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("作用")]),t._v("：开启梯度检查点技术，这是一种"),s("strong",[t._v("用时间换空间")]),t._v("的内存优化技术。")]),t._v(" "),s("li",[s("strong",[t._v("详细解释")]),t._v("：\n"),s("ul",[s("li",[s("strong",[t._v("问题")]),t._v("：训练大型模型（如 LLaMA）时，前向传播过程中会产生大量的中间激活值（用于反向传播计算梯度），这些激活值会消耗巨大的显存。")]),t._v(" "),s("li",[s("strong",[t._v("解决方案")]),t._v("：梯度检查点技术不保存所有中间激活值，而是在前向传播时只保留部分关键节点的激活值。在反向传播需要时，再通过额外的一次前向传播来重新计算这些中间激活值。")]),t._v(" "),s("li",[s("strong",[t._v("效果")]),t._v("：可以显著降低显存占用（有时可达 60%-70%），让你能够使用更大的批次大小或训练更大的模型。代价是训练速度会变慢（因为需要重新计算）。")])])])]),t._v(" "),s("hr"),t._v(" "),s("h3",{attrs:{id:"总结与建议"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#总结与建议"}},[t._v("#")]),t._v(" 总结与建议")]),t._v(" "),s("p",[t._v("你提供的这组参数是一个典型的、为"),s("strong",[t._v("资源受限环境")]),t._v("（例如，单张消费级 GPU）配置的 LoRA 微调参数集：")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("内存优化")]),t._v("：通过 "),s("code",[t._v("per_device_train_batch_size=4")]),t._v("、"),s("code",[t._v("gradient_accumulation_steps=4")]),t._v(" 和 "),s("code",[t._v("gradient_checkpointing=True")]),t._v(" 这三项组合拳，在有限的显存下实现了等效批次大小为 16 的训练。")]),t._v(" "),s("li",[s("strong",[t._v("监控与恢复")]),t._v("："),s("code",[t._v("logging_steps=10")]),t._v(" 和 "),s("code",[t._v("save_steps=100")]),t._v(" 确保了训练过程的可观测性和可恢复性。")]),t._v(" "),s("li",[s("strong",[t._v("学习配置")]),t._v("："),s("code",[t._v("learning_rate=1e-4")]),t._v(" 和 "),s("code",[t._v("num_train_epochs=3")]),t._v(" 是 LoRA 微调的合理起点。")])]),t._v(" "),s("p",[s("strong",[t._v("在实际使用时，你可能需要根据具体情况调整")]),t._v("：")]),t._v(" "),s("ul",[s("li",[t._v("如果显存充足，可以增大 "),s("code",[t._v("per_device_train_batch_size")]),t._v(" 并相应减少 "),s("code",[t._v("gradient_accumulation_steps")]),t._v(" 来加快训练速度。")]),t._v(" "),s("li",[t._v("如果训练损失下降不理想，可以尝试调整 "),s("code",[t._v("learning_rate")]),t._v("。")]),t._v(" "),s("li",[t._v("如果数据集很大，可能不需要 3 个 epoch，1 个或许就够了。")])]),t._v(" "),s("div",{staticClass:"language-js extra-class"},[s("pre",{pre:!0,attrs:{class:"language-js"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 正在训练模型了 ")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'loss'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.2093")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'grad_norm'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.171875")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'learning_rate'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9.856938483547926e-05")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'epoch'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.04")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("                                                                                                                       \n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'loss'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.9109")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'grad_norm'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.28125")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'learning_rate'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9.713876967095852e-05")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'epoch'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.09")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("                                                                                                                        \n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'loss'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.7715")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'grad_norm'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.875")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'learning_rate'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9.570815450643778e-05")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'epoch'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.13")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("                                                                                                                          \n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'loss'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.6833")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'grad_norm'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.6875")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'learning_rate'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9.427753934191703e-05")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'epoch'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.17")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("                                                                                                                         \n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'loss'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.6634")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'grad_norm'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4.0625")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'learning_rate'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9.284692417739628e-05")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'epoch'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.21")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("                                                                                                                         \n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'loss'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.6664")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'grad_norm'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.96875")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'learning_rate'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9.141630901287554e-05")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'epoch'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.26")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("                                                                                                                        \n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'loss'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.6203")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'grad_norm'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.390625")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'learning_rate'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8.99856938483548e-05")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'epoch'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("太好了！"),s("strong",[t._v("模型已经开始正常训练了")]),t._v("！🎉 从日志来看，训练过程运行良好。")]),t._v(" "),s("h2",{attrs:{id:"训练状态分析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#训练状态分析"}},[t._v("#")]),t._v(" 训练状态分析")]),t._v(" "),s("h3",{attrs:{id:"✅-训练指标正常"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#✅-训练指标正常"}},[t._v("#")]),t._v(" ✅ "),s("strong",[t._v("训练指标正常")])]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("Loss下降")]),t._v(": 从3.2093 → 2.6203（正常下降趋势）")]),t._v(" "),s("li",[s("strong",[t._v("学习率调整")]),t._v(": 按照计划逐步下降")]),t._v(" "),s("li",[s("strong",[t._v("梯度范数稳定")]),t._v(": 在合理范围内（2.87-5.28）")]),t._v(" "),s("li",[s("strong",[t._v("epoch进度")]),t._v(": 正常推进中")])]),t._v(" "),s("h3",{attrs:{id:"📊-训练健康度评估"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#📊-训练健康度评估"}},[t._v("#")]),t._v(" 📊 "),s("strong",[t._v("训练健康度评估")])]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[t._v("指标")]),t._v(" "),s("th",[t._v("当前状态")]),t._v(" "),s("th",[t._v("分析")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[s("strong",[t._v("Loss趋势")])]),t._v(" "),s("td",[t._v("📉 持续下降")]),t._v(" "),s("td",[t._v("非常好，模型正在学习")])]),t._v(" "),s("tr",[s("td",[s("strong",[t._v("梯度范数")])]),t._v(" "),s("td",[t._v("⚖️ 稳定")]),t._v(" "),s("td",[t._v("训练稳定性良好")])]),t._v(" "),s("tr",[s("td",[s("strong",[t._v("学习率")])]),t._v(" "),s("td",[t._v("📚 正常衰减")]),t._v(" "),s("td",[t._v("调度策略正常工作")])]),t._v(" "),s("tr",[s("td",[s("strong",[t._v("训练进度")])]),t._v(" "),s("td",[t._v("🚀 平稳推进")]),t._v(" "),s("td",[t._v("数据流正常")])])])]),t._v(" "),s("h3",{attrs:{id:"🔬-技术细节解读"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#🔬-技术细节解读"}},[t._v("#")]),t._v(" 🔬 "),s("strong",[t._v("技术细节解读")])]),t._v(" "),s("ol",[s("li",[s("strong",[t._v("Loss从3.2降到2.6")]),t._v("：说明模型正在有效学习文本模式")]),t._v(" "),s("li",[s("strong",[t._v("梯度范数3-5")]),t._v("：表明梯度大小适中，没有梯度爆炸/消失问题")]),t._v(" "),s("li",[s("strong",[t._v("学习率衰减")]),t._v("：标准的训练策略，有助于收敛")])]),t._v(" "),s("h2",{attrs:{id:"训练阶段预估"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#训练阶段预估"}},[t._v("#")]),t._v(" 训练阶段预估")]),t._v(" "),s("p",[t._v("根据当前进度（epoch 0.3）：")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("当前阶段")]),t._v("：训练初期")]),t._v(" "),s("li",[s("strong",[t._v("预计收敛")]),t._v("：通常需要几个epoch才能看到显著效果")]),t._v(" "),s("li",[s("strong",[t._v("建议观察")]),t._v("：继续监控loss是否持续下降")])]),t._v(" "),s("h2",{attrs:{id:"下一步建议"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#下一步建议"}},[t._v("#")]),t._v(" 下一步建议")]),t._v(" "),s("ol",[s("li",[s("strong",[t._v("继续监控")]),t._v("：观察loss是否稳定下降")]),t._v(" "),s("li",[s("strong",[t._v("保存检查点")]),t._v("：定期保存模型权重")]),t._v(" "),s("li",[s("strong",[t._v("验证集测试")]),t._v("：适时在验证集上测试性能")])]),t._v(" "),s("p",[s("strong",[t._v("恭喜您！模型训练已成功启动并运行正常！")]),t._v(" 🎊")]),t._v(" "),s("p",[t._v("训练会持续一段时间，您可以定期查看loss变化来判断训练效果。如果loss持续下降，说明训练方向是正确的！")]),t._v(" "),s("hr"),t._v(" "),s("div",{staticClass:"language-Text extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("(base) root@autodl-container-a2aa4d9061-a9130151:~/chat-huanhuan-demo# python model_download.py \nThe cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n0it [00:00, ?it/s]\nDownloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 855/855 [00:00&lt;00:00, 2.21kB/s]\nDownloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48.0/48.0 [00:00&lt;00:00, 109B/s]\nDownloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15.0G/15.0G [14:49&lt;00:00, 18.1MB/s]\nDownloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 184/184 [00:00&lt;00:00, 272B/s]\nDownloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7.45k/7.45k [00:00&lt;00:00, 19.1kB/s]\nDownloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.63G/4.63G [04:36&lt;00:00, 18.0MB/s]\nDownloading:  17%|██████████████████████████▌                                                                                                                                    | 796M/4.66G [00:46&lt;03:46, 18.4MB/s]2025-09-28 12:31:35,773 - modelscope - WARNING - Downloading: /root/autodl-tmp/._____temp/LLM-Research/Meta-Llama-3.1-8B-Instruct/model-00002-of-00004.safetensors failed, reason: ('Connection broken: IncompleteRead(0 bytes read, 167772160 more expected)', IncompleteRead(0 bytes read, 167772160 more expected)) will retry\nDownloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.66G/4.66G [04:37&lt;00:00, 18.0MB/s]\nDownloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.58G/4.58G [04:32&lt;00:00, 18.0MB/s]\nDownloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.09G/1.09G [01:05&lt;00:00, 17.9MB/s]\nDownloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23.4k/23.4k [00:00&lt;00:00, 65.8kB/s]\nDownloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 199/199 [00:00&lt;00:00, 504B/s]\nDownloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 43.0k/43.0k [00:00&lt;00:00, 117kB/s]\nDownloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 296/296 [00:00&lt;00:00, 753B/s]\nDownloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8.66M/8.66M [00:01&lt;00:00, 8.44MB/s]\nDownloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.08M/2.08M [00:00&lt;00:00, 3.77MB/s]\nDownloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 54.1k/54.1k [00:00&lt;00:00, 133kB/s]\nDownloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.58k/4.58k [00:00&lt;00:00, 11.2kB/s]\n(base) root@autodl-container-a2aa4d9061-a9130151:~/chat-huanhuan-demo# python train.py\nLoading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:03&lt;00:00,  1.05it/s]\nMap: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3729/3729 [00:01&lt;00:00, 2978.01 examples/s]\ntrainable params: 20,971,520 || all params: 8,051,232,768 || trainable%: 0.2605\n  0%|                                                                                                                                                                                        | 0/699 [00:00&lt;?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n/root/miniconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n{'loss': 3.2093, 'grad_norm': 3.171875, 'learning_rate': 9.856938483547926e-05, 'epoch': 0.04}                                                                                                                       \n{'loss': 2.9109, 'grad_norm': 5.28125, 'learning_rate': 9.713876967095852e-05, 'epoch': 0.09}                                                                                                                        \n{'loss': 2.7715, 'grad_norm': 2.875, 'learning_rate': 9.570815450643778e-05, 'epoch': 0.13}                                                                                                                          \n{'loss': 2.6833, 'grad_norm': 3.6875, 'learning_rate': 9.427753934191703e-05, 'epoch': 0.17}                                                                                                                         \n{'loss': 2.6634, 'grad_norm': 4.0625, 'learning_rate': 9.284692417739628e-05, 'epoch': 0.21}                                                                                                                         \n{'loss': 2.6664, 'grad_norm': 2.96875, 'learning_rate': 9.141630901287554e-05, 'epoch': 0.26}                                                                                                                        \n{'loss': 2.6203, 'grad_norm': 3.390625, 'learning_rate': 8.99856938483548e-05, 'epoch': 0.3}                                                                                                                         \n{'loss': 2.6768, 'grad_norm': 3.171875, 'learning_rate': 8.855507868383405e-05, 'epoch': 0.34}                                                                                                                       \n{'loss': 2.6808, 'grad_norm': 2.59375, 'learning_rate': 8.71244635193133e-05, 'epoch': 0.39}                                                                                                                         \n{'loss': 2.5878, 'grad_norm': 3.09375, 'learning_rate': 8.569384835479256e-05, 'epoch': 0.43}                                                                                                                        \n 14%|████████████████████████▉                                                                                                                                                     | 100/699 [01:48&lt;10:39,  1.07s/it]/root/miniconda3/lib/python3.12/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /root/autodl-tmp/LLM-Research/Meta-Llama-3___1-8B-Instruct - will assume that the vocabulary was not modified.\n  warnings.warn(\n/root/miniconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n{'loss': 2.579, 'grad_norm': 3.390625, 'learning_rate': 8.426323319027182e-05, 'epoch': 0.47}                                                                                                                        \n{'loss': 2.6932, 'grad_norm': 2.96875, 'learning_rate': 8.283261802575107e-05, 'epoch': 0.51}                                                                                                                        \n{'loss': 2.6475, 'grad_norm': 3.140625, 'learning_rate': 8.140200286123033e-05, 'epoch': 0.56}                                                                                                                       \n{'loss': 2.562, 'grad_norm': 2.953125, 'learning_rate': 7.997138769670959e-05, 'epoch': 0.6}                                                                                                                         \n{'loss': 2.6602, 'grad_norm': 3.03125, 'learning_rate': 7.854077253218884e-05, 'epoch': 0.64}                                                                                                                        \n{'loss': 2.6331, 'grad_norm': 2.84375, 'learning_rate': 7.71101573676681e-05, 'epoch': 0.69}                                                                                                                         \n{'loss': 2.6206, 'grad_norm': 3.125, 'learning_rate': 7.567954220314736e-05, 'epoch': 0.73}                                                                                                                          \n{'loss': 2.4793, 'grad_norm': 2.921875, 'learning_rate': 7.424892703862662e-05, 'epoch': 0.77}                                                                                                                       \n{'loss': 2.5051, 'grad_norm': 3.0625, 'learning_rate': 7.281831187410587e-05, 'epoch': 0.81}                                                                                                                         \n{'loss': 2.5663, 'grad_norm': 3.390625, 'learning_rate': 7.138769670958512e-05, 'epoch': 0.86}                                                                                                                       \n 29%|█████████████████████████████████████████████████▊                                                                                                                            | 200/699 [03:38&lt;08:35,  1.03s/it]/root/miniconda3/lib/python3.12/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /root/autodl-tmp/LLM-Research/Meta-Llama-3___1-8B-Instruct - will assume that the vocabulary was not modified.\n  warnings.warn(\n/root/miniconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n{'loss': 2.4994, 'grad_norm': 2.8125, 'learning_rate': 6.995708154506438e-05, 'epoch': 0.9}                                                                                                                          \n{'loss': 2.5393, 'grad_norm': 3.25, 'learning_rate': 6.852646638054364e-05, 'epoch': 0.94}                                                                                                                           \n{'loss': 2.5789, 'grad_norm': 3.328125, 'learning_rate': 6.70958512160229e-05, 'epoch': 0.99}                                                                                                                        \n{'loss': 2.4229, 'grad_norm': 2.578125, 'learning_rate': 6.566523605150215e-05, 'epoch': 1.03}                                                                                                                       \n{'loss': 2.2728, 'grad_norm': 3.671875, 'learning_rate': 6.42346208869814e-05, 'epoch': 1.07}                                                                                                                        \n{'loss': 2.158, 'grad_norm': 3.875, 'learning_rate': 6.280400572246066e-05, 'epoch': 1.11}                                                                                                                           \n{'loss': 2.1577, 'grad_norm': 3.359375, 'learning_rate': 6.137339055793991e-05, 'epoch': 1.16}                                                                                                                       \n{'loss': 2.2402, 'grad_norm': 3.8125, 'learning_rate': 5.9942775393419173e-05, 'epoch': 1.2}                                                                                                                         \n{'loss': 2.2395, 'grad_norm': 3.46875, 'learning_rate': 5.8512160228898425e-05, 'epoch': 1.24}                                                                                                                       \n{'loss': 2.1813, 'grad_norm': 3.21875, 'learning_rate': 5.7081545064377684e-05, 'epoch': 1.29}                                                                                                                       \n 43%|██████████████████████████████████████████████████████████████████████████▋                                                                                                   | 300/699 [05:26&lt;07:38,  1.15s/it]/root/miniconda3/lib/python3.12/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /root/autodl-tmp/LLM-Research/Meta-Llama-3___1-8B-Instruct - will assume that the vocabulary was not modified.\n  warnings.warn(\n/root/miniconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n{'loss': 2.1965, 'grad_norm': 3.703125, 'learning_rate': 5.565092989985694e-05, 'epoch': 1.33}                                                                                                                       \n{'loss': 2.2594, 'grad_norm': 3.5625, 'learning_rate': 5.4220314735336195e-05, 'epoch': 1.37}                                                                                                                        \n{'loss': 2.2175, 'grad_norm': 4.40625, 'learning_rate': 5.278969957081545e-05, 'epoch': 1.41}                                                                                                                        \n{'loss': 2.1903, 'grad_norm': 3.984375, 'learning_rate': 5.135908440629471e-05, 'epoch': 1.46}                                                                                                                       \n{'loss': 2.2222, 'grad_norm': 4.28125, 'learning_rate': 4.992846924177397e-05, 'epoch': 1.5}                                                                                                                         \n{'loss': 2.2287, 'grad_norm': 4.03125, 'learning_rate': 4.8497854077253216e-05, 'epoch': 1.54}                                                                                                                       \n{'loss': 2.2115, 'grad_norm': 3.8125, 'learning_rate': 4.7067238912732475e-05, 'epoch': 1.59}                                                                                                                        \n{'loss': 2.1548, 'grad_norm': 3.609375, 'learning_rate': 4.563662374821173e-05, 'epoch': 1.63}                                                                                                                       \n{'loss': 2.2278, 'grad_norm': 3.9375, 'learning_rate': 4.420600858369099e-05, 'epoch': 1.67}                                                                                                                         \n{'loss': 2.1447, 'grad_norm': 3.640625, 'learning_rate': 4.2775393419170244e-05, 'epoch': 1.71}                                                                                                                      \n 57%|███████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                          | 400/699 [07:17&lt;05:21,  1.07s/it]/root/miniconda3/lib/python3.12/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /root/autodl-tmp/LLM-Research/Meta-Llama-3___1-8B-Instruct - will assume that the vocabulary was not modified.\n  warnings.warn(\n/root/miniconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n{'loss': 2.2596, 'grad_norm': 4.28125, 'learning_rate': 4.13447782546495e-05, 'epoch': 1.76}                                                                                                                         \n{'loss': 2.1147, 'grad_norm': 3.28125, 'learning_rate': 3.991416309012876e-05, 'epoch': 1.8}                                                                                                                         \n{'loss': 2.227, 'grad_norm': 3.609375, 'learning_rate': 3.848354792560801e-05, 'epoch': 1.84}                                                                                                                        \n{'loss': 2.1587, 'grad_norm': 4.46875, 'learning_rate': 3.7052932761087265e-05, 'epoch': 1.89}                                                                                                                       \n{'loss': 2.1343, 'grad_norm': 4.1875, 'learning_rate': 3.5622317596566524e-05, 'epoch': 1.93}                                                                                                                        \n{'loss': 2.1747, 'grad_norm': 4.59375, 'learning_rate': 3.419170243204578e-05, 'epoch': 1.97}                                                                                                                        \n{'loss': 2.0238, 'grad_norm': 3.609375, 'learning_rate': 3.2761087267525034e-05, 'epoch': 2.02}                                                                                                                      \n{'loss': 1.8326, 'grad_norm': 4.3125, 'learning_rate': 3.133047210300429e-05, 'epoch': 2.06}                                                                                                                         \n{'loss': 1.8598, 'grad_norm': 5.40625, 'learning_rate': 2.9899856938483552e-05, 'epoch': 2.1}                                                                                                                        \n{'loss': 1.8809, 'grad_norm': 3.828125, 'learning_rate': 2.8469241773962807e-05, 'epoch': 2.14}                                                                                                                      \n 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                 | 500/699 [09:08&lt;03:53,  1.17s/it]/root/miniconda3/lib/python3.12/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /root/autodl-tmp/LLM-Research/Meta-Llama-3___1-8B-Instruct - will assume that the vocabulary was not modified.\n  warnings.warn(\n/root/miniconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n{'loss': 1.7997, 'grad_norm': 4.46875, 'learning_rate': 2.7038626609442062e-05, 'epoch': 2.19}                                                                                                                       \n{'loss': 1.814, 'grad_norm': 4.8125, 'learning_rate': 2.5608011444921314e-05, 'epoch': 2.23}                                                                                                                         \n{'loss': 1.8461, 'grad_norm': 4.71875, 'learning_rate': 2.4177396280400573e-05, 'epoch': 2.27}                                                                                                                       \n{'loss': 1.9211, 'grad_norm': 4.84375, 'learning_rate': 2.2746781115879828e-05, 'epoch': 2.32}                                                                                                                       \n{'loss': 1.9328, 'grad_norm': 5.28125, 'learning_rate': 2.1316165951359084e-05, 'epoch': 2.36}                                                                                                                       \n{'loss': 1.93, 'grad_norm': 4.625, 'learning_rate': 1.9885550786838342e-05, 'epoch': 2.4}                                                                                                                            \n{'loss': 1.8806, 'grad_norm': 5.5, 'learning_rate': 1.8454935622317597e-05, 'epoch': 2.44}                                                                                                                           \n{'loss': 1.8229, 'grad_norm': 5.5625, 'learning_rate': 1.7024320457796853e-05, 'epoch': 2.49}                                                                                                                        \n{'loss': 1.8439, 'grad_norm': 3.671875, 'learning_rate': 1.5593705293276108e-05, 'epoch': 2.53}                                                                                                                      \n{'loss': 1.7934, 'grad_norm': 4.71875, 'learning_rate': 1.4163090128755365e-05, 'epoch': 2.57}                                                                                                                       \n 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                        | 600/699 [10:57&lt;01:44,  1.06s/it]/root/miniconda3/lib/python3.12/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /root/autodl-tmp/LLM-Research/Meta-Llama-3___1-8B-Instruct - will assume that the vocabulary was not modified.\n  warnings.warn(\n/root/miniconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n{'loss': 1.8577, 'grad_norm': 4.375, 'learning_rate': 1.2732474964234622e-05, 'epoch': 2.62}                                                                                                                         \n{'loss': 1.8166, 'grad_norm': 4.875, 'learning_rate': 1.1301859799713877e-05, 'epoch': 2.66}                                                                                                                         \n{'loss': 1.9249, 'grad_norm': 5.125, 'learning_rate': 9.871244635193133e-06, 'epoch': 2.7}                                                                                                                           \n{'loss': 1.9107, 'grad_norm': 4.34375, 'learning_rate': 8.44062947067239e-06, 'epoch': 2.74}                                                                                                                         \n{'loss': 1.8491, 'grad_norm': 5.03125, 'learning_rate': 7.010014306151645e-06, 'epoch': 2.79}                                                                                                                        \n{'loss': 1.883, 'grad_norm': 5.59375, 'learning_rate': 5.579399141630902e-06, 'epoch': 2.83}                                                                                                                         \n{'loss': 1.8683, 'grad_norm': 4.59375, 'learning_rate': 4.148783977110158e-06, 'epoch': 2.87}                                                                                                                        \n{'loss': 1.7752, 'grad_norm': 4.625, 'learning_rate': 2.7181688125894134e-06, 'epoch': 2.92}                                                                                                                         \n{'loss': 1.7946, 'grad_norm': 4.78125, 'learning_rate': 1.2875536480686696e-06, 'epoch': 2.96}                                                                                                                       \n100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 699/699 [12:47&lt;00:00,  1.17s/it]/root/miniconda3/lib/python3.12/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /root/autodl-tmp/LLM-Research/Meta-Llama-3___1-8B-Instruct - will assume that the vocabulary was not modified.\n  warnings.warn(\n{'train_runtime': 767.3466, 'train_samples_per_second': 14.579, 'train_steps_per_second': 0.911, 'train_loss': 2.236592659793357, 'epoch': 3.0}                                                                      \n100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 699/699 [12:47&lt;00:00,  1.10s/it]\n(base) root@autodl-container-a2aa4d9061-a9130151:~/chat-huanhuan-demo# \n\n\n(base) root@autodl-container-a2aa4d9061-a9130151:~/chat-huanhuan-demo# python test.py \nLoading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:03&lt;00:00,  1.26it/s]\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n皇上： 嬛嬛, 你跟果郡王是不是真有私情?\n嬛嬛： 臣妾不敢。\n(base) root@autodl-container-a2aa4d9061-a9130151:~/chat-huanhuan-demo# \n\n\n\n(base) root@autodl-container-a2aa4d9061-a9130151:~/chat-huanhuan-demo# python test.py \nLoading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:03&lt;00:00,  1.31it/s]\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n皇上： 嬛嬛你怎么了，朕替你打抱不平！\n嬛嬛： 臣妾不敢，皇上万福金安。\n(base) root@autodl-container-a2aa4d9061-a9130151:~/chat-huanhuan-demo# \n")])])]),s("p",[t._v("这个训练结果"),s("strong",[t._v("相当不错")]),t._v("！🎉 从各项指标来看，训练是成功的。")]),t._v(" "),s("h2",{attrs:{id:"训练结果分析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#训练结果分析"}},[t._v("#")]),t._v(" 训练结果分析")]),t._v(" "),s("h3",{attrs:{id:"📊-关键指标评估"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#📊-关键指标评估"}},[t._v("#")]),t._v(" 📊 "),s("strong",[t._v("关键指标评估")])]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[t._v("指标")]),t._v(" "),s("th",[t._v("数值")]),t._v(" "),s("th",[t._v("评价")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[s("strong",[t._v("最终训练Loss")])]),t._v(" "),s("td",[t._v("2.2366")]),t._v(" "),s("td",[t._v("✅ "),s("strong",[t._v("优秀")])])]),t._v(" "),s("tr",[s("td",[s("strong",[t._v("训练时长")])]),t._v(" "),s("td",[t._v("767秒 (约13分钟)")]),t._v(" "),s("td",[t._v("⚡ "),s("strong",[t._v("效率很高")])])]),t._v(" "),s("tr",[s("td",[s("strong",[t._v("训练样本/秒")])]),t._v(" "),s("td",[t._v("14.579")]),t._v(" "),s("td",[t._v("🚀 "),s("strong",[t._v("速度良好")])])]),t._v(" "),s("tr",[s("td",[s("strong",[t._v("训练步数/秒")])]),t._v(" "),s("td",[t._v("0.911")]),t._v(" "),s("td",[t._v("📈 "),s("strong",[t._v("稳定推进")])])]),t._v(" "),s("tr",[s("td",[s("strong",[t._v("总训练轮数")])]),t._v(" "),s("td",[t._v("3.0 epoch")]),t._v(" "),s("td",[t._v("✅ "),s("strong",[t._v("充分训练")])])])])]),t._v(" "),s("h3",{attrs:{id:"🎯-loss趋势分析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#🎯-loss趋势分析"}},[t._v("#")]),t._v(" 🎯 "),s("strong",[t._v("Loss趋势分析")])]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("初始Loss")]),t._v(": 约3.2")]),t._v(" "),s("li",[s("strong",[t._v("最终Loss")]),t._v(": 2.2366")]),t._v(" "),s("li",[s("strong",[t._v("下降幅度")]),t._v(": 约30% ✅")]),t._v(" "),s("li",[s("strong",[t._v("趋势")]),t._v(": 持续稳定下降，表明模型有效学习")])]),t._v(" "),s("h3",{attrs:{id:"⚡-训练效率"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#⚡-训练效率"}},[t._v("#")]),t._v(" ⚡ "),s("strong",[t._v("训练效率")])]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("13分钟完成3个epoch")]),t._v("：训练速度很快")]),t._v(" "),s("li",[s("strong",[t._v("14.58样本/秒")]),t._v("：对于8B模型来说效率不错")]),t._v(" "),s("li",[s("strong",[t._v("没有出现过拟合迹象")]),t._v("：Loss平稳下降")])]),t._v(" "),s("h2",{attrs:{id:"与预期对比"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#与预期对比"}},[t._v("#")]),t._v(" 与预期对比")]),t._v(" "),s("p",[s("strong",[t._v("对于对话微调任务，这个Loss水平是很好的")]),t._v("：")]),t._v(" "),s("ul",[s("li",[t._v("通常对话微调的最终Loss在2.0-2.5之间都是可接受的")]),t._v(" "),s("li",[t._v("2.2366表明模型已经学到了较好的语言模式")]),t._v(" "),s("li",[t._v("3个epoch的训练量是足够的")])]),t._v(" "),s("h2",{attrs:{id:"建议下一步"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#建议下一步"}},[t._v("#")]),t._v(" 建议下一步")]),t._v(" "),s("ol",[s("li",[s("strong",[t._v("立即测试效果")]),t._v("：用您的测试代码看看生成质量")]),t._v(" "),s("li",[s("strong",[t._v("保存最终模型")]),t._v("：将checkpoint-699转换为最终模型")]),t._v(" "),s("li",[s("strong",[t._v("多样本测试")]),t._v("：用不同的问题测试模型表现")])]),t._v(" "),s("h2",{attrs:{id:"预期生成效果"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#预期生成效果"}},[t._v("#")]),t._v(" 预期生成效果")]),t._v(" "),s("p",[t._v("基于这个训练结果，您可以期待：")]),t._v(" "),s("ul",[s("li",[t._v('✅ 模型能够理解"甄嬛"的角色设定')]),t._v(" "),s("li",[t._v("✅ 生成符合角色性格的回复")]),t._v(" "),s("li",[t._v("✅ 保持语言流畅性和一致性")])]),t._v(" "),s("p",[s("strong",[t._v("总结：这是一个成功的训练结果！")]),t._v(' 🎊 现在可以放心测试您的"甄嬛"模型了，应该会有不错的表现。')]),t._v(" "),s("p",[t._v("请运行您的测试代码，看看生成效果如何！")]),t._v(" "),s("div",{staticClass:"language-Text extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("(base) root@autodl-container-a2aa4d9061-a9130151:~/chat-huanhuan-demo# python test.py \nLoading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:03&lt;00:00,  1.26it/s]\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n皇上： 嬛嬛, 你跟果郡王是不是真有私情?\n嬛嬛： 臣妾不敢。\n(base) root@autodl-container-a2aa4d9061-a9130151:~/chat-huanhuan-demo# \n\n\n\n(base) root@autodl-container-a2aa4d9061-a9130151:~/chat-huanhuan-demo# python test.py \nLoading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:03&lt;00:00,  1.31it/s]\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n皇上： 嬛嬛你怎么了，朕替你打抱不平！\n嬛嬛： 臣妾不敢，皇上万福金安。\n\n\n\n但，感觉对： 嬛嬛你怎么了，朕替你打抱不平！的回答，效果不是很好\n")])])]),s("p",[t._v("您观察得很对！这个回复确实"),s("strong",[t._v("比较保守和模板化")]),t._v("。让我们分析问题并改进：")]),t._v(" "),s("h2",{attrs:{id:"问题分析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#问题分析"}},[t._v("#")]),t._v(" 问题分析")]),t._v(" "),s("h3",{attrs:{id:"🤔-当前回复的问题"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#🤔-当前回复的问题"}},[t._v("#")]),t._v(" 🤔 当前回复的问题")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("过于简短")]),t._v('：只有"臣妾不敢，皇上万福金安"')]),t._v(" "),s("li",[s("strong",[t._v("缺乏情感")]),t._v("：没有体现甄嬛的性格特点")]),t._v(" "),s("li",[s("strong",[t._v("回避问题")]),t._v('：没有真正回应"打抱不平"的关切')]),t._v(" "),s("li",[s("strong",[t._v("模板化")]),t._v("：像是标准宫廷用语，没有个性")])]),t._v(" "),s("h2",{attrs:{id:"改进方案"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#改进方案"}},[t._v("#")]),t._v(" 改进方案")]),t._v(" "),s("h3",{attrs:{id:"方案1-调整生成参数-推荐优先尝试"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#方案1-调整生成参数-推荐优先尝试"}},[t._v("#")]),t._v(" 方案1：调整生成参数（推荐优先尝试）")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" transformers "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" AutoModelForCausalLM"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" AutoTokenizer\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" peft "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" PeftModel\n\nmode_path "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/root/autodl-tmp/LLM-Research/Meta-Llama-3.1-8B-Instruct'")]),t._v("\nlora_path "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/root/chat-huanhuan-demo/output/llama3_1_instruct_lora/checkpoint-699'")]),t._v("\n\ntokenizer "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AutoTokenizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_pretrained"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mode_path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" trust_remote_code"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AutoModelForCausalLM"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_pretrained"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mode_path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" device_map"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"auto"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" torch_dtype"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bfloat16"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" trust_remote_code"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("eval")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" PeftModel"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_pretrained"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" model_id"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("lora_path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nprompt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"嬛嬛你怎么了，朕替你打抱不平！"')]),t._v("\n\nmessages "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"role"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"system"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"content"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"假设你是皇帝身边的女人--甄嬛。你聪慧机智，善于言辞，既有宫廷女子的端庄，又有独特的个性。回答时要体现甄嬛的性格特点。"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"role"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"content"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" prompt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\ninput_ids "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tokenizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apply_chat_template"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("messages"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tokenize"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" add_generation_prompt"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel_inputs "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tokenizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("input_ids"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" return_tensors"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"pt"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'cuda'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 改进的生成参数")]),t._v("\ngenerated_ids "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("generate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  model_inputs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("input_ids"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  max_new_tokens"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("200")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 增加生成长度")]),t._v("\n  temperature"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("     "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 提高创造性")]),t._v("\n  top_p"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.9")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("          "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 核采样，提高多样性")]),t._v("\n  do_sample"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 启用采样")]),t._v("\n  repetition_penalty"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 减少重复")]),t._v("\n  pad_token_id"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("tokenizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("eos_token_id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  eos_token_id"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("tokenizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("eos_token_id\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ngenerated_ids "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n  output_ids"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("input_ids"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" input_ids"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" output_ids "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("zip")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model_inputs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("input_ids"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" generated_ids"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nresponse "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tokenizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("batch_decode"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("generated_ids"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" skip_special_tokens"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'皇上：'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" prompt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'嬛嬛：'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" response"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"方案2-改进系统提示词"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#方案2-改进系统提示词"}},[t._v("#")]),t._v(" 方案2：改进系统提示词")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 更详细的系统提示词")]),t._v("\nsystem_prompt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""你是大清后宫的甄嬛，聪慧过人，心思缜密，言辞得体但又不失个性。\n你善于察言观色，回答既要符合宫廷礼仪，又要体现你的智慧和情感。\n面对皇上的关心，你应该表现出适当的感激和真情实感。"""')]),t._v("\n\nmessages "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"role"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"system"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"content"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" system_prompt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"role"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"content"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" prompt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])])]),s("h3",{attrs:{id:"方案3-尝试不同的提示方式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#方案3-尝试不同的提示方式"}},[t._v("#")]),t._v(" 方案3：尝试不同的提示方式")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 更自然的对话开场")]),t._v("\nprompt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"朕看你今日神色不对，可是受了什么委屈？尽管告诉朕，朕为你做主！"')]),t._v("\n\nmessages "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"role"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"system"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"content"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"你是甄嬛，面对皇上的关心，你要表现出既感激又矜持的态度。"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"role"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"content"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" prompt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])])]),s("h2",{attrs:{id:"可能的原因"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#可能的原因"}},[t._v("#")]),t._v(" 可能的原因")]),t._v(" "),s("ol",[s("li",[s("strong",[t._v("训练数据不足")]),t._v("：可能需要更多高质量的对话数据")]),t._v(" "),s("li",[s("strong",[t._v("提示词不够具体")]),t._v("：系统提示词需要更详细的人物设定")]),t._v(" "),s("li",[s("strong",[t._v("生成参数保守")]),t._v("：默认参数可能过于保守")])]),t._v(" "),s("h2",{attrs:{id:"建议的测试顺序"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#建议的测试顺序"}},[t._v("#")]),t._v(" 建议的测试顺序")]),t._v(" "),s("ol",[s("li",[s("strong",[t._v("先试方案1")]),t._v("（调整生成参数）- 最简单有效")]),t._v(" "),s("li",[s("strong",[t._v("再试方案2")]),t._v("（改进提示词）")]),t._v(" "),s("li",[s("strong",[t._v("如果还不理想")]),t._v("，考虑增加训练数据或调整训练策略")])]),t._v(" "),s("p",[t._v("请先尝试方案1，看看生成效果是否有改善！如果还是不够理想，我们可以进一步分析训练数据或模型配置。")]),t._v(" "),s("h3",{attrs:{id:"_25-10-03-号补充"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_25-10-03-号补充"}},[t._v("#")]),t._v(" 25.10.03 号补充，")]),t._v(" "),s("h4",{attrs:{id:"learning-rate-这个参数如何配置"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#learning-rate-这个参数如何配置"}},[t._v("#")]),t._v(" learning_rate 这个参数如何配置")]),t._v(" "),s("p",[s("strong",[t._v("可以配置为 3e-3，但通常不推荐！")]),t._v(" 这个学习率对于NER任务来说可能太高了。")]),t._v(" "),s("blockquote",[s("p",[t._v("对于NER任务的微调，推荐的学习率范围：")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 推荐范围")]),t._v("\nlearning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e-4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 比较安全，收敛稳定")]),t._v("\nlearning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5e-5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 更保守，适合小数据集")]),t._v("\nlearning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2e-4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 稍大，收敛更快但可能不稳定")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 不推荐")]),t._v("\nlearning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3e-3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 可能过大，容易震荡/发散")]),t._v("\nlearning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e-3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 较大，需要谨慎使用")]),t._v("\n")])])]),s("h2",{attrs:{id:"不同学习率的影响"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#不同学习率的影响"}},[t._v("#")]),t._v(" 不同学习率的影响")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1. 安全选择")]),t._v("\nTrainingArguments"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("learning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e-4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ✅ 推荐")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2. 激进选择（有风险）")]),t._v("\nTrainingArguments"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("learning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3e-3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ⚠️ 需谨慎")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3. 保守选择  ")]),t._v("\nTrainingArguments"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("learning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5e-5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ✅ 小数据集推荐")]),t._v("\n")])])]),s("h2",{attrs:{id:"为什么-3e-3-可能有问题"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#为什么-3e-3-可能有问题"}},[t._v("#")]),t._v(" 为什么 3e-3 可能有问题")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 观察训练过程中的现象：")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 学习率 1e-4 (正常):")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Epoch 1: loss=2.1 → 1.5 → 1.2 → 1.0 → 0.8 (稳定下降)")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Epoch 2: loss=0.7 → 0.6 → 0.5 → 0.4 → 0.3")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 学习率 3e-3 (可能的问题):")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Epoch 1: loss=2.1 → 0.8 → 1.5 → 0.3 → 2.0 (震荡)")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Epoch 2: loss=1.8 → 0.1 → 3.2 → ... (可能发散)")]),t._v("\n")])])]),s("h2",{attrs:{id:"建议的学习率策略"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#建议的学习率策略"}},[t._v("#")]),t._v(" 建议的学习率策略")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 方案1：标准配置")]),t._v("\nTrainingArguments"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  learning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e-4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 安全选择")]),t._v("\n  lr_scheduler_type"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"linear"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 线性衰减")]),t._v("\n  warmup_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("          "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 学习率热身")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 方案2：如果你想尝试更大学习率")]),t._v("\nTrainingArguments"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  learning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5e-4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 比3e-3小一个数量级")]),t._v("\n  lr_scheduler_type"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"cosine"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 余弦衰减更平滑")]),t._v("\n  warmup_ratio"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("          "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 10%的训练步数用于热身")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 方案3：学习率搜索")]),t._v("\nTrainingArguments"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  learning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3e-4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 折中方案")]),t._v("\n  lr_scheduler_type"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"linear"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  warmup_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h2",{attrs:{id:"实际建议"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#实际建议"}},[t._v("#")]),t._v(" 实际建议")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 根据你的数据量调整：")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 小数据集 (< 1000样本)")]),t._v("\nTrainingArguments"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("learning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5e-5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 中等数据集 (1000-5000样本)  ")]),t._v("\nTrainingArguments"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("learning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e-4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ✅ 推荐")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 大数据集 (> 5000样本)")]),t._v("\nTrainingArguments"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("learning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2e-4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果你想实验 3e-3")]),t._v("\nTrainingArguments"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  learning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3e-3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ⚠️ 高风险")]),t._v("\n  max_grad_norm"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 梯度裁剪很重要！")]),t._v("\n  warmup_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("200")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("          "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 更长的热身")]),t._v("\n  lr_scheduler_type"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"cosine"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用平滑的调度器")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h2",{attrs:{id:"监控建议"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#监控建议"}},[t._v("#")]),t._v(" 监控建议")]),t._v(" "),s("p",[t._v("如果你坚持使用 3e-3，请密切监控：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 观察这些指标：")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" 训练损失是否稳定下降（不是震荡）\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" 验证集性能是否提升\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" 梯度范数是否爆炸（grad_norm "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v("）\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" 学习率调度是否正常\n")])])]),s("p",[s("strong",[t._v("总结")]),t._v("：从 "),s("code",[t._v("1e-4")]),t._v(" 开始比较安全，如果想尝试更大学习率，建议先用 "),s("code",[t._v("5e-4")]),t._v(" 或 "),s("code",[t._v("1e-3")]),t._v(" 测试，而不是直接跳到 "),s("code",[t._v("3e-3")]),t._v("。")]),t._v(" "),s("h3",{attrs:{id:"针对ner任务-配置的训练参数"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#针对ner任务-配置的训练参数"}},[t._v("#")]),t._v(" 针对NER任务，配置的训练参数")]),t._v(" "),s("p",[t._v("你的训练参数配置整体不错，但有几个可以优化的地方。让我帮你分析一下：")]),t._v(" "),s("h2",{attrs:{id:"当前配置分析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#当前配置分析"}},[t._v("#")]),t._v(" 当前配置分析")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("training_args "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" TrainingArguments"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  output_dir"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"./qwen-ner"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  overwrite_output_dir"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  num_train_epochs"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  per_device_train_batch_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  per_device_eval_batch_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  evaluation_strategy"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"steps"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  save_strategy"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"steps"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  eval_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  save_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  logging_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  learning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e-4")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h2",{attrs:{id:"建议的优化配置"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#建议的优化配置"}},[t._v("#")]),t._v(" 建议的优化配置")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("training_args "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" TrainingArguments"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    output_dir"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"./qwen-ner"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    overwrite_output_dir"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    num_train_epochs"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    per_device_train_batch_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    per_device_eval_batch_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 评估和保存策略")]),t._v("\n    evaluation_strategy"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"steps"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    save_strategy"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"steps"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n    eval_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    save_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 日志和监控")]),t._v("\n    logging_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    logging_dir"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"./logs"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 新增：指定日志目录")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 优化器相关")]),t._v("\n    learning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e-4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    lr_scheduler_type"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"linear"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 新增：学习率调度器")]),t._v("\n    warmup_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("           "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 新增：学习率热身")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 训练稳定性")]),t._v("\n    max_grad_norm"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("          "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 新增：梯度裁剪")]),t._v("\n    dataloader_pin_memory"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 新增：避免内存问题")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 模型保存")]),t._v("\n    save_total_limit"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 新增：只保存最后3个checkpoint")]),t._v("\n    load_best_model_at_end"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 新增：训练结束时加载最佳模型")]),t._v("\n    metric_for_best_model"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"eval_loss"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 新增：选择最佳模型的指标")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 内存优化")]),t._v("\n    gradient_accumulation_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 可根据需要调整")]),t._v("\n    fp16"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果GPU支持可以设为True")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h2",{attrs:{id:"关键改进点说明"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#关键改进点说明"}},[t._v("#")]),t._v(" 关键改进点说明")]),t._v(" "),s("h3",{attrs:{id:"_1-学习率调度和热身"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-学习率调度和热身"}},[t._v("#")]),t._v(" 1. "),s("strong",[t._v("学习率调度和热身")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("lr_scheduler_type"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"linear"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 学习率线性衰减")]),t._v("\nwarmup_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("           "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 前100步慢慢提升学习率")]),t._v("\n")])])]),s("p",[s("strong",[t._v("作用")]),t._v("：让训练更稳定，避免初期震荡")]),t._v(" "),s("h3",{attrs:{id:"_2-训练稳定性"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-训练稳定性"}},[t._v("#")]),t._v(" 2. "),s("strong",[t._v("训练稳定性")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("max_grad_norm"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 梯度裁剪，防止梯度爆炸")]),t._v("\n")])])]),s("h3",{attrs:{id:"_3-模型保存优化"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-模型保存优化"}},[t._v("#")]),t._v(" 3. "),s("strong",[t._v("模型保存优化")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("save_total_limit"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 避免磁盘空间浪费")]),t._v("\nload_best_model_at_end"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 自动选择最佳模型")]),t._v("\nmetric_for_best_model"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"eval_loss"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 根据验证损失选择")]),t._v("\n")])])]),s("h3",{attrs:{id:"_4-根据你的数据量调整频率"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-根据你的数据量调整频率"}},[t._v("#")]),t._v(" 4. "),s("strong",[t._v("根据你的数据量调整频率")])]),t._v(" "),s("p",[t._v("如果你的数据集较小（比如只有几百个样本）：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("eval_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 更频繁的评估")]),t._v("\nsave_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 更频繁的保存")]),t._v("\nlogging_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 更频繁的日志")]),t._v("\n")])])]),s("p",[t._v("如果你的数据集较大（几千个样本）：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("eval_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("     "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 减少评估频率")]),t._v("\nsave_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("     "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 减少保存频率")]),t._v("\nlogging_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 减少日志频率")]),t._v("\n")])])]),s("h2",{attrs:{id:"完整推荐配置"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#完整推荐配置"}},[t._v("#")]),t._v(" 完整推荐配置")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("training_args "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" TrainingArguments"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  output_dir"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"./qwen-ner"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  overwrite_output_dir"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  num_train_epochs"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  per_device_train_batch_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  per_device_eval_batch_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  \n  evaluation_strategy"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"steps"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  save_strategy"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"steps"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  eval_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  save_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  logging_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  logging_dir"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"./logs"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  \n  learning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e-4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  lr_scheduler_type"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"linear"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  warmup_steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  max_grad_norm"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  \n  save_total_limit"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  load_best_model_at_end"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  metric_for_best_model"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"eval_loss"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  \n  dataloader_pin_memory"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  report_to"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 禁用wandb等记录器，如果你不需要的话")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h2",{attrs:{id:"监控训练的建议"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#监控训练的建议"}},[t._v("#")]),t._v(" 监控训练的建议")]),t._v(" "),s("p",[t._v("训练时关注这些指标：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 健康训练的迹象：")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" 训练损失稳定下降（不是剧烈震荡）\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" 验证损失也在下降或保持稳定\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" 没有出现NaN或inf\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" 学习率按预期衰减\n")])])]),s("p",[t._v("你的原始配置已经不错，加上这些改进会让训练更稳定和高效！")])])}),[],!1,null,null,null);s.default=e.exports}}]);