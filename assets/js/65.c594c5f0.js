(window.webpackJsonp=window.webpackJsonp||[]).push([[65],{508:function(t,s,a){"use strict";a.r(s);var n=a(3),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"automodelfortokenclassification-参数作用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#automodelfortokenclassification-参数作用"}},[t._v("#")]),t._v(" AutoModelForTokenClassification 参数作用")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1. 加载模型和tokenizer")]),t._v("\nmodel "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AutoModelForTokenClassification"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_pretrained"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  model_checkpoint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  id2label"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("id2label"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  label2id"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("label2id\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#这一步为什么要制定： id2label  和  label2id 呢， 作用是什么")]),t._v("\n")])])]),s("p",[t._v("指定 "),s("code",[t._v("id2label")]),t._v(" 和 "),s("code",[t._v("label2id")]),t._v(" 非常重要，主要有以下几个作用：")]),t._v(" "),s("h2",{attrs:{id:"_1-模型输出配置"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-模型输出配置"}},[t._v("#")]),t._v(" 1. "),s("strong",[t._v("模型输出配置")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 告诉模型每个输出位置对应什么实体类型")]),t._v("\nmodel "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AutoModelForTokenClassification"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_pretrained"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  model_checkpoint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  id2label"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("id2label"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# {0: 'O', 1: 'B-中医治则', 2: 'I-中医治则', ...}")]),t._v("\n  label2id"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("label2id   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# {'O': 0, 'B-中医治则': 1, 'I-中医治则': 2, ...}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("这样模型就知道：")]),t._v(" "),s("ul",[s("li",[t._v("分类头有 21 个输出神经元（对应你的21个标签）")]),t._v(" "),s("li",[t._v("第0个输出对应 'O'（非实体）")]),t._v(" "),s("li",[t._v("第1个输出对应 'B-中医治则'")]),t._v(" "),s("li",[t._v("第2个输出对应 'I-中医治则'")]),t._v(" "),s("li",[t._v("等等...")])]),t._v(" "),s("h2",{attrs:{id:"_2-损失函数计算"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-损失函数计算"}},[t._v("#")]),t._v(" 2. "),s("strong",[t._v("损失函数计算")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 在训练时，模型需要知道如何计算损失")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 你的标签: [0, 0, 0, 11, 12, ...]  # 对应 ['O','O','O','B-临床表现','I-临床表现',...]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 模型输出: [batch_size, seq_len, num_labels] = [4, 512, 21]")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 损失函数通过 label2id 映射知道如何对齐")]),t._v("\nloss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cross_entropy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model_outputs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h2",{attrs:{id:"_3-预测结果解码"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-预测结果解码"}},[t._v("#")]),t._v(" 3. "),s("strong",[t._v("预测结果解码")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 推理时，模型输出数字，需要转换回标签")]),t._v("\npredictions "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("input_ids"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# predictions.shape: [batch_size, seq_len, 21]")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 取每个位置概率最大的标签ID")]),t._v("\npredicted_ids "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("argmax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("predictions"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("logits"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dim"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# predicted_ids: tensor([[0, 0, 0, 11, 12, ...]])")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用 id2label 解码为可读标签")]),t._v("\npredicted_labels "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("id2label"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("id")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" predicted_ids"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ['O', 'O', 'O', 'B-临床表现', 'I-临床表现', ...]")]),t._v("\n")])])]),s("h2",{attrs:{id:"_4-模型保存和加载"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-模型保存和加载"}},[t._v("#")]),t._v(" 4. "),s("strong",[t._v("模型保存和加载")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 模型会保存这些映射，下次加载时自动知道标签体系")]),t._v("\nmodel"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("save_pretrained"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"./my-ner-model"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 保存的配置中包含 id2label 和 label2id")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 下次加载时无需再次指定")]),t._v("\nmodel "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AutoModelForTokenClassification"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_pretrained"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"./my-ner-model"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 模型自动知道标签映射")]),t._v("\n")])])]),s("h2",{attrs:{id:"_5-验证配置正确性"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5-验证配置正确性"}},[t._v("#")]),t._v(" 5. "),s("strong",[t._v("验证配置正确性")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 你可以检查模型是否正确配置")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"模型分类头数量: ')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("num_labels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 应该是 21")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"模型标签映射: ')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("config"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("id2label"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出示例:")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 模型分类头数量: 21")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 模型标签映射: {0: 'O', 1: 'B-中医治则', 2: 'I-中医治则', ...}")]),t._v("\n")])])]),s("h2",{attrs:{id:"_6-实际训练中的使用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_6-实际训练中的使用"}},[t._v("#")]),t._v(" 6. "),s("strong",[t._v("实际训练中的使用")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 在你的训练循环中")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" batch "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" train_dataloader"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  input_ids "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" batch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'input_ids'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  attention_mask "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" batch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'attention_mask'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  labels "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" batch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'labels'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 这些是数字ID: [0, 0, 0, 11, 12, ...]")]),t._v("\n  \n  outputs "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("input_ids"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" attention_mask"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("attention_mask"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("labels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  loss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" outputs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("loss\n  \n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 模型内部使用 label2id 和 id2label 来:")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1. 理解输入标签的含义")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2. 计算正确的损失")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3. 生成有意义的预测结果")]),t._v("\n")])])]),s("h2",{attrs:{id:"如果不指定会怎样"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#如果不指定会怎样"}},[t._v("#")]),t._v(" 如果不指定会怎样？")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果不指定，模型会使用默认配置")]),t._v("\nmodel "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AutoModelForTokenClassification"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_pretrained"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model_checkpoint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"默认标签数量: ')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("num_labels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 通常是 2 (比如用于二分类)")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"默认标签映射: ')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("config"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("id2label"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# {0: 'LABEL_0', 1: 'LABEL_1'}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# id2label: {0: 'LABEL_0', 1: 'LABEL_1', 2: 'LABEL_2', 3: 'LABEL_3', 4: 'LABEL_4', 5: 'LABEL_5'}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# label2id: {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2, 'LABEL_3': 3, 'LABEL_4': 4, 'LABEL_5': 5}")]),t._v("\n\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 这样会导致:")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1. 模型输出维度与你的标签数量不匹配")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2. 无法正确理解你的标签含义")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3. 预测结果无法解码为有意义的实体类型")]),t._v("\n")])])]),s("p",[s("strong",[t._v("总结")]),t._v("：指定 "),s("code",[t._v("id2label")]),t._v(" 和 "),s("code",[t._v("label2id")]),t._v(" 是让模型理解你的具体NER任务设置，包括要识别哪些实体类型、如何计算损失、如何解码预测结果。这是微调成功的关键配置。")])])}),[],!1,null,null,null);s.default=e.exports}}]);