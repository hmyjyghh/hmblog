(window.webpackJsonp=window.webpackJsonp||[]).push([[200],{643:function(t,s,a){"use strict";a.r(s);var n=a(3),r=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"_1-pydantic"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-pydantic"}},[t._v("#")]),t._v(" 1. pydantic")]),t._v(" "),s("h3",{attrs:{id:"_1-from-pydantic-import-basemodel-field"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-from-pydantic-import-basemodel-field"}},[t._v("#")]),t._v(" 1. from pydantic import BaseModel, Field")]),t._v(" "),s("p",[t._v("在 Pydantic 库中，BaseModel 和 Field 是两个核心组件，主要用于数据验证、数据建模和设置字段约束，以下是它们的具体作用：")]),t._v(" "),s("ol",[s("li",[t._v("BaseModel 的作用\nBaseModel 是 Pydantic 中所有数据模型的基类，所有自定义的数据模型都需要继承它。它的核心功能包括：")])]),t._v(" "),s("h2",{attrs:{id:"_2-sklearn"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-sklearn"}},[t._v("#")]),t._v(" 2. sklearn")]),t._v(" "),s("p",[t._v("scikit-learn（简称sklearn）是Python中最流行的机器学习库之一，它建立在NumPy、SciPy和matplotlib等科学计算库之上，提供了一系列简单易用的工具，帮助开发者快速实现各种机器学习算法和数据预处理任务。")]),t._v(" "),s("p",[t._v("它的核心功能包括：")]),t._v(" "),s("ol",[s("li",[s("p",[s("strong",[t._v("丰富的算法支持")]),t._v("：")]),t._v(" "),s("ul",[s("li",[t._v("分类算法（如逻辑回归、决策树、随机森林、SVM、KNN等）")]),t._v(" "),s("li",[t._v("回归算法（如线性回归、岭回归、Lasso回归、随机森林回归等）")]),t._v(" "),s("li",[t._v("聚类算法（如K-Means、DBSCAN等）")]),t._v(" "),s("li",[t._v("降维算法（如PCA、t-SNE等）")])])]),t._v(" "),s("li",[s("p",[s("strong",[t._v("数据预处理工具")]),t._v("：")]),t._v(" "),s("ul",[s("li",[t._v("数据标准化、归一化")]),t._v(" "),s("li",[t._v("缺失值处理")]),t._v(" "),s("li",[t._v("特征选择与转换")]),t._v(" "),s("li",[t._v("数据分割（训练集/测试集拆分）")])])]),t._v(" "),s("li",[s("p",[s("strong",[t._v("模型评估工具")]),t._v("：")]),t._v(" "),s("ul",[s("li",[t._v("提供各种评估指标（准确率、精确率、召回率、F1分数、均方误差等）")]),t._v(" "),s("li",[t._v("交叉验证功能")]),t._v(" "),s("li",[t._v("模型调参工具（网格搜索、随机搜索）")])])]),t._v(" "),s("li",[s("p",[s("strong",[t._v("实用工具")]),t._v("：")]),t._v(" "),s("ul",[s("li",[t._v("数据集加载（内置多个经典数据集，如鸢尾花、波士顿房价等）")]),t._v(" "),s("li",[t._v("模型持久化（保存和加载训练好的模型）")])])])]),t._v(" "),s("p",[t._v("在你提供的代码中，sklearn被用于：")]),t._v(" "),s("ul",[s("li",[t._v("分割训练集和测试集（"),s("code",[t._v("train_test_split")]),t._v("）")]),t._v(" "),s("li",[t._v("训练随机森林分类器（"),s("code",[t._v("RandomForestClassifier")]),t._v("）")]),t._v(" "),s("li",[t._v("计算模型准确率（"),s("code",[t._v("accuracy_score")]),t._v("）")])]),t._v(" "),s("p",[t._v("scikit-learn的优势在于API设计一致、文档完善、易于上手，非常适合机器学习初学者和快速原型开发。它的代码示例通常像这样：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ensemble "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" RandomForestClassifier\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model_selection "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" train_test_split\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("metrics "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" accuracy_score\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 分割数据")]),t._v("\nX_train"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" X_test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_train"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_test "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" train_test_split"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" test_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 训练模型")]),t._v("\nmodel "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RandomForestClassifier"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_train"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_train"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 预测与评估")]),t._v("\ny_pred "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"准确率:"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" accuracy_score"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_pred"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("总之，scikit-learn是机器学习工程中处理经典机器学习任务的必备工具之一。")]),t._v(" "),s("h2",{attrs:{id:"_3-pandas-库的使用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-pandas-库的使用"}},[t._v("#")]),t._v(" 3. pandas 库的使用")]),t._v(" "),s("h3",{attrs:{id:"场景一"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#场景一"}},[t._v("#")]),t._v(" 场景一:")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"./dataset/Fraud_News_Reports/冒充客服诈骗(200).csv"')]),t._v("\ndataset "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ndataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("head"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" 这个head"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" 的作用是读取前"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("条数据\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" 默认显示前"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("行数据\n\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" 包含表头（列名）\n\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" 快速预览数据的结构和内容\n")])])]),s("h3",{attrs:{id:"场景二"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#场景二"}},[t._v("#")]),t._v(" 场景二:")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 示例数据")]),t._v("\nrows "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'张三'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'北京'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'李四'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'上海'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'王五'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("28")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'广州'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 第一次写入（带表头）")]),t._v("\ndf1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DataFrame"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rows"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" columns"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'姓名'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'年龄'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'城市'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndf1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" mode"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'w'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" header"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" index"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 文件内容：")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 姓名,年龄,城市")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 张三,25,北京")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 李四,30,上海")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 王五,28,广州")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 追加写入（不带表头）")]),t._v("\nnew_rows "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'赵六'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("35")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'深圳'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'钱七'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("26")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'杭州'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\ndf2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DataFrame"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("new_rows"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndf2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" mode"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'a'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" header"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" index"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 文件内容：")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 姓名,年龄,城市")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 张三,25,北京")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 李四,30,上海")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 王五,28,广州")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 赵六,35,深圳")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 钱七,26,杭州")]),t._v("\n")])])]),s("h3",{attrs:{id:"场景三"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#场景三"}},[t._v("#")]),t._v(" 场景三")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" row "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" sliced_data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("iterrows"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"循环中的 i=')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 只会输出一次: i=1")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"write dialog count: ')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出: write dialog count: 2")]),t._v("\n\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 我还是不明白，这里的 i  为什么是1    不应该是 0 吗")]),t._v("\n")])])]),s("p",[t._v("这是一个很好的问题！原因在于 "),s("code",[t._v("iterrows() 方法")]),t._v("返回的是原始DataFrame的索引，"),s("code",[t._v("而不是从0开始的重新编号")]),t._v("。")]),t._v(" "),s("p",[s("a",{attrs:{href:"https://www.cnblogs.com/beichengshiqiao/p/18372937",target:"_blank",rel:"noopener noreferrer"}},[t._v("可参考"),s("OutboundLink")],1)]),t._v(" "),s("h2",{attrs:{id:"_4-json-库的使用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-json-库的使用"}},[t._v("#")]),t._v(" 4. json 库的使用")]),t._v(" "),s("ul",[s("li",[t._v("json.dumps (obj)：Python 对象 → JSON 字符串")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" json\n\njson"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dumps"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("obj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" indent"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ensure_ascii"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1. 检查是否可以序列化为标准 JSON")]),t._v("\njson_str "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" json"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dumps"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("test_result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ensure_ascii"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"标准JSON格式:"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" json_str"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# json.dump (obj, fp)：Python 对象 → 直接写入文件")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 常见场景：直接将 JSON 数据保存到文件（如配置文件、数据集存储），简化文件写入流程。")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2. 检查是否可以保存到文件并读取")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'test_output.json'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'w'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" encoding"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'utf-8'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n   json"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dump"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("test_result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ensure_ascii"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" indent"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'test_output.json'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'r'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" encoding"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'utf-8'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n   file_content "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" json"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"从文件读取的内容:"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" file_content"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"_2-json-loads"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-json-loads"}},[t._v("#")]),t._v(" 2. "),s("code",[t._v("json.loads()")])]),t._v(" "),s("ul",[s("li",[t._v("把字符串格式的JSON数据 → 转换成真正的Python对象")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" json\njson"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("loads"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cleaned_result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ndata "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" json"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("loads"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cleaned_result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'result'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'speaker'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 王强")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'result'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'is_fraud'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# True")]),t._v("\n\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 转换后")]),t._v("\npython_dict "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" json"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("loads"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("json_str"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Python字典:"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" python_dict"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 显示单引号，但这是Python的显示方式")]),t._v("\n")])])]),s("ul",[s("li",[t._v("会把双引号变为单引号")]),t._v(" "),s("li",[t._v("会把true/false，变为python 中的 True/False, 注意：true → True")])]),t._v(" "),s("p",[s("img",{attrs:{src:"/hmblog/images/python/json-loads.png",alt:"json.loads()的作用"}})]),t._v(" "),s("p",[s("strong",[t._v("还可以讲生成的json 数据，保存到json文件中")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2. 检查是否可以保存到文件并读取")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'test_output.json'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'w'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" encoding"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'utf-8'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n   json"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dump"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ensure_ascii"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" indent"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h2",{attrs:{id:"_5-re-库的使用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5-re-库的使用"}},[t._v("#")]),t._v(" 5. re 库的使用")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("remove_markdown_boundary")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("text"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" re"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sub"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("r'^```json\\n(.*)\\n```$'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("r'\\1'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" text"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("strip"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" flags"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("re"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DOTALL"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("ul",[s("li",[t._v("这个函数的作用")])]),t._v(" "),s("div",{staticClass:"language-Text extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("\n它做的事情：\n1. **识别模式**：找到以 ````json` 开头和以 ```` 结尾的文本块\n2. **提取内容**：只保留中间的实际JSON内容\n3. **去掉空白**：顺便清理一下前后的空格\n\n## 正则表达式分解\n\n```python\nr'^```json\\n(.*)\\n```$'\n")])])]),s("p",[s("code",[t._v("re")]),t._v(" 是 Python 的"),s("strong",[t._v("正则表达式（Regular Expression）库")]),t._v("，用于进行"),s("strong",[t._v("字符串匹配、搜索和替换")]),t._v("等高级文本处理操作。")]),t._v(" "),s("h2",{attrs:{id:"re-findall-函数详解"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#re-findall-函数详解"}},[t._v("#")]),t._v(" re.findall() 函数详解")]),t._v(" "),s("h3",{attrs:{id:"基本语法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#基本语法"}},[t._v("#")]),t._v(" 基本语法")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("re"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("findall"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pattern"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" string"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("ul",[s("li",[t._v("在字符串中查找"),s("strong",[t._v("所有")]),t._v("匹配正则表达式的部分")]),t._v(" "),s("li",[t._v("返回包含所有匹配项的"),s("strong",[t._v("列表")])])]),t._v(" "),s("h3",{attrs:{id:"您的代码分析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#您的代码分析"}},[t._v("#")]),t._v(" 您的代码分析")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("all_cites "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" re"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("findall"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"[【](.*?)[】]"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" response"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h4",{attrs:{id:"正则表达式分解"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#正则表达式分解"}},[t._v("#")]),t._v(" 正则表达式分解：")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("[【]")]),t._v(" - 匹配左括号 "),s("code",[t._v("【")])]),t._v(" "),s("li",[s("code",[t._v("(.*?)")]),t._v(" - "),s("strong",[t._v("捕获组")]),t._v("：匹配任意字符（除换行外）0次或多次，"),s("strong",[t._v("非贪婪模式")])]),t._v(" "),s("li",[s("code",[t._v("[】]")]),t._v(" - 匹配右括号 "),s("code",[t._v("】")])])]),t._v(" "),s("h4",{attrs:{id:"匹配示例"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#匹配示例"}},[t._v("#")]),t._v(" 匹配示例：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("response "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"这是一个例子【引用1】，另一个例子【引用2】，最后【引用3】"')]),t._v("\nall_cites "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" re"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("findall"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"[【](.*?)[】]"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" response"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("all_cites"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出: ['引用1', '引用2', '引用3']")]),t._v("\n")])])]),s("h2",{attrs:{id:"re-库其他常用函数"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#re-库其他常用函数"}},[t._v("#")]),t._v(" re 库其他常用函数")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" re\n\ntext "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"我的电话是123-4567，另一个电话是890-1234"')]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1. re.search() - 查找第一个匹配")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("match")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" re"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("search"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('r"\\d{3}-\\d{4}"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" text"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("match")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("match")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("group"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出: 123-4567")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2. re.match() - 从字符串开头匹配")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("match")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" re"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("match")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('r"\\d{3}-\\d{4}"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" text"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("match")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出: None (因为不是以电话号码开头)")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3. re.sub() - 替换匹配内容")]),t._v("\nnew_text "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" re"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sub"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('r"\\d{3}-\\d{4}"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"XXX-XXXX"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" text"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("new_text"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 输出: "我的电话是XXX-XXXX，另一个电话是XXX-XXXX"')]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 3.1 re.sub("[{} 【】]", "", cite)')]),t._v("\n\ncite "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"【Smith2020】"')]),t._v("\nresult "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" re"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sub"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"[{} 【】]"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cite"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 输出: "Smith2020"')]),t._v("\n\n功能：删除字符串 cite 中所有的花括号、方括号和空格字符。\n\n\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 4. re.split() - 按模式分割")]),t._v("\nparts "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" re"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('r"\\d+"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a1b22c333d"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("parts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出: ['a', 'b', 'c', 'd']")]),t._v("\n")])])]),s("h2",{attrs:{id:"在您代码中的应用场景"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#在您代码中的应用场景"}},[t._v("#")]),t._v(" 在您代码中的应用场景")]),t._v(" "),s("p",[t._v("您的代码很可能是用于"),s("strong",[t._v("提取引用或标注")]),t._v("：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 从文本中提取所有被【】括起来的内容")]),t._v("\nresponse "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"根据研究【Smith2020】，这个方法很有效。另外【Johnson2019】也支持这个观点。"')]),t._v("\ncitations "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" re"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("findall"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"[【](.*?)[】]"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" response"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("citations"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出: ['Smith2020', 'Johnson2019']")]),t._v("\n")])])]),s("h2",{attrs:{id:"正则表达式符号说明"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#正则表达式符号说明"}},[t._v("#")]),t._v(" 正则表达式符号说明")]),t._v(" "),s("ul",[s("li",[s("code",[t._v(".")]),t._v(" - 匹配任意字符（除换行）")]),t._v(" "),s("li",[s("code",[t._v("*")]),t._v(" - 前一个字符0次或多次")]),t._v(" "),s("li",[s("code",[t._v("*?")]),t._v(" - "),s("strong",[t._v("非贪婪模式")]),t._v("，匹配尽可能少的字符")]),t._v(" "),s("li",[s("code",[t._v("[ ]")]),t._v(" - 字符集，匹配括号内任意字符")]),t._v(" "),s("li",[s("code",[t._v("( )")]),t._v(" - 捕获组，提取匹配的内容")])]),t._v(" "),s("p",[t._v("您的代码高效地从文本中提取了所有被 "),s("code",[t._v("【】")]),t._v(" 包围的引用内容！")]),t._v(" "),s("h3",{attrs:{id:"注意-优先练习大模型应用开发中常用到的-其他的后面再慢慢学"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#注意-优先练习大模型应用开发中常用到的-其他的后面再慢慢学"}},[t._v("#")]),t._v(" 注意，优先练习大模型应用开发中常用到的，其他的后面再慢慢学")]),t._v(" "),s("h2",{attrs:{id:"_5-tqdm"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5-tqdm"}},[t._v("#")]),t._v(" 5. tqdm")]),t._v(" "),s("p",[s("code",[t._v("tqdm")]),t._v(" 是一个 Python 库，用于在程序运行过程中显示进度条，直观地展示任务的执行进度，让用户了解任务完成的程度以及预估剩余时间等信息。它适用于各种迭代操作，如循环遍历列表、读取文件、执行多步计算任务等场景。")]),t._v(" "),s("h3",{attrs:{id:"主要特点"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#主要特点"}},[t._v("#")]),t._v(" 主要特点")]),t._v(" "),s("ol",[s("li",[s("strong",[t._v("使用简单")]),t._v("：只需对普通的迭代对象（如 "),s("code",[t._v("list")]),t._v("、"),s("code",[t._v("range")]),t._v(" 等）进行简单的包装，就能自动生成进度条。")]),t._v(" "),s("li",[s("strong",[t._v("多种模式")]),t._v("：支持多种迭代场景，不仅可以用于普通的 "),s("code",[t._v("for")]),t._v(" 循环，还能与 "),s("code",[t._v("pandas")]),t._v("、"),s("code",[t._v("numpy")]),t._v(" 等库配合使用，以及在多线程、多进程任务中展示进度。")]),t._v(" "),s("li",[s("strong",[t._v("自定义性强")]),t._v("：可以自定义进度条的颜色、格式、显示内容等，以满足不同的需求。")]),t._v(" "),s("li",[s("strong",[t._v("跨平台")]),t._v("：兼容 Windows、Linux、macOS 等主流操作系统。")])]),t._v(" "),s("h3",{attrs:{id:"常见用法示例"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#常见用法示例"}},[t._v("#")]),t._v(" 常见用法示例")]),t._v(" "),s("ol",[s("li",[s("strong",[t._v("基本使用")]),t._v("：在普通的 "),s("code",[t._v("for")]),t._v(" 循环中显示进度条。")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" tqdm "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" tqdm\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" time\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 模拟一个耗时任务，循环 10 次")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" tqdm"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    time"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sleep"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 模拟每次循环耗时 1 秒")]),t._v("\n")])])]),s("p",[t._v("运行上述代码，在控制台会看到一个动态更新的进度条，显示任务的完成百分比、已用时间、预计剩余时间等信息。")]),t._v(" "),s("ol",{attrs:{start:"2"}},[s("li",[s("strong",[t._v("结合列表遍历")]),t._v("：")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" tqdm "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" tqdm\nmy_list "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" element "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" tqdm"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("my_list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 这里可以执行对 element 的操作，比如打印")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("element"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("这样在遍历列表的过程中，会实时显示进度条，帮助了解列表遍历的进度情况。")]),t._v(" "),s("ol",{attrs:{start:"3"}},[s("li",[s("strong",[t._v("自定义进度条格式")]),t._v("：")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" tqdm "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" tqdm\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" time\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 自定义进度条格式，只显示完成百分比和剩余时间")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" tqdm"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bar_format"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'{percentage:3.0f}%|{bar}| {remaining}'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    time"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sleep"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("通过 "),s("code",[t._v("bar_format")]),t._v(" 参数，可以灵活定制进度条显示的内容，比如显示已处理的数量、总数量、进度条的长度等。")]),t._v(" "),s("ol",{attrs:{start:"4"}},[s("li",[s("strong",[t._v("在多线程或多进程任务中使用")]),t._v("："),s("code",[t._v("tqdm")]),t._v(" 也可以与 "),s("code",[t._v("concurrent.futures")]),t._v(" 库配合，在多线程或多进程任务中展示进度条。以下是多线程的示例：")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" concurrent"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("futures\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" tqdm "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" tqdm\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" time\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("task")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    time"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sleep"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" x "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" x\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" concurrent"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("futures"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ThreadPoolExecutor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" executor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    results "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tqdm"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("executor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("map")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("task"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" total"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("在多线程执行任务时，通过 "),s("code",[t._v("tqdm")]),t._v(" 可以实时看到任务的整体完成进度。")]),t._v(" "),s("h3",{attrs:{id:"应用场景"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#应用场景"}},[t._v("#")]),t._v(" 应用场景")]),t._v(" "),s("ol",[s("li",[s("strong",[t._v("数据处理")]),t._v("：在处理大量数据（如读取大文件、清洗数据、特征工程等）时，显示处理进度，避免用户长时间等待却不知道程序是否在正常运行。")]),t._v(" "),s("li",[s("strong",[t._v("机器学习训练")]),t._v("：在训练模型的过程中，展示训练轮次的进度，帮助开发者了解模型训练的状态。")]),t._v(" "),s("li",[s("strong",[t._v("网络请求")]),t._v("：当需要发送大量网络请求（如爬取网页数据）时，使用 "),s("code",[t._v("tqdm")]),t._v(" 可以实时看到请求的完成情况。")])]),t._v(" "),s("h2",{attrs:{id:"_6-pickle-库的主要作用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_6-pickle-库的主要作用"}},[t._v("#")]),t._v(" 6. pickle 库的主要作用")]),t._v(" "),s("p",[t._v("核心功能：保存 Python 对象到文件，以及从文件恢复 Python 对象。")]),t._v(" "),s("p",[s("code",[t._v("pickle")]),t._v(" 是 Python 的"),s("strong",[t._v("对象序列化库")]),t._v("，用于将 Python 对象转换为字节流（序列化）和从字节流重建对象（反序列化）。")]),t._v(" "),s("h3",{attrs:{id:"pickle-库的主要作用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#pickle-库的主要作用"}},[t._v("#")]),t._v(" pickle 库的主要作用")]),t._v(" "),s("p",[s("strong",[t._v("核心功能")]),t._v("：保存 Python 对象到文件，以及从文件恢复 Python 对象。")]),t._v(" "),s("h2",{attrs:{id:"dump-函数-序列化-保存"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#dump-函数-序列化-保存"}},[t._v("#")]),t._v(" dump() 函数 - 序列化（保存）")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("pickle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dump"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("raw_docs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("raw_docs_path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"wb"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[s("strong",[t._v("作用")]),t._v("：将 Python 对象序列化并写入文件")]),t._v(" "),s("p",[s("strong",[t._v("参数")]),t._v("：")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("raw_docs")]),t._v("：要保存的 Python 对象（可以是任何类型）")]),t._v(" "),s("li",[s("code",[t._v('open(raw_docs_path, "wb")')]),t._v("：以二进制写入模式打开的文件对象")])]),t._v(" "),s("p",[s("strong",[t._v("等效写法")]),t._v("（推荐）：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用 with 语句更安全（自动关闭文件）")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("raw_docs_path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"wb"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    pickle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dump"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("raw_docs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"load-函数-反序列化-加载"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#load-函数-反序列化-加载"}},[t._v("#")]),t._v(" load() 函数 - 反序列化（加载）")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("pickle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("raw_docs_path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"rb"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[s("strong",[t._v("作用")]),t._v("：从文件中读取并反序列化 Python 对象")]),t._v(" "),s("p",[s("strong",[t._v("参数")]),t._v("：")]),t._v(" "),s("ul",[s("li",[s("code",[t._v('open(raw_docs_path, "rb")')]),t._v("：以二进制读取模式打开的文件对象")])]),t._v(" "),s("p",[s("strong",[t._v("等效写法")]),t._v("（推荐）：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("raw_docs_path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"rb"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    loaded_docs "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pickle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"实际应用示例"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#实际应用示例"}},[t._v("#")]),t._v(" 实际应用示例")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pickle\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 示例数据")]),t._v("\nraw_docs "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"content"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"文档内容1"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"metadata"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"author"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Alice"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"content"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"文档内容2"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"metadata"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"author"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Bob"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"列表"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"也可以保存"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"set"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"集合"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"同样支持"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 保存对象")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"documents.pkl"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"wb"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    pickle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dump"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("raw_docs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 加载对象")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"documents.pkl"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"rb"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    loaded_docs "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pickle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loaded_docs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 与原始 raw_docs 完全一致")]),t._v("\n")])])]),s("h3",{attrs:{id:"可以-pickle-的对象类型"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#可以-pickle-的对象类型"}},[t._v("#")]),t._v(" 可以 pickle 的对象类型")]),t._v(" "),s("p",[t._v("几乎所有的 Python 对象都可以被 pickle：")]),t._v(" "),s("ul",[s("li",[t._v("✅ 基本类型："),s("code",[t._v("int")]),t._v(", "),s("code",[t._v("float")]),t._v(", "),s("code",[t._v("str")]),t._v(", "),s("code",[t._v("list")]),t._v(", "),s("code",[t._v("dict")]),t._v(", "),s("code",[t._v("set")]),t._v(", "),s("code",[t._v("tuple")])]),t._v(" "),s("li",[t._v("✅ 自定义类和对象")]),t._v(" "),s("li",[t._v("✅ 函数和类定义（需要满足特定条件）")]),t._v(" "),s("li",[t._v("✅ NumPy 数组、Pandas DataFrame 等")])]),t._v(" "),s("h2",{attrs:{id:"在您代码中的应用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#在您代码中的应用"}},[t._v("#")]),t._v(" 在您代码中的应用")]),t._v(" "),s("p",[t._v("在您的 RAG 系统中，pickle 用于：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 保存原始文档集合")]),t._v("\npickle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dump"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("raw_docs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("raw_docs_path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"wb"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 后续直接加载，无需重新处理")]),t._v("\nraw_docs "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pickle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("raw_docs_path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"rb"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h2",{attrs:{id:"优点-vs-缺点"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#优点-vs-缺点"}},[t._v("#")]),t._v(" 优点 vs 缺点")]),t._v(" "),s("p",[s("strong",[t._v("优点")]),t._v("：")]),t._v(" "),s("ul",[s("li",[t._v("使用简单，一行代码保存复杂对象")]),t._v(" "),s("li",[t._v("保持对象完整结构和类型")]),t._v(" "),s("li",[t._v("Python 原生支持，无需额外依赖")])]),t._v(" "),s("p",[s("strong",[t._v("缺点")]),t._v("：")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("安全风险")]),t._v("：可能执行恶意代码")]),t._v(" "),s("li",[s("strong",[t._v("版本兼容性")]),t._v("：不同 Python 版本可能不兼容")]),t._v(" "),s("li",[s("strong",[t._v("仅限 Python")]),t._v("：其他语言无法读取")])]),t._v(" "),s("h2",{attrs:{id:"安全提醒-⚠️"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#安全提醒-⚠️"}},[t._v("#")]),t._v(" 安全提醒 ⚠️")]),t._v(" "),s("p",[s("strong",[t._v("只加载来自可信源的 pickle 文件")]),t._v("：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 危险：不要加载不受信任的 pickle 文件")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"untrusted.pkl"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"rb"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    data "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pickle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 可能执行恶意代码")]),t._v("\n")])])]),s("p",[t._v("pickle 让数据持久化变得非常简单，是机器学习中常用的模型保存方式！")]),t._v(" "),s("h2",{attrs:{id:"_7-itertools-库的使用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_7-itertools-库的使用"}},[t._v("#")]),t._v(" 7. itertools 库的使用")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" itertools\n\nchunk_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50000")]),t._v("\nchunk "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("itertools"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("islice"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("reader"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" chunk_size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("ol",[s("li",[s("strong",[s("code",[t._v("itertools")])]),t._v("：Python 内置的工具库，专门提供高效处理迭代器/可迭代对象的函数（无需自己写循环截取数据）。")]),t._v(" "),s("li",[s("strong",[s("code",[t._v("islice")])]),t._v("：全称「iterator slice」（迭代器切片），功能是对"),s("strong",[t._v("可迭代对象做“惰性切片”")]),t._v("（不会提前加载所有数据到内存）。")]),t._v(" "),s("li",[s("strong",[s("code",[t._v("reader")])]),t._v("：这里是 "),s("code",[t._v("jsonlines.Reader")]),t._v(" 对象（读取 JSONL 文件的迭代器），特点是"),s("strong",[t._v("逐行读取数据")]),t._v("（每次迭代返回 JSONL 中的一行，解析为字典）。")]),t._v(" "),s("li",[s("strong",[s("code",[t._v("chunk_size")])]),t._v("：截取的“块大小”（比如你设的 1000），表示每次从 "),s("code",[t._v("reader")]),t._v(" 中取 "),s("code",[t._v("chunk_size")]),t._v(" 条数据。")])]),t._v(" "),s("p",[s("code",[t._v("itertools.islice(reader, chunk_size)")]),t._v(" 的核心作用是 "),s("strong",[t._v("从可迭代对象（这里是 "),s("code",[t._v("jsonlines.Reader")]),t._v("）中，按指定长度截取“一块数据”")]),t._v("，避免一次性加载全部数据（尤其适合你 31GB 的超大文件）。")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("chunk "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("itertools"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("islice"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("reader"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" chunk_size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("等价于「从 "),s("code",[t._v("jsonlines")]),t._v(" 读取器中，一次性取 "),s("code",[t._v("chunk_size")]),t._v(" 条数据（比如 1000 条），转为列表 "),s("code",[t._v("chunk")]),t._v("」，但核心优势是 "),s("strong",[t._v("惰性读取")]),t._v("：")]),t._v(" "),s("ul",[s("li",[t._v("不会把 31GB 文件的所有数据都加载到内存，只加载当前块的 1000 条；")]),t._v(" "),s("li",[t._v("读完一块处理完后，再读下一块，内存占用始终控制在小范围（这是处理超大文件的关键）。")])]),t._v(" "),s("h3",{attrs:{id:"对比-不用-islice-会怎么样"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#对比-不用-islice-会怎么样"}},[t._v("#")]),t._v(" 对比：不用 "),s("code",[t._v("islice")]),t._v(" 会怎么样？")]),t._v(" "),s("p",[t._v("如果直接写 "),s("code",[t._v("for obj in reader:")]),t._v("，会逐行读取所有数据，但你需要“按块处理”（比如每处理 1000 条打印一次进度），就需要自己写计数、判断逻辑：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 不用 islice 的等效写法（更繁琐）")]),t._v("\nchunk "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" obj "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" reader"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    chunk"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("obj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("chunk"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" chunk_size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("break")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 凑够一块就停止")]),t._v("\n")])])]),s("p",[t._v("而 "),s("code",[t._v("itertools.islice")]),t._v(" 帮你封装了这个“截取指定长度数据”的逻辑，代码更简洁、效率更高（底层是 C 实现，比纯 Python 循环快）。")]),t._v(" "),s("ul",[s("li",[t._v("控制内存占用："),s("strong",[t._v("每次只加载 1000 条数据，避免内存爆炸；")])]),t._v(" "),s("li",[t._v("提升处理效率：批量读取 + 批量处理，比逐行处理（边读边写）更快；")]),t._v(" "),s("li",[t._v("简化代码：不用自己写计数、中断逻辑，直接截取块数据。")])]),t._v(" "),s("h2",{attrs:{id:"_8-sinan"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_8-sinan"}},[t._v("#")]),t._v(" 8. sinan")]),t._v(" "),s("blockquote",[s("p",[s("code",[t._v("Sinan")]),t._v(" 是一个"),s("strong",[t._v("中文友好的智能日期解析工具类")]),t._v("，核心作用是将用户输入的非标准化日期（自然语言 / 模糊格式）"),s("strong",[t._v("转换为程序可处理的标准化日期")]),t._v("，常用于对话系统、智能表单等需要提取用户日期输入的场景。")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sinan "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Sinan\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 测试不同输入的解析结果")]),t._v("\ntest_dates "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"今天"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"明天"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"下周一"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2025/12/03"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"12月3号"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"3天后"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" date_str "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" test_dates"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    result "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Sinan"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("date_str"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"输入: ')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("date_str"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v(" → 输出: ")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v(" (类型: ")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v(')"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h2",{attrs:{id:"_9-uvicorn"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_9-uvicorn"}},[t._v("#")]),t._v(" 9. uvicorn")]),t._v(" "),s("p",[t._v("用 Uvicorn（一个高性能的 ASGI 服务器）启动 Python Web 应用（通常是 FastAPI 或 Starlette 框架开发的应用）的核心启动命令。")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" __name__ "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'__main__'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    uvicorn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("app"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" host"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'0.0.0.0'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" port"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8009")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" workers"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"fastapi"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#fastapi"}},[t._v("#")]),t._v(" FastAPI")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# main.py（你的应用主文件）")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" fastapi "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" FastAPI\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 创建 app 实例（就是 uvicorn.run() 中传入的 app）")]),t._v("\napp "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" FastAPI"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 定义接口示例")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@app"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("async")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("root")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"message"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Hello World"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=r.exports}}]);