(window.webpackJsonp=window.webpackJsonp||[]).push([[111],{553:function(t,a,s){"use strict";s.r(a);var r=s(3),e=Object(r.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h2",{attrs:{id:"transformer实战"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#transformer实战"}},[t._v("#")]),t._v(" transformer实战")]),t._v(" "),a("h3",{attrs:{id:"_1-数据集准备"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-数据集准备"}},[t._v("#")]),t._v(" 1. 数据集准备")]),t._v(" "),a("p",[t._v("要看数据集是什么格式的，进行格式化处理")]),t._v(" "),a("p",[t._v("看模型分词需要什么格式的")]),t._v(" "),a("p",[a("strong",[t._v("手撕代码，任务拆解")])]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1. 引入 torch.utils.data.Dataset 类")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("utils"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Dataset\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2. 自定义数据集类")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3. 引入的 from datasets import Dataset 类")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" datasets "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Dataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" load_dataset\n\nDataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_dict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nDataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load_from_disk"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n确定引入哪个类，来处理数据\n\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.")]),t._v(" 自定义数据集类，继承 Dataset 类，实现 __getitem__ 和 __len__ 方法。\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.")]),t._v(" 引入 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" datasets "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Dataset 类，使用 from_dict 方法或 load_from_disk 方法加载数据集。\n\n\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 4. 数据预处理")]),t._v("\n\n接着，我们就需要通过 DataLoader 库来按 batch 加载数据，并且将文本以及标签都转换为模型可以接受的输入形式。前面我们已经通过 categories 搜集了数据集中的所有实体标签，因此很容易建立标签映射字典：\n")])])]),a("h3",{attrs:{id:"_2-数据集分词"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-数据集分词"}},[t._v("#")]),t._v(" 2. 数据集分词")]),t._v(" "),a("h3",{attrs:{id:"_3-数据集处理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-数据集处理"}},[t._v("#")]),t._v(" 3. 数据集处理")]),t._v(" "),a("h3",{attrs:{id:"_4-模型训练"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-模型训练"}},[t._v("#")]),t._v(" 4. 模型训练")]),t._v(" "),a("h3",{attrs:{id:"_5-模型评估"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-模型评估"}},[t._v("#")]),t._v(" 5. 模型评估")]),t._v(" "),a("h3",{attrs:{id:"_6-模型保存"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-模型保存"}},[t._v("#")]),t._v(" 6. 模型保存")]),t._v(" "),a("h3",{attrs:{id:"_7-模型加载"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_7-模型加载"}},[t._v("#")]),t._v(" 7. 模型加载")]),t._v(" "),a("h3",{attrs:{id:"_8-模型预测"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_8-模型预测"}},[t._v("#")]),t._v(" 8. 模型预测")])])}),[],!1,null,null,null);a.default=e.exports}}]);