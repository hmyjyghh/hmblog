(window.webpackJsonp=window.webpackJsonp||[]).push([[98],{601:function(t,s,a){"use strict";a.r(s);var n=a(3),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"内置函数的使用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#内置函数的使用"}},[t._v("#")]),t._v(" 内置函数的使用")]),t._v(" "),s("p",[t._v("zip  和 enumerate")]),t._v(" "),s("p",[s("code",[t._v("zip()")]),t._v(" 和 "),s("code",[t._v("enumerate()")]),t._v(" 都是用于处理可迭代对象的内置函数，但它们的功能和使用场景有明显区别：")]),t._v(" "),s("h3",{attrs:{id:"_1-zip-函数"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-zip-函数"}},[t._v("#")]),t._v(" 1. "),s("code",[t._v("zip()")]),t._v(" 函数")]),t._v(" "),s("p",[s("strong",[t._v("功能")]),t._v("：将多个可迭代对象（如列表、元组）中对应位置的元素打包成一个个元组，返回一个迭代器。"),s("br"),t._v(" "),s("strong",[t._v("特点")]),t._v("：")]),t._v(" "),s("ul",[s("li",[t._v("接收多个可迭代对象作为参数（至少1个）。")]),t._v(" "),s("li",[t._v("返回的迭代器中，每个元素是由所有输入对象对应位置元素组成的元组。")]),t._v(" "),s("li",[t._v("当输入对象长度不一致时，以最短的对象为准，超出部分会被忽略。")]),t._v(" "),s("li",[t._v("如需查看结果，可转换为列表（"),s("code",[t._v("list()")]),t._v("）或元组（"),s("code",[t._v("tuple()")]),t._v("）。")])]),t._v(" "),s("p",[s("strong",[t._v("示例")]),t._v("：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("list1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nlist2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'a'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'b'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'c'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 打包两个列表的对应元素")]),t._v("\nzipped "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("zip")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("list1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" list2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("zipped"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出：[(1, 'a'), (2, 'b'), (3, 'c')]")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 处理长度不一致的情况")]),t._v("\nlist3 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nzipped2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("zip")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("list1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" list3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("zipped2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出：[(1, 10), (2, 20)]（仅匹配前2个元素）")]),t._v("\n")])])]),s("h3",{attrs:{id:"_2-enumerate-函数"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-enumerate-函数"}},[t._v("#")]),t._v(" 2. "),s("code",[t._v("enumerate()")]),t._v(" 函数")]),t._v(" "),s("p",[s("strong",[t._v("功能")]),t._v("：为可迭代对象的元素添加一个索引值，返回一个迭代器，其中每个元素是 "),s("code",[t._v("(索引, 元素)")]),t._v(" 的元组。"),s("br"),t._v(" "),s("strong",[t._v("特点")]),t._v("：")]),t._v(" "),s("ul",[s("li",[t._v("接收一个可迭代对象作为参数，还可指定索引的起始值（默认从0开始）。")]),t._v(" "),s("li",[t._v("常用于需要同时获取元素及其位置（索引）的场景（如循环遍历）。")])]),t._v(" "),s("p",[s("strong",[t._v("示例")]),t._v("：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("fruits "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'apple'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'banana'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'cherry'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 默认从0开始索引")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" index"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fruit "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("enumerate")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("fruits"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("index"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fruit"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出：")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 0 apple")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1 banana")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2 cherry")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 指定索引从1开始")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" index"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fruit "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("enumerate")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("fruits"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" start"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("index"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fruit"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出：")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1 apple")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2 banana")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3 cherry")]),t._v("\n")])])]),s("h3",{attrs:{id:"核心区别"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#核心区别"}},[t._v("#")]),t._v(" 核心区别")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[t._v("维度")]),t._v(" "),s("th",[s("code",[t._v("zip()")])]),t._v(" "),s("th",[s("code",[t._v("enumerate()")])])])]),t._v(" "),s("tbody",[s("tr",[s("td",[t._v("输入")]),t._v(" "),s("td",[t._v("多个可迭代对象")]),t._v(" "),s("td",[t._v("单个可迭代对象")])]),t._v(" "),s("tr",[s("td",[t._v("输出")]),t._v(" "),s("td",[t._v("对应位置元素组成的元组")]),t._v(" "),s("td",[s("code",[t._v("(索引, 元素)")]),t._v(" 形式的元组")])]),t._v(" "),s("tr",[s("td",[t._v("用途")]),t._v(" "),s("td",[t._v("合并多个序列的对应元素")]),t._v(" "),s("td",[t._v("为序列元素添加索引（位置标记）")])])])]),t._v(" "),s("p",[t._v("简单说："),s("code",[t._v("zip()")]),t._v(" 用于“横向”合并多个序列，"),s("code",[t._v("enumerate()")]),t._v(" 用于为单个序列“纵向”添加索引。")]),t._v(" "),s("h3",{attrs:{id:"_3-strip-函数"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-strip-函数"}},[t._v("#")]),t._v(" 3. strip() 函数")]),t._v(" "),s("p",[t._v("当然，很乐意为您解释这个在文本处理中至关重要的基础方法。")]),t._v(" "),s("p",[s("code",[t._v("line.strip()")]),t._v(" 是 Python 字符串方法 "),s("code",[t._v("str.strip()")]),t._v(" 的一个非常典型的应用场景。它的核心作用是："),s("strong",[t._v("移除字符串 "),s("code",[t._v("line")]),t._v(" 首尾的特定字符（默认是空白字符），并返回处理后的新字符串。")])]),t._v(" "),s("hr"),t._v(" "),s("h3",{attrs:{id:"_1-核心作用详解"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-核心作用详解"}},[t._v("#")]),t._v(" 1. 核心作用详解")]),t._v(" "),s("p",[t._v("假设我们从文件或网络中读取了一行文本，它通常看起来像这样：\n"),s("code",[t._v('" \\t Hello, World! \\n "')])]),t._v(" "),s("p",[s("code",[t._v("line.strip()")]),t._v(" 会：")]),t._v(" "),s("ol",[s("li",[s("strong",[t._v("移除首部空白")]),t._v("：开头的空格和制表符 "),s("code",[t._v("\\t")]),t._v(" 被移除。")]),t._v(" "),s("li",[s("strong",[t._v("移除尾部空白")]),t._v("：末尾的回车换行符 "),s("code",[t._v("\\n")]),t._v(" 和空格被移除。")]),t._v(" "),s("li",[s("strong",[t._v("保留中间部分")]),t._v("：字符串中间的任何空白字符（包括空格、制表符）都会被完整保留。")]),t._v(" "),s("li",[s("strong",[t._v("返回新字符串")]),t._v("：它"),s("strong",[t._v("不会")]),t._v("修改原始字符串 "),s("code",[t._v("line")]),t._v("，而是返回一个处理后的新字符串。")])]),t._v(" "),s("p",[t._v("所以，处理结果是："),s("code",[t._v('"Hello, World!"')])]),t._v(" "),s("h3",{attrs:{id:"_2-为什么在-nlp-和数据预处理中至关重要"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-为什么在-nlp-和数据预处理中至关重要"}},[t._v("#")]),t._v(" 2. 为什么在 NLP 和数据预处理中至关重要？")]),t._v(" "),s("p",[t._v("在处理文本数据（尤其是读取文件或处理网络响应）时，"),s("code",[t._v("strip()")]),t._v(" 几乎是必不可少的步骤。主要原因如下：")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("清理换行符")]),t._v("：从文件（如 "),s("code",[t._v(".txt")]),t._v(", "),s("code",[t._v(".csv")]),t._v("）中按行读取（"),s("code",[t._v("for line in file:")]),t._v("）时，每一行的末尾通常都带有不可见的换行符 "),s("code",[t._v("\\n")]),t._v(" 或 "),s("code",[t._v("\\r\\n")]),t._v("。如果不处理，这些字符会成为你文本数据的一部分，导致后续处理（如分词、模型输入）出错。")]),t._v(" "),s("li",[s("strong",[t._v("去除无意义的空白")]),t._v("：文本开头和结尾的空格、制表符通常不包含任何语义信息，只是格式化的产物。去除它们可以使数据更干净、一致。")]),t._v(" "),s("li",[s("strong",[t._v("避免空行干扰")]),t._v("：一个常见的空行可能只包含一个 "),s("code",[t._v("\\n")]),t._v("，即 "),s("code",[t._v('"\\n"')]),t._v("。对其使用 "),s("code",[t._v("strip()")]),t._v(" 后会得到一个空字符串 "),s("code",[t._v('""')]),t._v("，这样我们就可以轻松地用 "),s("code",[t._v("if line.strip():")]),t._v(" 来过滤掉这些无意义的空行。")]),t._v(" "),s("li",[s("strong",[t._v("为后续任务做准备")]),t._v('：干净的数据是分词、构建词表、模型训练和评估的基础。杂乱的空白字符会导致同一个词（如 "word" 和 "word "）被识别为两个不同的 token，严重影响模型性能。')])]),t._v(" "),s("h3",{attrs:{id:"_3-参数-自定义要移除的字符"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-参数-自定义要移除的字符"}},[t._v("#")]),t._v(" 3. 参数：自定义要移除的字符")]),t._v(" "),s("p",[s("code",[t._v("strip()")]),t._v(" 方法可以接受一个可选的 "),s("code",[t._v("chars")]),t._v(" 参数，用于指定想要移除的特定字符，而不是默认的空白符。")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("line.strip()")]),t._v("：默认行为，移除首尾所有空白字符（包括空格、"),s("code",[t._v("\\t")]),t._v(", "),s("code",[t._v("\\n")]),t._v(", "),s("code",[t._v("\\r")]),t._v(", "),s("code",[t._v("\\v")]),t._v(", "),s("code",[t._v("\\f")]),t._v(" 等）。")]),t._v(" "),s("li",[s("code",[t._v("line.strip(‘.,!? ')")]),t._v("：移除首尾的句点、逗号、感叹号、问号和空格。"),s("strong",[t._v("注意")]),t._v("：字符的顺序不重要，它代表一个字符集合。")])]),t._v(" "),s("p",[s("strong",[t._v("示例：")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("line "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" “"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("!!这是一条示例文本?!"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ”\ncleaned_line "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" line"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("strip"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("‘"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("!? ’"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cleaned_line"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出： “这是一条示例文本”")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 开头的 “...!!” 和 结尾的 “?!., ” 都被移除了")]),t._v("\n")])])]),s("h3",{attrs:{id:"_4-相关方法-rstrip-和-lstrip"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-相关方法-rstrip-和-lstrip"}},[t._v("#")]),t._v(" 4. 相关方法："),s("code",[t._v("rstrip()")]),t._v(" 和 "),s("code",[t._v("lstrip()")])]),t._v(" "),s("p",[t._v("有时你只需要处理一端：")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("line.rstrip()")]),t._v("：只移除字符串"),s("strong",[t._v("末尾")]),t._v("的空白字符。这在处理行数据时非常常用，因为它只去掉换行符而保留行首的缩进（比如代码文件）。")]),t._v(" "),s("li",[s("code",[t._v("line.lstrip()")]),t._v("：只移除字符串"),s("strong",[t._v("开头")]),t._v("的空白字符。")])]),t._v(" "),s("h3",{attrs:{id:"_5-一个典型的-nlp-数据处理示例"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5-一个典型的-nlp-数据处理示例"}},[t._v("#")]),t._v(" 5. 一个典型的 NLP 数据处理示例")]),t._v(" "),s("p",[t._v("假设我们有一个 "),s("code",[t._v("corpus.txt")]),t._v(" 文件，内容如下：")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("  今天是晴天。\n\n  \n外面在下雨。  \n我们需要处理文本。\n")])])]),s("p",[t._v("我们使用以下代码读取并清洗数据：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("cleaned_lines "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'corpus.txt'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'r'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" encoding"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'utf-8'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" line "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1. 先strip去除首尾空白和换行符")]),t._v("\n        stripped_line "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" line"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("strip"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 2. 检查是否不是空行（过滤掉strip后为""的行）')]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" stripped_line"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            cleaned_lines"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("stripped_line"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cleaned_lines"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出： ['今天是晴天。', '外面在下雨。', '我们需要处理文本。']")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 后续就可以对 cleaned_lines 进行分词、训练等操作了")]),t._v("\n")])])]),s("h3",{attrs:{id:"总结"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[t._v("#")]),t._v(" 总结")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",{staticStyle:{"text-align":"left"}},[t._v("方法")]),t._v(" "),s("th",{staticStyle:{"text-align":"left"}},[t._v("作用")]),t._v(" "),s("th",{staticStyle:{"text-align":"left"}},[t._v("应用场景")])])]),t._v(" "),s("tbody",[s("tr",[s("td",{staticStyle:{"text-align":"left"}},[s("code",[t._v("line.strip()")])]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("移除字符串"),s("strong",[t._v("首尾")]),t._v("的"),s("strong",[t._v("所有空白字符")]),t._v("（默认）或指定字符集。")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[s("strong",[t._v("最常用")]),t._v("，用于通用文本清洗，去除首尾无用空白和换行符。")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[s("code",[t._v("line.strip(‘chars’)")])]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("移除字符串"),s("strong",[t._v("首尾")]),t._v("的"),s("strong",[t._v("指定字符集")]),t._v("中的任何字符。")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("清理特定标点符号或无用字符。")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[s("code",[t._v("line.rstrip()")])]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("只移除字符串"),s("strong",[t._v("末尾")]),t._v("的空白或指定字符。")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("保留行首缩进，只去除行尾换行符。")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[s("code",[t._v("line.lstrip()")])]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("只移除字符串"),s("strong",[t._v("开头")]),t._v("的空白或指定字符。")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("较少用，用于处理特定格式的字符串。")])])])]),t._v(" "),s("p",[t._v("作为一名高级 Python 开发工程师，在处理任何文本数据流时，养成第一时间使用 "),s("code",[t._v("strip()")]),t._v(" 来规范化输入的习惯，是保证数据质量的关键第一步。")]),t._v(" "),s("h3",{attrs:{id:"_4-json-loads"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-json-loads"}},[t._v("#")]),t._v(" 4.json.loads()")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# json.loads(line.strip())")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 作用：接受一个合法的JSON格式的字符串作为输入，并将其反序列化（deserialize）为对应的Python数据结构。")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 输入：一个字符串，例如 \'{"name": "Alice", "age": 30}\'。')]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 输出：一个Python对象，例如字典 {"name": "Alice", "age": 30}')]),t._v("\n")])])]),s("h3",{attrs:{id:"_5-input-items-是python字典的一个方法-它返回一个包含字典所有-键-值-对的视图对象。"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5-input-items-是python字典的一个方法-它返回一个包含字典所有-键-值-对的视图对象。"}},[t._v("#")]),t._v(" 5. input.items() 是Python字典的一个方法，它返回一个包含字典所有(键, 值)对的视图对象。")]),t._v(" "),s("p",[s("strong",[t._v("跟js 里面的 Object.entries() 类似")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tokens"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" tensor1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mask"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" tensor2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"labels"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" tensor3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# input.items() 返回：")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# dict_items([('tokens', tensor1), ('mask', tensor2), ('labels', tensor3)])")]),t._v("\n")])])]),s("p",[t._v("当然！这行代码是深度学习中非常常见的模式，尤其在多GPU训练或需要显式管理设备内存时。让我为您详细解析。")]),t._v(" "),s("h4",{attrs:{id:"代码解析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#代码解析"}},[t._v("#")]),t._v(" 代码解析")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"cuda"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" v "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("items"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("这行代码的作用是："),s("strong",[t._v("将一个字典中的所有张量（Tensor）从当前设备（通常是CPU）移动到CUDA设备（GPU）上。")])]),t._v(" "),s("hr"),t._v(" "),s("h4",{attrs:{id:"_1-input-items-的作用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-input-items-的作用"}},[t._v("#")]),t._v(" 1. "),s("code",[t._v("input.items()")]),t._v(" 的作用")]),t._v(" "),s("p",[s("code",[t._v("input.items()")]),t._v(" 是Python字典的一个方法，它返回一个包含字典所有"),s("code",[t._v("(键, 值)")]),t._v("对的视图对象。")]),t._v(" "),s("p",[s("strong",[t._v("示例：")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tokens"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" tensor1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mask"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" tensor2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"labels"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" tensor3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# input.items() 返回：")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# dict_items([('tokens', tensor1), ('mask', tensor2), ('labels', tensor3)])")]),t._v("\n")])])]),s("h4",{attrs:{id:"_2-for-k-v-in-input-items-的作用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-for-k-v-in-input-items-的作用"}},[t._v("#")]),t._v(" 2. "),s("code",[t._v("for k, v in input.items()")]),t._v(" 的作用")]),t._v(" "),s("p",[t._v("这是一个字典遍历的语法，它：")]),t._v(" "),s("ul",[s("li",[s("strong",[s("code",[t._v("k")])]),t._v("：获取每个键（key），如 "),s("code",[t._v('"tokens"')]),t._v(", "),s("code",[t._v('"mask"')]),t._v(", "),s("code",[t._v('"labels"')])]),t._v(" "),s("li",[s("strong",[s("code",[t._v("v")])]),t._v("：获取每个值（value），即对应的张量 "),s("code",[t._v("tensor1")]),t._v(", "),s("code",[t._v("tensor2")]),t._v(", "),s("code",[t._v("tensor3")])])]),t._v(" "),s("h4",{attrs:{id:"_3-to-cuda-的作用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-to-cuda-的作用"}},[t._v("#")]),t._v(" 3. "),s("code",[t._v('.to("cuda")')]),t._v(" 的作用")]),t._v(" "),s("p",[t._v("这是PyTorch张量的方法，用于将张量移动到指定的设备：")]),t._v(" "),s("ul",[s("li",[s("code",[t._v('"cuda"')]),t._v("：移动到GPU")]),t._v(" "),s("li",[s("code",[t._v('"cpu"')]),t._v("：移动到CPU")])]),t._v(" "),s("h4",{attrs:{id:"_4-字典推导式-k-v-to-cuda-for-k-v-in-input-items"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-字典推导式-k-v-to-cuda-for-k-v-in-input-items"}},[t._v("#")]),t._v(" 4. 字典推导式 "),s("code",[t._v('{k: v.to("cuda") for k, v in input.items()}')])]),t._v(" "),s("p",[t._v("将上述操作组合起来：")]),t._v(" "),s("ul",[s("li",[t._v("对于字典中的每个键值对")]),t._v(" "),s("li",[t._v("保持键 "),s("code",[t._v("k")]),t._v(" 不变")]),t._v(" "),s("li",[t._v("将值 "),s("code",[t._v("v")]),t._v("（张量）移动到GPU")]),t._v(" "),s("li",[t._v("构建一个新的字典")])]),t._v(" "),s("hr"),t._v(" "),s("h2",{attrs:{id:"_6-在nlp和深度学习中的实际应用场景"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_6-在nlp和深度学习中的实际应用场景"}},[t._v("#")]),t._v(" 6. 在NLP和深度学习中的实际应用场景")]),t._v(" "),s("h3",{attrs:{id:"场景1-模型训练前的数据准备"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#场景1-模型训练前的数据准备"}},[t._v("#")]),t._v(" 场景1：模型训练前的数据准备")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 假设我们有一个包含多个张量的输入字典")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"input_ids"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2023")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2003")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1037")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2164")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("102")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# token IDs")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"attention_mask"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("                "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 注意力掩码")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"labels"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("                                           "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 标签")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"移动前设备:"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"input_ids"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("device"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# cpu")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 关键操作：将所有张量移动到GPU")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"cuda"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" v "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("items"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"移动后设备:"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"input_ids"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("device"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# cuda:0")]),t._v("\n")])])]),s("h3",{attrs:{id:"场景2-与模型配合使用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#场景2-与模型配合使用"}},[t._v("#")]),t._v(" 场景2：与模型配合使用")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 假设模型已经在GPU上")]),t._v("\nmodel "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" MyTransformerModel"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"cuda"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 训练循环中")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" batch "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" dataloader"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 将批次数据移动到GPU")]),t._v("\n  batch "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"cuda"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" v "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" batch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("items"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  \n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 前向传播（现在所有数据都在GPU上，效率最高）")]),t._v("\n  outputs "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),t._v("batch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  loss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" outputs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("loss\n  \n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 反向传播等...")]),t._v("\n")])])]),s("hr"),t._v(" "),s("h2",{attrs:{id:"为什么需要这样的操作"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#为什么需要这样的操作"}},[t._v("#")]),t._v(" 为什么需要这样的操作？")]),t._v(" "),s("h3",{attrs:{id:"_1-设备一致性要求"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-设备一致性要求"}},[t._v("#")]),t._v(" 1. "),s("strong",[t._v("设备一致性要求")])]),t._v(" "),s("p",[t._v("PyTorch要求所有参与运算的张量必须在同一个设备上。如果模型在GPU上而数据在CPU上，会报错。")]),t._v(" "),s("h3",{attrs:{id:"_2-性能优化"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-性能优化"}},[t._v("#")]),t._v(" 2. "),s("strong",[t._v("性能优化")])]),t._v(" "),s("p",[t._v("GPU计算比CPU快得多，但需要数据在GPU内存中。")]),t._v(" "),s("h3",{attrs:{id:"_3-批量处理"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-批量处理"}},[t._v("#")]),t._v(" 3. "),s("strong",[t._v("批量处理")])]),t._v(" "),s("p",[t._v("可以一次性处理整个字典的所有张量，代码更简洁。")]),t._v(" "),s("hr"),t._v(" "),s("h2",{attrs:{id:"更健壮的写法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#更健壮的写法"}},[t._v("#")]),t._v(" 更健壮的写法")]),t._v(" "),s("p",[t._v("在实际项目中，我们通常会写得更健壮：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 方法1：指定具体设备")]),t._v("\ndevice "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("device"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"cuda"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cuda"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_available"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"cpu"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("device"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" v "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("items"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 方法2：处理非张量值（避免报错）")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("device"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_tensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" v "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" v "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("items"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 方法3：使用getattr避免属性错误")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("device"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("hasattr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'to'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" v "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" v "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("items"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("hr"),t._v(" "),s("h2",{attrs:{id:"类似的应用模式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#类似的应用模式"}},[t._v("#")]),t._v(" 类似的应用模式")]),t._v(" "),s("p",[t._v("这种模式在深度学习中非常常见：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 将模型移动到设备")]),t._v("\nmodel "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("device"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 将优化器状态移动到设备（如果优化器在模型之后创建，通常不需要）")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" state "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" optimizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("state"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("values"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" v "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" state"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("items"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_tensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      state"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("device"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("hr"),t._v(" "),s("h2",{attrs:{id:"总结-2"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#总结-2"}},[t._v("#")]),t._v(" 总结")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",{staticStyle:{"text-align":"left"}},[t._v("代码部分")]),t._v(" "),s("th",{staticStyle:{"text-align":"left"}},[t._v("作用")]),t._v(" "),s("th",{staticStyle:{"text-align":"left"}},[t._v("重要性")])])]),t._v(" "),s("tbody",[s("tr",[s("td",{staticStyle:{"text-align":"left"}},[s("code",[t._v("input.items()")])]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("获取字典的所有键值对")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("遍历字典内容")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[s("code",[t._v("for k, v in")])]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("解包键和值")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("分别处理键和值")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[s("code",[t._v('v.to("cuda")')])]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("将张量移动到GPU")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("确保设备一致性")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[t._v("字典推导式")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("构建新字典")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("代码简洁高效")])])])]),t._v(" "),s("p",[s("strong",[t._v("这行代码的核心价值")]),t._v("：确保输入数据与模型在同一设备上，这是深度学习训练中避免设备不匹配错误的标准做法，对于实现高效的GPU计算至关重要。")]),t._v(" "),s("p",[t._v("在实际的NLP项目中，这种模式几乎出现在每一个训练循环的数据加载步骤中。")]),t._v(" "),s("h2",{attrs:{id:"_7-e-for-e-in-examples-的用法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_7-e-for-e-in-examples-的用法"}},[t._v("#")]),t._v(" 7. e for e in examples 的用法")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# e for e in examples")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 作用：遍历examples中的每一个元素，并将每个元素赋值给e")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输入：一个列表或任何可迭代对象，例如 [1, 2, 3, 4, 5]。")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出：依次将列表中的每个元素赋值给e，并执行相应的操作。")]),t._v("\n\nexamples "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"content"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"这是第一段内容。"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"content"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"这是第二段内容。"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\ncontents "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"摘要生成: \\n"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" e "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" e "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" examples"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"content"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])])]),s("h2",{attrs:{id:"_8-python-中的列表推导式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_8-python-中的列表推导式"}},[t._v("#")]),t._v(" 8. python 中的列表推导式")]),t._v(" "),s("ul",[s("li",[t._v("要学习列表推导式，首先需要了解Python中的列表（List）和for循环。")]),t._v(" "),s("li",[t._v("可迭代对象（比如列表）可以用于for循环，列表推导式就是利用for循环来创建列表的一种简洁方式。")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 模拟你的工具对象")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("MockTool")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" name\n\ntools "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("MockTool"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tool"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'or'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("join"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("tool"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" tool "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" tools"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 完整示例")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 模拟你的工具对象")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("MockTool")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" name\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 创建模拟工具列表")]),t._v("\ntools "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("MockTool"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'tavily_search'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" MockTool"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'calculator'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" MockTool"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'weather'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 你的原始代码")]),t._v("\ntool_names "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'or'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("join"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("tool"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" tool "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" tools"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v("f'当前结果: ")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("tool_names"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'")])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出: tavily_searchorcalculatororweather")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 更合理的写法")]),t._v("\ntool_names_better "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("' or '")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("join"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("tool"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" tool "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" tools"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v("f'改进结果: ")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("tool_names_better"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'")])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出: tavily_search or calculator or weather")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 或者用逗号分隔，最后用or")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tools"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  tool_names_optimal "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("', '")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("join"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("tool"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" tool "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" tools"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("' or '")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" tools"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  tool_names_optimal "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tools"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" tools "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v("f'最优结果: ")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("tool_names_optimal"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'")])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出: tavily_search, calculator or weather")]),t._v("\n")])])]),s("h2",{attrs:{id:"_9-with-open"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_9-with-open"}},[t._v("#")]),t._v(" 9. with.open")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data_file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'rt'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" encoding"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'utf-8'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n")])])]),s("ul",[s("li",[t._v("'rt'\n"),s("ul",[s("li",[s("code",[t._v("r")]),t._v("表示读取(read)，"),s("code",[t._v("t")]),t._v("表示文本模式(text)")]),t._v(" "),s("li",[s("code",[t._v("encoding='utf-8'")]),t._v("表示以utf-8编码读取文件")])])])]),t._v(" "),s("h2",{attrs:{id:"_10-python-中-items-作用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_10-python-中-items-作用"}},[t._v("#")]),t._v(" 10. python 中 items() 作用")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 字典的 items() 方法")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 作用：返回字典的键值对视图对象")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出：一个包含所有键值对的视图对象，每个元素都是一个元组 (key, value)")]),t._v("\n\nid2label "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'O'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'B-LOC'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'I-LOC'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 调用 items() 方法")]),t._v("\nitems_view "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" id2label"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("items"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 转换为列表查看")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("items_view"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [(0, 'O'), (1, 'B-LOC'), (2, 'I-LOC')]")]),t._v("\n")])])]),s("h2",{attrs:{id:"_11-python-中-字典推导式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_11-python-中-字典推导式"}},[t._v("#")]),t._v(" 11. python 中 "),s("code",[t._v("字典推导式")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 字典的 items() 方法")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 作用：返回字典的键值对视图对象")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出：一个包含所有键值对的视图对象，每个元素都是一个元组 (key, value)")]),t._v("\n\nid2label "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'O'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'B-LOC'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'I-LOC'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 调用 items() 方法")]),t._v("\nitems_view "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" id2label"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("items"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 转换为列表查看")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("items_view"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [(0, 'O'), (1, 'B-LOC'), (2, 'I-LOC')]")]),t._v("\n\nlabel2id "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" k "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" v "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" id2label"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("items"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# {'O': 0, 'B-LOC': 1, 'I-LOC': 2}")]),t._v("\n\n可见，原元组中的 `"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("` 确实被交换为了新字典中的 `"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("`。\n")])])]),s("h2",{attrs:{id:"_12-python-中-列表推导式-和-字典推导式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_12-python-中-列表推导式-和-字典推导式"}},[t._v("#")]),t._v(" 12. python 中 "),s("code",[t._v("列表推导式")]),t._v(" 和 "),s("code",[t._v("字典推导式")])]),t._v(" "),s("ol",[s("li",[s("p",[t._v("列表推导式\n语法：[表达式 for 变量 in 可迭代对象 if 条件]")])]),t._v(" "),s("li",[s("p",[t._v("字典推导式")])])]),t._v(" "),s("p",[t._v("语法：{表达式 for 变量 in 可迭代对象 if 条件}")]),t._v(" "),s("ol",{attrs:{start:"3"}},[s("li",[t._v("集合推导式")])]),t._v(" "),s("ul",[s("li",[t._v("用于创建集合（自动去重），语法与列表推导式类似，但用"),s("code",[t._v("{}")]),t._v("包裹。\n语法：{表达式 for 变量 in 可迭代对象 if 条件}")])]),t._v(" "),s("h3",{attrs:{id:"总结-3"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#总结-3"}},[t._v("#")]),t._v(" 总结")]),t._v(" "),s("blockquote",[s("p",[t._v("四种推导式的核心作用都是"),s("code",[t._v("简化集合类数据的创建")]),t._v("，区别在于返回类型：")])]),t._v(" "),s("ul",[s("li",[t._v("列表推导式 → 列表（list）")]),t._v(" "),s("li",[t._v("字典推导式 → 字典（dict）")]),t._v(" "),s("li",[t._v("集合推导式 → 集合（set）")]),t._v(" "),s("li",[t._v("生成器推导式 → 生成器（generator）")])]),t._v(" "),s("h2",{attrs:{id:"_13-entities-true-setdefault"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_13-entities-true-setdefault"}},[t._v("#")]),t._v(" 13. entities_true.setdefault()")]),t._v(" "),s("p",[s("code",[t._v("entities_true.setdefault()")]),t._v(" 是字典的一个非常有用的方法，它的作用是："),s("strong",[t._v("获取指定键的值，如果键不存在，则设置默认值并返回。")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[t._v("value "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("dict")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setdefault"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default_value"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"与普通赋值的区别"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#与普通赋值的区别"}},[t._v("#")]),t._v(" 与普通赋值的区别")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[t._v("entities_true "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'name'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Alice'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 传统方式：需要先检查键是否存在")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'age'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" entities_true"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    entities_true"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'age'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n    age "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    age "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" entities_true"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'age'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用 setdefault：一行代码完成")]),t._v("\nage "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" entities_true"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setdefault"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'age'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h2",{attrs:{id:"_14-true-ent-extend"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_14-true-ent-extend"}},[t._v("#")]),t._v(" 14. true_ent.extend()")]),t._v(" "),s("ul",[s("li",[t._v("是列表的一个方法，用于将另一个"),s("code",[t._v("可迭代对象")]),t._v("中的所有元素添加到列表末尾。")])]),t._v(" "),s("blockquote",[s("p",[t._v("注意: 可迭代对象有: list, 元组, 字符串")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# true_ent = []")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# python 里面叫 list, js 里叫数组")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extend"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("iterable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("ul",[s("li",[s("p",[s("strong",[t._v("扩展列表")]),t._v("：将传入的可迭代对象中的每个元素逐个添加到原列表末尾")])]),t._v(" "),s("li",[s("p",[s("strong",[t._v("不创建新列表")]),t._v("：在原列表上直接修改（原地操作）")])]),t._v(" "),s("li",[s("p",[s("strong",[t._v("返回 None")]),t._v("：方法本身返回 None，所以不要赋值给变量")])])]),t._v(" "),s("h3",{attrs:{id:"eg"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#eg"}},[t._v("#")]),t._v(" eg:")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 初始列表")]),t._v("\ntrue_ent "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'apple'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'banana'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用 extend 添加多个元素")]),t._v("\ntrue_ent"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extend"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'orange'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'grape'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("true_ent"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出: ['apple', 'banana', 'orange', 'grape']")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 添加元组")]),t._v("\ntrue_ent"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extend"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'kiwi'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'melon'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("true_ent"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出: ['apple', 'banana', 'orange', 'grape', 'kiwi', 'melon']")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 添加字符串（字符串是可迭代的）")]),t._v("\ntrue_ent"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extend"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'abc'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("true_ent"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出: ['apple', 'banana', 'orange', 'grape', 'kiwi', 'melon', 'a', 'b', 'c']")]),t._v("\n")])])]),s("h2",{attrs:{id:"_15-列表推导式-if-and-使用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_15-列表推导式-if-and-使用"}},[t._v("#")]),t._v(" 15. 列表推导式 + if + and 使用")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[t._v("rerank_train "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("item "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" item "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" rerank_train "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"query"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"content"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])])]),s("h2",{attrs:{id:"_16-python-open-函数使用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_16-python-open-函数使用"}},[t._v("#")]),t._v(" 16. python open 函数使用")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[t._v("rerank_train_handler "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"./data/rerank_data/train.json"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"w"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" item "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" rerank_train"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    rerank_train_handler"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("json"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dumps"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ensure_ascii"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\n"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);