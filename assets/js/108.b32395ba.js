(window.webpackJsonp=window.webpackJsonp||[]).push([[108],{550:function(t,a,s){"use strict";s.r(a);var e=s(3),n=Object(e.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h2",{attrs:{id:"rag"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#rag"}},[t._v("#")]),t._v(" RAG")]),t._v(" "),a("h3",{attrs:{id:"_1-基本概念"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-基本概念"}},[t._v("#")]),t._v(" 1. 基本概念")]),t._v(" "),a("blockquote",[a("p",[t._v("RAG（Retrieval Augmented Generation）- 检索增强⽣成，顾名思义，通过检索外部数据，增强⼤模型的⽣成效果。")])]),t._v(" "),a("ul",[a("li",[t._v("RAG即检索增强⽣成，"),a("strong",[t._v("为LLM提供了从某些数据源检索到的信息")]),t._v("，并基于此修正⽣成的答案。")]),t._v(" "),a("li",[t._v("RAG 基本上是"),a("code",[t._v("Search + LLM 提示")]),t._v("，可以通过⼤模型回答查询，并将搜索算法所找到的信息作为⼤模型的上下⽂。")]),t._v(" "),a("li",[t._v("查询和检索到的上下⽂都会被注⼊到发送到 LLM 的提示语中。")])]),t._v(" "),a("h3",{attrs:{id:"_2-rag系统工作流程图解"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-rag系统工作流程图解"}},[t._v("#")]),t._v(" 2. RAG系统⼯作流程图解")]),t._v(" "),a("p",[a("img",{attrs:{src:"/hmblog/images/llm/rag/RAG-1.png",alt:"RAG系统⼯作流程图解"}})]),t._v(" "),a("h3",{attrs:{id:"_3-rag系统的搭建流程"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-rag系统的搭建流程"}},[t._v("#")]),t._v(" 3. RAG系统的搭建流程")]),t._v(" "),a("p",[a("img",{attrs:{src:"/hmblog/images/llm/rag/RAG-2.png",alt:"RAG系统搭建流程"}})]),t._v(" "),a("h3",{attrs:{id:"_4-rag-工作流程拆解"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-rag-工作流程拆解"}},[t._v("#")]),t._v(" 4. RAG 工作流程拆解")]),t._v(" "),a("h4",{attrs:{id:"索引-indexing"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#索引-indexing"}},[t._v("#")]),t._v(" 索引（Indexing）")]),t._v(" "),a("ul",[a("li",[t._v("索引⾸先清理和提取各种格式的原始数据，如 PDF、HTML、 Word 和 Markdown，然后将其转换为统⼀的纯⽂本格式。")]),t._v(" "),a("li",[t._v("为了适应语⾔模型的上下⽂限制，⽂本被分割成更⼩的、可消化的块（chunk）。")]),t._v(" "),a("li",[t._v("然后"),a("code",[t._v("使⽤嵌⼊模型")]),t._v("将块编码成向量表示，"),a("code",[t._v("并存储在向量数据库中")]),t._v("。这⼀步对于在随后的检索阶段实现⾼效的相似性搜索⾄关重要。")]),t._v(" "),a("li",[t._v("知识库分割成 chunks，并将 chunks 向量化⾄向量库中")])]),t._v(" "),a("h4",{attrs:{id:"检索-retrieval"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#检索-retrieval"}},[t._v("#")]),t._v(" 检索（Retrieval）")]),t._v(" "),a("ul",[a("li",[t._v("在收到⽤户查询（Query）后，RAG 系统采⽤与索引阶段相同的编码模型将查询转换为向量表示，")]),t._v(" "),a("li",[t._v("然后计算索引语料库中查询向量与块向量的相似性得分。该系统优先级和检索最⾼ k （Top-K）块，显示最⼤的相似性查询。")]),t._v(" "),a("li",[t._v("这些块随后被⽤作 "),a("code",[t._v("prompt")]),t._v(" 中的扩展上下⽂。Query 向量化，匹配向量空间中相近的 chunks")])]),t._v(" "),a("h3",{attrs:{id:"_5-rag具体实现流程"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-rag具体实现流程"}},[t._v("#")]),t._v(" 5. RAG具体实现流程")]),t._v(" "),a("p",[t._v("加载⽂件 => 读取⽂本 => ⽂本分割 =>⽂本向量化 => 输⼊问题向量化 => 在⽂本向量中匹配出与问题向量最相似的 top k 个 => 匹配出的⽂本作为上下⽂和问题⼀起添加到 "),a("code",[t._v("prompt")]),t._v(" 中 => 提交给 LLM ⽣成回答")]),t._v(" "),a("h3",{attrs:{id:"_6-向量与embeddings的定义"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-向量与embeddings的定义"}},[t._v("#")]),t._v(" 6. 向量与Embeddings的定义")]),t._v(" "),a("ol",[a("li",[t._v("将⽂本转成⼀组浮点数：每个下标 i ，对应⼀个维度")]),t._v(" "),a("li",[t._v("整个数组对应⼀个 n 维空间的⼀个点，即"),a("code",[t._v("⽂本向量")]),t._v("⼜叫 Embeddings")]),t._v(" "),a("li",[t._v("向量之间可以计算距离，距离远近对应"),a("code",[t._v("语义相似度")]),t._v("⼤⼩")])]),t._v(" "),a("h3",{attrs:{id:"_7-文档的加载与切割-基于文档的llm回复系统搭建"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_7-文档的加载与切割-基于文档的llm回复系统搭建"}},[t._v("#")]),t._v(" 7. ⽂档的加载与切割（基于⽂档的LLM回复系统搭建）")]),t._v(" "),a("p",[a("img",{attrs:{src:"/hmblog/images/llm/rag/RAG-3.png",alt:"⽂档的加载与切割"}})]),t._v(" "),a("h2",{attrs:{id:"为什么需要rag"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#为什么需要rag"}},[t._v("#")]),t._v(" 为什么需要RAG")]),t._v(" "),a("h3",{attrs:{id:"_1-因为llm的局限性-所以需要rag来增强模型的能力"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-因为llm的局限性-所以需要rag来增强模型的能力"}},[t._v("#")]),t._v(" 1. 因为LLM的局限性，所以需要RAG来增强模型的能力")]),t._v(" "),a("blockquote",[a("p",[t._v("将⼤模型应⽤于实际业务场景时会发现，通⽤的基础⼤模型基本⽆法满⾜我们的实际业务需求，主要有以下⼏⽅⾯原因:")])]),t._v(" "),a("ul",[a("li",[t._v("LLM的知识不是实时的，不具备知识更新")]),t._v(" "),a("li",[t._v("LLM可能不知道你私有的领域/业务知识")]),t._v(" "),a("li",[t._v("LLM有时会在回答中⽣成看似合理但实际上是错误的信息")])]),t._v(" "),a("h3",{attrs:{id:"_2-为什么会用到rag"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-为什么会用到rag"}},[t._v("#")]),t._v(" 2. 为什么会⽤到RAG?")]),t._v(" "),a("ol",[a("li",[t._v("提⾼准确性: "),a("code",[t._v("通过检索相关的信息")]),t._v("，RAG可以提⾼⽣成⽂本的准确性。")]),t._v(" "),a("li",[t._v("减少训练成本：与需要⼤量数据来训练的⼤型⽣成模型相⽐，"),a("code",[t._v("RAG可以通过检索机制")]),t._v("来减少所需的训练数据量，从⽽降低训练成本。")]),t._v(" "),a("li",[t._v("适应性强：RAG模型可以适应新的或不断变化的数据。"),a("code",[t._v("由于它们能够检索最新的信息")]),t._v("，因此在新数据和事件出现时，它们能够快速适应并⽣成相关的⽂本。")])]),t._v(" "),a("h3",{attrs:{id:"_3-rag-和-fine-tuning-对比"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-rag-和-fine-tuning-对比"}},[t._v("#")]),t._v(" 3. RAG 和 Fine-tuning 对比")]),t._v(" "),a("ol",[a("li",[t._v("RAG（检索增强⽣成）是把内部的⽂档数据先进⾏embedding，"),a("strong",[t._v("借助检索先获得⼤致的知识范围答案，再结合prompt给到LLM")]),t._v("，让LLM⽣成最终的答案")]),t._v(" "),a("li",[t._v("Fine-tuning（微调）"),a("strong",[t._v("是⽤⼀定量的数据集")]),t._v("对LLM进⾏局部参数的调整，以期望LLM更加理解我们的业务逻辑，有更好的"),a("code",[t._v("zero-shot")]),t._v("能⼒。")])]),t._v(" "),a("h2",{attrs:{id:"rag-框架或技术点"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#rag-框架或技术点"}},[t._v("#")]),t._v(" RAG 框架或技术点")]),t._v(" "),a("h3",{attrs:{id:"_1-multi-query-多查询"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-multi-query-多查询"}},[t._v("#")]),t._v(" 1. Multi-Query(多查询)")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("查询生成 / 改写")]),t._v("：使用 "),a("code",[t._v("LLM")]),t._v(" 对用户的初始查询进行改写，"),a("strong",[t._v("生成多个语义相似但表述不同的查询变体")]),t._v("。")]),t._v(" "),a("li",[t._v("这些变体从不同角度诠释原始问题，扩大检索覆盖范围。")]),t._v(" "),a("li",[t._v("例如，原始查询是 “气候变化的影响”，生成的查询可能包括 “气候变化的经济后果”, “气候变化与公共健康” 等。")])]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 多查询，提示词模版设计")]),t._v("\n\ntemplate "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""You are an AI language model assistant. Your task is to generate five \ndifferent versions of the given user question to retrieve relevant documents from a vector \ndatabase. By generating multiple perspectives on the user question, your goal is to help\nthe user overcome some of the limitations of the distance-based similarity search. \nProvide these alternative questions separated by newlines. Original question: {question}"""')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 中文解释：你是一个AI语言模型助手。你的任务是生成N个针对给定用户问题的不同版本，从向量中检索相关文档数据库......")]),t._v("\n")])])]),a("h3",{attrs:{id:"_2-fusion-rag"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-fusion-rag"}},[t._v("#")]),t._v(" 2. Fusion RAG")]),t._v(" "),a("p",[t._v("RAG Fusion（RAG 融合）")]),t._v(" "),a("p",[t._v("包含 "),a("code",[t._v("多查询")]),t._v("  +  "),a("code",[t._v("RRF")])]),t._v(" "),a("ul",[a("li",[t._v("倒数排名融合")])]),t._v(" "),a("blockquote",[a("p",[t._v("RRF(Reciprocal Rank Fusion)是一种融合多个检索结果列表的算法，"),a("strong",[t._v("特别适用于混合检索场景")]),t._v("（如结合稠密向量检索和稀疏词频检索）。")])]),t._v(" "),a("blockquote",[a("p",[t._v("使用(RRF) 算法合并所有检索结果,")])]),t._v(" "),a("h4",{attrs:{id:"融合步骤"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#融合步骤"}},[t._v("#")]),t._v(" 融合步骤")]),t._v(" "),a("ul",[a("li",[t._v("对每个生成的查询进行基于向量的搜索，形成多路搜索召回的list。")])]),t._v(" "),a("ol",[a("li",[t._v("为每个排名列表中的结果分配倒数排名分数，分数按 "),a("code",[t._v("1/(rank + k)")]),t._v(" 计算，其中 "),a("code",[t._v("rank")]),t._v(" 是文档在列表中的位置，"),a("code",[t._v("k")]),t._v(" 是一个常量，通常设置为 "),a("code",[t._v("60")]),t._v(" 效果最佳。")]),t._v(" "),a("li",[t._v("分数累加(倒数排名分数相加)")]),t._v(" "),a("li",[t._v("获得最终的排序, 提高最相关文档在结果列表顶部出现的可能性。")])]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("提示调整")]),t._v("：在提示中要求 LLM 更重视原始查询，以缓解多查询可能稀释用户原始意图的问题。")])]),t._v(" "),a("h3",{attrs:{id:"_3-decomposition"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-decomposition"}},[t._v("#")]),t._v(" 3. Decomposition")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("prompts "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ChatPromptTemplate\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Decomposition")]),t._v("\ntemplate "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""You are a helpful assistant that generates multiple sub-questions related to an input question. \\n\nThe goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation. \\n\nGenerate multiple search queries related to: {question} \\n\nOutput (3 queries):"""')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 你是一个能够根据输入问题生成多个相关子问题的有帮助的助手。目标是将输入分解为一组子问题/子问题，这些子问题可以独立回答。")]),t._v("\nprompt_decomposition "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ChatPromptTemplate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_template"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("template"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"_4-hyde"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-hyde"}},[t._v("#")]),t._v(" 4. HyDE")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# step1 首先就是定义一个生成假设文档的提示词")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# HyDE document generation")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 您可以使用这个文档生成提示, 您可以根据您感兴趣的领域任意调整它。")]),t._v("\ntemplate "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""Please write a scientific paper passage to answer the question\nQuestion: {question}\nPassage:"""')]),t._v("\nprompt_hyde "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ChatPromptTemplate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_template"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("template"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# step2 调用大模型, 得到与我们的问题相关的假设文档部分。")]),t._v("\ngenerate_docs_for_retrieval "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  prompt_hyde "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" ChatOpenAI"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("temperature"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" StrOutputParser"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Run")]),t._v("\nquestion "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"What is task decomposition for LLM agents?"')]),t._v("\ngenerate_docs_for_retrieval"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("invoke"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"question"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("question"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# step3 接下来，就是用那个假设性文档，构成链 去使用, 运行检索")]),t._v("\nretrieval_chain "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" generate_docs_for_retrieval "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" retriever\nretrieved_docs "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" retrieval_chain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("invoke"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"question"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("question"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nretrieved_docs\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# retriever, 我们将从索引中获取与`已嵌入的假设文档`相关的文档。")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 得到了一些与该假设文档相关的检索块。")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# step4 最后，我们在这里获取我们定义的检索到的文档以及我们的问题。")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 也就是将，查询到相关片段(eg: 这里的retrieved_docs)作为上下文，再次传送给大模型去检索，答案")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 在这里定义我们检索到的文档  和  要询问的问题")]),t._v("\ntemplate "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""Answer the following question based on this context:\n\n{context}\n\nQuestion: {question}\n"""')]),t._v("\n\nprompt "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ChatPromptTemplate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_template"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("template"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nfinal_rag_chain "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  prompt\n  "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" llm\n  "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" StrOutputParser"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nfinal_rag_chain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("invoke"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"context"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("retrieved_docs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"question"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("question"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("h1",{attrs:{id:"检索过程-可以在langsmith-平台去查看"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#检索过程-可以在langsmith-平台去查看"}},[t._v("#")]),t._v(" 检索过程，可以在LangSmith 平台去查看")]),t._v(" "),a("h3",{attrs:{id:"_5-routing"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-routing"}},[t._v("#")]),t._v(" 5. Routing")]),t._v(" "),a("p",[t._v("个人理解：根据不同的问题，导航到不同的向量数据库去查询，以便更精准地进行查询。")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# step1 ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 假设我们有三个不同的文档,例如Python文档、JS文档、Golang文档")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Data model")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("RouteQuery")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("BaseModel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""Route a user query to the most relevant datasource."""')]),t._v("\n\n  datasource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Literal"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"python_docs"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"js_docs"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"golang_docs"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Field"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    description"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Given a user question choose which datasource would be most relevant for answering their question"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# LLM with function call ")]),t._v("\nllm "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ChatOpenAI"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"gpt-3.5-turbo-0125"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" temperature"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nstructured_llm "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" llm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("with_structured_output"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RouteQuery"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 拥有3个文档源，然后与LLM进行绑定")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 因此, 您可以看到我们对结构化输出所做的工作,基本上是在幕后。即采用对象定义,转换为函数模式并将该函数模式绑定到我们的LLM。")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# step2 然后我们调用 Prompt")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Prompt ")]),t._v("\nsystem "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""You are an expert at routing a user question to the appropriate data source.\n\nBased on the programming language the question is referring to, route it to the relevant data source."""')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 提示词翻译")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""您是将用户问题路由到适当数据源的专家。\n\n根据问题所指的编程语言，将其路由到相关数据源。"""')]),t._v("\nprompt "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ChatPromptTemplate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_messages"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"system"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" system"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"human"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{question}"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Define router ")]),t._v("\nrouter "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" prompt "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" structured_llm\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 因此, 您基本上可以将这个问题与不同的链挂钩,例如,Python的检索器链一, JS的检索器链二, 等等。")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# step3 ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("choose_route")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("result"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"python_docs"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" result"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datasource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lower"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("### Logic here ")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"chain for python_docs"')]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"js_docs"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" result"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datasource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lower"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("### Logic here ")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"chain for js_docs"')]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("### Logic here ")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"golang_docs"')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 所有这有点像路由机制")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 但这实际上是在承担输入问题并将其转换为结构化对象的繁重工作,该结构化对象将输出限制为我们在路由问题中关心的几种输出类型之一。")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 所以,这确实是这一切结合在一起的方式。")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# step4")]),t._v("\n")])])]),a("h2",{attrs:{id:"ragas-评估"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ragas-评估"}},[t._v("#")]),t._v(" Ragas 评估")]),t._v(" "),a("p",[a("strong",[t._v("数据准备")]),t._v("：输入 question、contexts、answer，可选 ground truth。")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[t._v("eval_data "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"question"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Ragas 的核心指标有哪些？"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"contexts"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Ragas 包含 context precision、context recall、faithfulness、answer relevancy 等指标..."')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"answer"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Ragas 的核心指标包括上下文精确率、上下文召回率、忠实度和答案相关性。"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"ground_truth"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Ragas 的核心指标包括上下文精确率、上下文召回率、忠实度和答案相关性。"')]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])])]),a("h3",{attrs:{id:"核心定位与设计理念"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#核心定位与设计理念"}},[t._v("#")]),t._v(" 核心定位与设计理念")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("面向 RAG 全流程")]),t._v("：聚焦检索质量与生成质量两大维度，指标可直接映射到系统组件的优化方向。")]),t._v(" "),a("li",[a("strong",[t._v("无参考评估")]),t._v("：减少对人工标注 ground truth 的依赖，通过 LLM 与嵌入模型实现自动验证。")]),t._v(" "),a("li",[a("strong",[t._v("可操作")]),t._v("：每个指标都有明确计算逻辑与优化建议，便于落地迭代。")])]),t._v(" "),a("hr"),t._v(" "),a("h3",{attrs:{id:"核心指标体系-0-1-分-越高越好"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#核心指标体系-0-1-分-越高越好"}},[t._v("#")]),t._v(" 核心指标体系（0–1 分，越高越好）")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"left"}},[t._v("维度")]),t._v(" "),a("th",{staticStyle:{"text-align":"left"}},[t._v("指标")]),t._v(" "),a("th",{staticStyle:{"text-align":"left"}},[t._v("定义与计算逻辑")]),t._v(" "),a("th",{staticStyle:{"text-align":"left"}},[t._v("优化方向")]),t._v(" "),a("th",{staticStyle:{"text-align":"left"}},[t._v("理想阈值")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("检索质量")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("Context Precision（上下文精确率）")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("检索到的上下文是否均为回答必需，过滤冗余")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("提升检索相关性、去重、过滤噪声")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("≥0.8")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("检索质量")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("Context Recall（上下文召回率）")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("是否完整召回回答所需关键信息")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("优化检索策略、调整 top-k、分块与重排")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("≥0.9")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("检索质量")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("Context Entity Recall（上下文实体召回率）")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("关键实体的召回完整性")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("增强实体抽取、优化向量/关键词检索")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("≥0.9")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("生成质量")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("Faithfulness（忠实度）")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("答案陈述是否可从上下文推断，检测幻觉")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("优化提示词、增加引用、限制幻觉")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("≥0.85")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("生成质量")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("Answer Relevancy（答案相关性）")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("答案对问题的响应程度，是否切题")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("优化提示词、增强问题理解、控制冗余")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("≥0.85")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("生成质量")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("Answer Correctness（答案正确性）")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("与 ground truth 的事实匹配程度（需参考）")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("提升检索召回与生成忠实度")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("≥0.8")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("综合")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("Ragas Score")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("综合上述指标的加权得分（可自定义权重）")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("全链路协同优化")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("≥0.8")])])])]),t._v(" "),a("h3",{attrs:{id:"ragas-评估指标"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ragas-评估指标"}},[t._v("#")]),t._v(" ragas 评估指标")]),t._v(" "),a("ul",[a("li",[t._v("context_precision: 上下文精确率")]),t._v(" "),a("li",[t._v("context_recall: 上下文召回率")]),t._v(" "),a("li",[t._v("faithfulness: 忠实度")]),t._v(" "),a("li",[t._v("answer_relevancy: 答案相关性")])]),t._v(" "),a("h3",{attrs:{id:"评估流程与实现原理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#评估流程与实现原理"}},[t._v("#")]),t._v(" 评估流程与实现原理")]),t._v(" "),a("ol",[a("li",[a("strong",[t._v("数据准备")]),t._v("：输入 question、contexts、answer，可选 ground truth。")]),t._v(" "),a("li",[a("strong",[t._v("指标计算")]),t._v("：\n"),a("ul",[a("li",[t._v("检索指标：通过嵌入相似度与 LLM 验证上下文相关性与召回完整性。")]),t._v(" "),a("li",[t._v("生成指标：将答案分解为原子陈述，由 LLM 验证是否可从上下文推导（Faithfulness）；通过语义相似度评估 Answer Relevancy。")])])]),t._v(" "),a("li",[a("strong",[t._v("结果分析")]),t._v("：生成各指标分数与综合 Ragas Score，定位检索或生成环节的瓶颈。")])]),t._v(" "),a("hr"),t._v(" "),a("h3",{attrs:{id:"与传统评估方法的对比"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#与传统评估方法的对比"}},[t._v("#")]),t._v(" 与传统评估方法的对比")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"left"}},[t._v("特性")]),t._v(" "),a("th",{staticStyle:{"text-align":"left"}},[t._v("传统方法（BLEU/ROUGE）")]),t._v(" "),a("th",{staticStyle:{"text-align":"left"}},[t._v("Ragas")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("评估标准")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("文本表面相似度")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("语义理解 + 事实一致性")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("参考依赖")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("必须 ground truth")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("支持无参考评估")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("覆盖维度")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("单一")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("检索—生成全链路多维指标")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("RAG 适用性")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("低（无法评估检索质量）")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("高（针对性设计）")])])])])])}),[],!1,null,null,null);a.default=n.exports}}]);