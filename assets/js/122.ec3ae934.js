(window.webpackJsonp=window.webpackJsonp||[]).push([[122],{565:function(t,n,a){"use strict";a.r(n);var s=a(3),e=Object(s.a)({},(function(){var t=this,n=t._self._c;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h2",{attrs:{id:"其他相关"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#其他相关"}},[t._v("#")]),t._v(" 其他相关")]),t._v(" "),n("h3",{attrs:{id:"_1-react"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-react"}},[t._v("#")]),t._v(" 1. ReAct")]),t._v(" "),n("p",[n("strong",[t._v("推理与行动")])]),t._v(" "),n("p",[t._v("在 RAG（检索增强生成）中，"),n("code",[t._v("ReAct")]),t._v(" 是一种用于构建基于大语言模型（LLM）的智能体的框架，其核心理念是将链式思维提示的优势整合到 Agent 框架中。")]),t._v(" "),n("p",[t._v("ReAct 最早在论文《ReAct: Synergizing Reasoning and Acting in Language Models》中提出，它的含义是直接利用 LLM 进行 Reasoning+Action，即推理与行动 。")]),t._v(" "),n("blockquote",[n("p",[t._v("具体来说，ReAct 让 LLM 通过一系列 “思考 - 行动 - 观察”（Thought-Action-Observation）的循环来解决问题，而不是一次性直接生成最终答案。")])]),t._v(" "),n("ul",[n("li",[t._v("其中，推理（Thought）阶段利用 LLM 生成分析步骤，解释任务上下文或状态，为下一步行动提供逻辑依据；")]),t._v(" "),n("li",[t._v("行动（Action）则依据推理结果生成工具调用请求，像查搜索引擎、调用 API、数据库检索等；")]),t._v(" "),n("li",[t._v("观察（Observation）就是模型接收来自环境的反馈，并据此更新高层计划 。")])]),t._v(" "),n("p",[t._v("通过这样交替执行推理和操作步骤，**ReAct 框架允许模型动态生成推理路径，在与环境交互的同时不断调整计划，从而实现迭代和增量式的任务解决，其检索并非被动，而是一个主动的、由决策驱动的过程 。**该模式可以增强 LLM 的决策和解决问题的能力，让其处理复杂任务时更具可解释性、可诊断性和稳健性 。")]),t._v(" "),n("h4",{attrs:{id:"使用llama-index库中的reactagent"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#使用llama-index库中的reactagent"}},[t._v("#")]),t._v(" 使用"),n("code",[t._v("llama_index")]),t._v("库中的"),n("code",[t._v("ReActAgent")])]),t._v(" "),n("div",{staticClass:"language-py extra-class"},[n("pre",{pre:!0,attrs:{class:"language-py"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" llama_index"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("agent "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ReActAgent\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" llama_index"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("query_engine "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" QueryEngineTool\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1. 封装RAG检索工具")]),t._v("\ntool_a "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" QueryEngineTool"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_defaults"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    query_engine"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("query_engine_a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# A公司专属检索引擎")]),t._v("\n    description"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"用于查询A公司的财务信息，包括销售额、增长率等"')]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntool_b "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" QueryEngineTool"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_defaults"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    query_engine"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("query_engine_b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# B公司专属检索引擎")]),t._v("\n    description"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"用于查询B公司的财务信息，包括销售额、增长率等"')]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nquery_engine_tools "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("tool_a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tool_b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2. 初始化ReAct Agent（绑定LLM与检索工具）")]),t._v("\nagent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ReActAgent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_tools"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    query_engine_tools"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    llm"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("llm"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 选用的大语言模型（如GPT-4、Llama 3）")]),t._v("\n    verbose"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出思考与行动过程")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("ol",{attrs:{start:"2"}},[n("li",[t._v("COT 思维链\n已成为增强复杂任务上模型性能的标准提示技术。该模型被指示“一步一步思考”，以利用更多的测试时间计算将困难的任务分解为更小、更简单的步骤。CoT 将大任务转化为多个可管理的任务，并阐明对模型思维过程的解释。")])]),t._v(" "),n("p",[t._v("在 RAG（检索增强生成）中，ReAct 是一种用于构建基于大语言模型（LLM）的智能体的框架，其核心理念是将链式思维提示的优势整合到 Agent 框架中 。")]),t._v(" "),n("p",[t._v("论文：《ReAct: Synergizing Reasoning and Acting in Language Models》")]),t._v(" "),n("ul",[n("li",[t._v("ReAct 让 LLM 通过一系列 “思考 - 行动 - 观察”（Thought-Action-Observation）的循环来解决问题，而不是一次性直接生成最终答案 。")]),t._v(" "),n("li",[t._v("其中，推理（Thought）阶段利用 LLM 生成分析步骤，解释任务上下文或状态，为下一步行动提供逻辑依据；")]),t._v(" "),n("li",[t._v("行动（Action）则依据推理结果生成工具调用请求，像查搜索引擎、调用 API、数据库检索等；")]),t._v(" "),n("li",[t._v("观察（Observation）就是模型接收来自环境的反馈，并据此更新高层计划 。")])]),t._v(" "),n("p",[t._v("Task decomposition：任务分解")]),t._v(" "),n("p",[t._v("任务分解是将复杂任务分解为更小、更易于管理的步骤或子目标的过程。\n这可以通过思维链提示等技术来实现，它指示模型逐步思考，或者使用特定任务的指令和人工输入。\n目标是通过规划和执行每个组件步骤，使大问题更容易解决。")]),t._v(" "),n("p",[t._v("Task decomposition 可以通过以下方式实现：")]),t._v(" "),n("ul",[n("li",[t._v("提示词工程：设计特定的提示词，引导模型生成结构化的思考步骤。")]),t._v(" "),n("li",[t._v("人工输入：在任务执行过程中，人类提供额外的输入，帮助模型更好地理解任务需求。")]),t._v(" "),n("li",[t._v("自动分解：利用模型的推理能力，自动将复杂任务分解为多个子任务。")])]),t._v(" "),n("p",[t._v("思维链（CoT）已成为增强复杂任务上模型性能的标准提示技术。该模型被指示“一步一步思考”，以利用更多的测试时间计算将困难的任务分解为更小、更简单的步骤。CoT 将大任务转化为多个可管理的任务，并阐明对模型思维过程的解释。\nTree of Thoughts 通过探索每个步骤的多种推理可能性来扩展 CoT。")]),t._v(" "),n("ul",[n("li",[t._v("它首先将问题分解为多个思维步骤，每个步骤生成多个想法，从而创建树结构。搜索过程可以是 BFS（广度优先搜索）或 DFS（深度优先搜索），每个状态都由分类器（通过提示）或多数票评估。")])]),t._v(" "),n("h2",{attrs:{id:"_7-任务分解-task-decomposition-的优化"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_7-任务分解-task-decomposition-的优化"}},[t._v("#")]),t._v(" 7. 任务分解（Task Decomposition）的优化")]),t._v(" "),n("ul",[n("li",[n("p",[n("strong",[t._v("确定分解模式")]),t._v("：根据问题的特点确定使用串行模式或并行模式。串行模式适用于逻辑依赖强的问题分解，确保步骤的连贯性，如对于 “RAG 都有哪些阶段？” 这样的问题，需要先找到都有哪些阶段，然后再询问各个阶段该做什么事情。并行模式适用于独立子任务的高效处理，能提升响应速度，如对于 “如何规划北京到上海的 5 天旅游行程？” 的问题，可以分解成交通、住宿、景点三个子问题，分别完成。")])]),t._v(" "),n("li",[n("p",[n("strong",[t._v("构建提示模板")]),t._v("：使用特定的提示模板引导 LLM 进行问题分解。")]),t._v(" "),n("ul",[n("li",[t._v("例如，“你的任务是针对输入的问题生成多个相关的子问题或子查询，将输入问题分解成一组可以独立回答的子问题或子任务。")]),t._v(" "),n("li",[t._v("以下是输入的问题："),n("question",[t._v(t._s(t.question))]),t._v("请生成 3-5 个与该问题相关的搜索查询，并使用换行符进行分割。")],1),t._v(" "),n("li",[t._v("生成的子问题 / 子查询应具有明确的主题和可独立回答的特点。请在 <子问题> 标签内写下生成的子问题 / 子查询。”")])])]),t._v(" "),n("li",[n("p",[t._v("子任务处理与结果整合：")]),t._v(" "),n("ul",[n("li",[t._v("针对每个子任务单独执行检索和生成，最后将子结果汇总整合，形成最终答案。")]),t._v(" "),n("li",[t._v("在整合过程中，需要确保子结果之间的逻辑连贯性和一致性。")])])])])])}),[],!1,null,null,null);n.default=e.exports}}]);