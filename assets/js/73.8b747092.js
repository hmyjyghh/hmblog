(window.webpackJsonp=window.webpackJsonp||[]).push([[73],{518:function(t,e,o){"use strict";o.r(e);var s=o(3),_=Object(s.a)({},(function(){var t=this,e=t._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h2",{attrs:{id:"logits-是什么"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#logits-是什么"}},[t._v("#")]),t._v(" logits 是什么？")]),t._v(" "),e("p",[t._v("在深度学习（尤其是自然语言处理的语言模型任务中），"),e("strong",[t._v("logits")]),t._v(" 是模型在最后一层输出的"),e("strong",[t._v("原始未归一化的概率分数")]),t._v("。")]),t._v(" "),e("p",[t._v("以这段代码为例，当我们把分词后的输入 "),e("code",[t._v("inputs")]),t._v(" 传入 "),e("code",[t._v("model")]),t._v(" 后，模型会针对每个输入 token（分词后的基本单元），预测下一个可能出现的 token。"),e("code",[t._v("logits")]),t._v(" 就是这些预测的"),e("strong",[t._v("原始分数")]),t._v("，它还没有经过 softmax 函数的归一化处理（如果要得到概率，需要对 logits 做 softmax 操作，将其转换为 0 到 1 之间的概率分布）。")]),t._v(" "),e("p",[e("code",[t._v("logits.shape")]),t._v(" 输出的是一个张量形状，比如假设这里是 "),e("code",[t._v("(batch_size, sequence_length, vocab_size)")]),t._v("，其中 "),e("code",[t._v("batch_size")]),t._v(" 是批次大小（这里是 1），"),e("code",[t._v("sequence_length")]),t._v(" 是输入序列的长度，"),e("code",[t._v("vocab_size")]),t._v(" 是模型词汇表的大小（即模型能生成的不同 token 的总数）。这个形状反映了模型对每个位置的每个可能 token 都给出了一个原始分数。")])])}),[],!1,null,null,null);e.default=_.exports}}]);