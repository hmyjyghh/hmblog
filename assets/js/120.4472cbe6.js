(window.webpackJsonp=window.webpackJsonp||[]).push([[120],{562:function(t,s,a){"use strict";a.r(s);var n=a(3),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"混合检索"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#混合检索"}},[t._v("#")]),t._v(" 混合检索")]),t._v(" "),s("p",[t._v("混合检索的优势：将 BM25 的稀疏向量、BGE-M3 的稀疏向量与 Qwen3 Embedding 的稠密检索相结合，可以充分发挥各自的优势。")]),t._v(" "),s("ul",[s("li",[t._v("BM25 的稀疏向量基于统计信息，具有较好的可解释性，能快速定位关键词。")]),t._v(" "),s("li",[t._v("BGE-M3 的稀疏向量利用神经网络捕捉语义，对上下文相关性的理解更深入。")]),t._v(" "),s("li",[t._v("Qwen3 Embedding 的稠密向量则能从整体语义层面进行精准匹配。")])]),t._v(" "),s("p",[t._v("三者结合可以在不同层面上理解文本，提高检索的准确性和召回率，适用于各种复杂的信息检索场景。")]),t._v(" "),s("h2",{attrs:{id:"根据简历去学习"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#根据简历去学习"}},[t._v("#")]),t._v(" 根据简历去学习")]),t._v(" "),s("ol",[s("li",[t._v("Milvus 向量数据库, 检索原理，聚类算法")]),t._v(" "),s("li",[t._v("BM25、Dense(稠密)、Sparse(稀疏) 检索或召回")]),t._v(" "),s("li",[t._v("RAG 技术点使用 +  评测框架(RAGAS) 框架的使用")]),t._v(" "),s("li",[t._v("vLLM 框架 使用 + 原理")]),t._v(" "),s("li",[t._v("阶段4，作业题")]),t._v(" "),s("li",[t._v("简历")])]),t._v(" "),s("ul",[s("li",[t._v("LLM")]),t._v(" "),s("li",[t._v("Function Calling")]),t._v(" "),s("li",[t._v("多轮对话")]),t._v(" "),s("li",[t._v("Agent 或者  MCP协议，利用MCP完成对第三方内容服务，eg: 音乐、天气、数据库等调用")])]),t._v(" "),s("ol",{attrs:{start:"7"}},[s("li",[t._v("MCP、Function Calling")]),t._v(" "),s("li",[t._v("Agent")]),t._v(" "),s("li",[t._v("RRF算法")])]),t._v(" "),s("p",[t._v("TTS 是 Text-to-Speech（文本转语音）的缩写，指将文字信息转换为语音的技术。在这个场景中，就是依据工具调用获取的结果（如音乐、天气、数据库等信息），把文字内容转化为语音形式进行回复，实现从文本到语音的输出，让用户可以通过听觉接收信息。")]),t._v(" "),s("p",[t._v("MCP, 是模型上下文协议，简单来说，MCP就是AI大模型的标准化工具箱")]),t._v(" "),s("p",[t._v("大模型可以利用这些工具与外界互动、获取信息并且完成具体任务")]),t._v(" "),s("p",[t._v("MCP则通过标准化的协议，自动化了这一步骤")]),t._v(" "),s("p",[t._v("MCP服务作为AI与外部工具的中间层\n代替人类访问并且操作外部工具")]),t._v(" "),s("p",[t._v("MCP Server, 通常就是运行在本地的一段nodejs 或者 python 程序")]),t._v(" "),s("p",[t._v("大模型通过操作系统的stdio， 也就是标准输入通道调用某个MCP Server， MCP Server接到这些请求之后，通过自己的代码功能或者 使用 API 请求，访问外部工具、完成任务。")]),t._v(" "),s("p",[t._v("MCP协议与function call非常的相似")]),t._v(" "),s("p",[t._v("MCP的优点，在于整合了：之前各家大模型不同的function call的标准， 整合成了一个统一的标准协议")]),t._v(" "),s("p",[t._v("市面上几乎所有的大模型 都可以接入 MCP")]),t._v(" "),s("p",[t._v("1:48, 实战演示：")]),t._v(" "),s("h3",{attrs:{id:"_11-04"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_11-04"}},[t._v("#")]),t._v(" 11-04")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sentence_transformers "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" SentenceTransformer\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cluster "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" AgglomerativeClustering\n")])])]),s("h4",{attrs:{id:"你可以给我讲讲-sentencetransformer-和-agglomerativeclustering-这2个函数的用法吗"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#你可以给我讲讲-sentencetransformer-和-agglomerativeclustering-这2个函数的用法吗"}},[t._v("#")]),t._v(" 你可以给我讲讲：SentenceTransformer   和  AgglomerativeClustering  这2个函数的用法吗")]),t._v(" "),s("blockquote",[s("p",[t._v("它们通常一起用于文本聚类任务。")])]),t._v(" "),s("h2",{attrs:{id:"sentencetransformer"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#sentencetransformer"}},[t._v("#")]),t._v(" SentenceTransformer")]),t._v(" "),s("h3",{attrs:{id:"基本介绍"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#基本介绍"}},[t._v("#")]),t._v(" 基本介绍")]),t._v(" "),s("p",[t._v("SentenceTransformer 是一个专门用于将句子、段落或文档转换为向量表示的模型。")]),t._v(" "),s("h3",{attrs:{id:"基本用法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#基本用法"}},[t._v("#")]),t._v(" 基本用法")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sentence_transformers "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" SentenceTransformer\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 加载预训练模型")]),t._v("\nmodel "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SentenceTransformer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'all-MiniLM-L6-v2'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 将句子转换为向量")]),t._v("\nsentences "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"这是一个测试句子"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"这是另一个句子"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nembeddings "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("encode"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sentences"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("embeddings"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (2, 384) - 2个句子，每个384维向量")]),t._v("\n")])])]),s("h3",{attrs:{id:"常用参数"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#常用参数"}},[t._v("#")]),t._v(" 常用参数")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 更多编码选项")]),t._v("\nembeddings "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("encode"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    sentences"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    batch_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("           "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 批处理大小")]),t._v("\n    show_progress_bar"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 显示进度条")]),t._v("\n    convert_to_tensor"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 转换为tensor")]),t._v("\n    normalize_embeddings"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 归一化向量")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"常用预训练模型"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#常用预训练模型"}},[t._v("#")]),t._v(" 常用预训练模型")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("all-MiniLM-L6-v2")]),t._v(": 轻量级，平衡性能与速度")]),t._v(" "),s("li",[s("code",[t._v("paraphrase-multilingual-MiniLM-L12-v2")]),t._v(": 多语言支持")]),t._v(" "),s("li",[s("code",[t._v("all-mpnet-base-v2")]),t._v(": 高质量，计算量较大")])]),t._v(" "),s("h2",{attrs:{id:"agglomerativeclustering"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#agglomerativeclustering"}},[t._v("#")]),t._v(" AgglomerativeClustering")]),t._v(" "),s("h3",{attrs:{id:"基本介绍-2"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#基本介绍-2"}},[t._v("#")]),t._v(" 基本介绍")]),t._v(" "),s("p",[t._v("层次聚类算法，通过自底向上合并相似的数据点形成聚类。")]),t._v(" "),s("h3",{attrs:{id:"基本用法-2"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#基本用法-2"}},[t._v("#")]),t._v(" 基本用法")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cluster "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" AgglomerativeClustering\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 创建聚类器")]),t._v("\nclustering "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AgglomerativeClustering"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    n_clusters"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 聚类数量")]),t._v("\n    affinity"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'cosine'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 距离度量")]),t._v("\n    linkage"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'average'")]),t._v("    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 链接方式")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 执行聚类")]),t._v("\nlabels "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" clustering"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit_predict"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("embeddings"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h4",{attrs:{id:"scikit-learn-版本变化说明"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#scikit-learn-版本变化说明"}},[t._v("#")]),t._v(" scikit-learn 版本变化说明")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("旧版 (<1.4.0)")]),t._v(": 使用 "),s("code",[t._v("affinity")]),t._v(" 参数")]),t._v(" "),s("li",[s("strong",[t._v("新版 (≥1.4.0)")]),t._v(": 使用 "),s("code",[t._v("metric")]),t._v(" 参数，"),s("code",[t._v("affinity")]),t._v(" 被弃用")])]),t._v(" "),s("h3",{attrs:{id:"主要参数"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#主要参数"}},[t._v("#")]),t._v(" 主要参数")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("n_clusters")]),t._v(": 聚类数量（如果不确定，可设为None）")]),t._v(" "),s("li",[s("code",[t._v("affinity")]),t._v(": 距离度量方法\n"),s("ul",[s("li",[s("code",[t._v("cosine")]),t._v(": 余弦距离（适合文本）")]),t._v(" "),s("li",[s("code",[t._v("euclidean")]),t._v(": 欧氏距离")]),t._v(" "),s("li",[s("code",[t._v("manhattan")]),t._v(": 曼哈顿距离")])])]),t._v(" "),s("li",[s("code",[t._v("linkage")]),t._v(": 链接策略\n"),s("ul",[s("li",[s("code",[t._v("ward")]),t._v(": 最小化方差（只适用于欧氏距离）")]),t._v(" "),s("li",[s("code",[t._v("average")]),t._v(": 平均距离")]),t._v(" "),s("li",[s("code",[t._v("complete")]),t._v(": 最大距离")]),t._v(" "),s("li",[s("code",[t._v("single")]),t._v(": 最小距离")])])])]),t._v(" "),s("h3",{attrs:{id:"自动确定聚类数量"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#自动确定聚类数量"}},[t._v("#")]),t._v(" 自动确定聚类数量")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 不指定聚类数量，通过距离阈值确定")]),t._v("\nclustering "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AgglomerativeClustering"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    n_clusters"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    distance_threshold"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 距离阈值")]),t._v("\n    affinity"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'cosine'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    linkage"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'average'")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h2",{attrs:{id:"完整示例-文本聚类"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#完整示例-文本聚类"}},[t._v("#")]),t._v(" 完整示例：文本聚类")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sentence_transformers "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" SentenceTransformer\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cluster "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" AgglomerativeClustering\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 示例文本数据")]),t._v("\ndocuments "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"我喜欢吃苹果和香蕉"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"今天天气真好，适合出去玩"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"水果对健康很有好处"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"明天可能要下雨，记得带伞"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"苹果和香蕉都是常见的水果"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"户外活动让人心情愉悦"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"天气预报说今天晴朗"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"多吃水果可以补充维生素"')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1. 将文本转换为向量")]),t._v("\nmodel "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SentenceTransformer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'paraphrase-multilingual-MiniLM-L12-v2'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nembeddings "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("encode"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("documents"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2. 执行层次聚类")]),t._v("\nclustering "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AgglomerativeClustering"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    n_clusters"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    affinity"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'cosine'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    linkage"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'average'")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ncluster_labels "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" clustering"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit_predict"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("embeddings"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3. 查看结果")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("doc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" label"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("enumerate")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("zip")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("documents"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cluster_labels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"聚类 ')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("label"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v(": ")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("doc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 4. 统计每个聚类的文档数量")]),t._v("\nunique_labels "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("unique"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cluster_labels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" label "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" unique_labels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    count "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cluster_labels "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" label"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"聚类 ')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("label"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v(" 有 ")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("count"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v(' 个文档"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h2",{attrs:{id:"可视化聚类结果"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#可视化聚类结果"}},[t._v("#")]),t._v(" 可视化聚类结果")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" matplotlib"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pyplot "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" plt\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("manifold "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" TSNE\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用t-SNE降维可视化")]),t._v("\ntsne "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" TSNE"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("n_components"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" random_state"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nembeddings_2d "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tsne"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit_transform"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("embeddings"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nplt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("figure"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("figsize"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nscatter "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" plt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scatter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("embeddings_2d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" embeddings_2d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                     c"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("cluster_labels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cmap"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'viridis'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("colorbar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("scatter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("title"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'文本聚类可视化'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h2",{attrs:{id:"应用场景"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#应用场景"}},[t._v("#")]),t._v(" 应用场景")]),t._v(" "),s("ol",[s("li",[s("strong",[t._v("文档分类")]),t._v(": 将相似文档自动分组")]),t._v(" "),s("li",[s("strong",[t._v("话题发现")]),t._v(": 从大量文本中发现主要话题")]),t._v(" "),s("li",[s("strong",[t._v("推荐系统")]),t._v(": 找到相似内容的项目")]),t._v(" "),s("li",[s("strong",[t._v("数据清洗")]),t._v(": 识别和合并相似的文本条目")])]),t._v(" "),s("p",[t._v("这种组合特别适合处理文本数据，因为SentenceTransformer能很好地捕捉语义信息，而层次聚类不需要预先指定聚类数量，可以发现数据中自然的分组结构。")])])}),[],!1,null,null,null);s.default=e.exports}}]);