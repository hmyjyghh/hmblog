(window.webpackJsonp=window.webpackJsonp||[]).push([[85],{567:function(t,a,s){"use strict";s.r(a);var n=s(3),r=Object(n.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("p",[a("code",[t._v("requires_grad")]),t._v(" 是 PyTorch 中张量的一个重要属性，用于"),a("strong",[t._v("控制梯度计算和参数更新")]),t._v("。")]),t._v(" "),a("h2",{attrs:{id:"_1-基本含义"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-基本含义"}},[t._v("#")]),t._v(" 1. 基本含义")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("requires_grad=True")]),t._v("："),a("strong",[t._v("需要计算梯度")]),t._v("，参与反向传播和参数更新")]),t._v(" "),a("li",[a("code",[t._v("requires_grad=False")]),t._v("："),a("strong",[t._v("不需要计算梯度")]),t._v("，在训练过程中被冻结")])]),t._v(" "),a("h2",{attrs:{id:"_2-在-lora-中的作用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-在-lora-中的作用"}},[t._v("#")]),t._v(" 2. 在 LoRA 中的作用")]),t._v(" "),a("p",[t._v("在你手撕 LoRA 类的场景中：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 冻结原来的层的参数")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" param "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("base_layer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parameters"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  param"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("requires_grad "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n")])])]),a("p",[t._v("这意味着：")]),t._v(" "),a("ul",[a("li",[t._v("✅ "),a("strong",[t._v("原始权重被冻结")]),t._v("，不参与训练")]),t._v(" "),a("li",[t._v("✅ "),a("strong",[t._v("只有 LoRA 的适配器参数会被更新")])]),t._v(" "),a("li",[t._v("✅ "),a("strong",[t._v("大幅减少训练参数量和内存占用")])])]),t._v(" "),a("h2",{attrs:{id:"_3-实际示例"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-实际示例"}},[t._v("#")]),t._v(" 3. 实际示例")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" nn\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 假设这是你的原始线性层")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("LoRAWrapper")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Module"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" base_layer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" rank"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("super")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__init__"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("base_layer "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" base_layer\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lora_A "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("base_layer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("in_features"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" rank"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bias"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lora_B "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rank"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" base_layer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out_features"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bias"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        \n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 冻结原始层参数")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" param "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("base_layer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parameters"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            param"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("requires_grad "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 🎯 关键步骤！")]),t._v("\n        \n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# LoRA 参数默认 requires_grad=True")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 所以只有这些参数会被训练")]),t._v("\n    \n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("forward")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        base_output "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("base_layer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        lora_output "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lora_B"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lora_A"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" base_output "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" lora_output\n")])])]),a("h2",{attrs:{id:"_4-验证效果"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-验证效果"}},[t._v("#")]),t._v(" 4. 验证效果")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 创建模型")]),t._v("\nlinear_layer "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlora_model "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LoRAWrapper"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("linear_layer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 检查参数状态")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" param "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" lora_model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("named_parameters"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string-interpolation"}},[a("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"')]),a("span",{pre:!0,attrs:{class:"token interpolation"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v(": requires_grad = ")]),a("span",{pre:!0,attrs:{class:"token interpolation"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("param"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("requires_grad"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出示例：")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# base_layer.weight: requires_grad = False  # ❌ 冻结")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# base_layer.bias: requires_grad = False    # ❌ 冻结  ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# lora_A.weight: requires_grad = True       # ✅ 训练")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# lora_B.weight: requires_grad = True       # ✅ 训练")]),t._v("\n")])])]),a("h2",{attrs:{id:"_5-为什么重要"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-为什么重要"}},[t._v("#")]),t._v(" 5. 为什么重要？")]),t._v(" "),a("ol",[a("li",[a("strong",[t._v("参数效率")]),t._v("：只训练少量 LoRA 参数，而不是整个模型")]),t._v(" "),a("li",[a("strong",[t._v("防止灾难性遗忘")]),t._v("：保持预训练权重不变")]),t._v(" "),a("li",[a("strong",[t._v("内存优化")]),t._v("：减少梯度计算的内存开销")]),t._v(" "),a("li",[a("strong",[t._v("训练稳定性")]),t._v("：避免破坏预训练的知识")])]),t._v(" "),a("p",[t._v("这就是 LoRA 能够高效微调大模型的核心机制！")])])}),[],!1,null,null,null);a.default=r.exports}}]);