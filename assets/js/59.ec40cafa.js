(window.webpackJsonp=window.webpackJsonp||[]).push([[59],{543:function(t,_,v){"use strict";v.r(_);var a=v(3),r=Object(a.a)({},(function(){var t=this,_=t._self._c;return _("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[_("h3",{attrs:{id:"_1-说一下chatgpt的优缺点"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-说一下chatgpt的优缺点"}},[t._v("#")]),t._v(" 1. 说一下ChatGPT的优缺点")]),t._v(" "),_("ol",[_("li",[t._v("优点：\n"),_("ul",[_("li",[t._v("强大的语言理解和生成能力")]),t._v(" "),_("li",[t._v("广泛的应用场景")]),t._v(" "),_("li",[t._v("出色的上下文理解和多轮对话能力")]),t._v(" "),_("li",[t._v("多功能性与通用性")]),t._v(" "),_("li",[t._v("大幅提升效率")])])]),t._v(" "),_("li",[t._v("缺点：\n"),_("ul",[_("li",[t._v('模型"幻觉"')]),t._v(" "),_("li",[t._v("训练数据有截止日期、知识陈旧与缺乏实时性")]),t._v(" "),_("li",[t._v("计算资源需求高")]),t._v(" "),_("li",[t._v("可能产生偏见与有害内容")]),t._v(" "),_("li",[t._v("在专业领域深度不足")]),t._v(" "),_("li",[t._v("上下文长度限制")]),t._v(" "),_("li",[t._v("会让人们对它产生依赖，渐渐地缺乏独立思考的能力")])])])]),t._v(" "),_("h3",{attrs:{id:"_2-请简述下transformer基本流程"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-请简述下transformer基本流程"}},[t._v("#")]),t._v(" 2. 请简述下Transformer基本流程")]),t._v(" "),_("blockquote",[_("p",[t._v("简化流程: 输入 -> 编码（通过自注意力理解源序列） -> 解码（通过交叉注意力参考编码结果，并通过掩码自注意力生成目标序列） -> 输出。")])]),t._v(" "),_("ul",[_("li",[t._v("输入层：将输入的文本序列转换为向量表示")]),t._v(" "),_("li",[t._v("编码器层：将输入向量编码为上下文表示")]),t._v(" "),_("li",[t._v("解码器层：根据上下文表示生成输出序列")]),t._v(" "),_("li",[t._v("输出层：将输出向量转换为文本序列")]),t._v(" "),_("li",[t._v("位置编码：为了保留序列中单词的位置信息，引入位置编码")]),t._v(" "),_("li",[t._v("自注意力机制：模型通过自注意力机制来学习输入序列中不同位置之间的依赖关系")]),t._v(" "),_("li",[t._v("多头注意力机制：模型通过多头注意力机制来学习输入序列中不同位置之间的依赖关系")]),t._v(" "),_("li",[t._v("前馈神经网络：每个位置的表示通过前馈神经网络进行处理")]),t._v(" "),_("li",[t._v("层归一化：在每个子层之间引入层归一化，提高模型的训练稳定性")]),t._v(" "),_("li",[t._v("残差连接：引入残差连接，解决深度神经网络训练中的梯度消失问题")])]),t._v(" "),_("h3",{attrs:{id:"_3-为什么基于transformer的架构需要多头注意力机制"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_3-为什么基于transformer的架构需要多头注意力机制"}},[t._v("#")]),t._v(" 3. 为什么基于Transformer的架构需要多头注意力机制？")]),t._v(" "),_("ul",[_("li",[t._v("考察点，多头注意力机制，多头，多个专家，多个角度去分析和理解")])]),t._v(" "),_("blockquote",[_("p",[t._v("简单来说，"),_("strong",[t._v("多头机制允许模型同时从不同的“表示子空间”和不同“角度”关注输入信息，极大地增强了模型的表征能力和泛化能力。")])])]),t._v(" "),_("ol",[_("li",[t._v("克服单头注意力的局限性：增强模型的“视角”")]),t._v(" "),_("li",[t._v("并行捕捉多种类型的关系")]),t._v(" "),_("li",[t._v("增加模型的表征能力和稳健性")])]),t._v(" "),_("h4",{attrs:{id:"技术实现简述"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#技术实现简述"}},[t._v("#")]),t._v(" 技术实现简述")]),t._v(" "),_("p",[t._v("在技术上，多头注意力的实现非常优雅：")]),t._v(" "),_("ol",[_("li",[_("strong",[t._v("线性投影")]),t._v("：对于给定的输入，通过 "),_("code",[t._v("h")]),t._v(" 个（头的数量）不同的线性投影矩阵，分别生成 "),_("code",[t._v("h")]),t._v(" 套 "),_("strong",[t._v("Query、Key、Value")]),t._v(" 向量。")]),t._v(" "),_("li",[_("strong",[t._v("并行计算")]),t._v("：在这 "),_("code",[t._v("h")]),t._v(" 套投影上并行地执行缩放点积注意力计算，得到 "),_("code",[t._v("h")]),t._v(" 个输出矩阵。")]),t._v(" "),_("li",[_("strong",[t._v("拼接与融合")]),t._v("：将这 "),_("code",[t._v("h")]),t._v(" 个输出矩阵拼接起来，最后通过一个线性层进行融合，将信息整合回原始的维度。")])]),t._v(" "),_("h3",{attrs:{id:"_4-编码器-解码器-编解码llm的区别"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_4-编码器-解码器-编解码llm的区别"}},[t._v("#")]),t._v(" 4. 编码器，解码器，编解码LLM的区别？")]),t._v(" "),_("ul",[_("li",[t._v("编码器：将输入序列编码为上下文表示")]),t._v(" "),_("li",[t._v("解码器：根据上下文表示生成输出序列")]),t._v(" "),_("li",[t._v("编解码LLM：同时进行编码和解码，生成输出序列")])]),t._v(" "),_("table",[_("thead",[_("tr",[_("th",{staticStyle:{"text-align":"left"}},[t._v("特性")]),t._v(" "),_("th",{staticStyle:{"text-align":"left"}},[t._v("编码器-仅编码")]),t._v(" "),_("th",{staticStyle:{"text-align":"left"}},[t._v("解码器-仅解码")]),t._v(" "),_("th",{staticStyle:{"text-align":"left"}},[t._v("编码器-解码器")])])]),t._v(" "),_("tbody",[_("tr",[_("td",{staticStyle:{"text-align":"left"}},[_("strong",[t._v("核心注意力")])]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[t._v("双向注意力")]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[t._v("因果/掩码注意力")]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[t._v("编码器：双向"),_("br"),t._v("解码器：因果 + "),_("strong",[t._v("交叉注意力")])])]),t._v(" "),_("tr",[_("td",{staticStyle:{"text-align":"left"}},[_("strong",[t._v("训练目标")])]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[t._v("掩码语言建模")]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[t._v("自回归语言建模")]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[t._v("序列到序列学习")])]),t._v(" "),_("tr",[_("td",{staticStyle:{"text-align":"left"}},[_("strong",[t._v("信息流")])]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[t._v("看到整个输入")]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[t._v("只能看到左侧上下文")]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[t._v("编码器看全源序列，解码器自回归生成目标序列")])]),t._v(" "),_("tr",[_("td",{staticStyle:{"text-align":"left"}},[_("strong",[t._v("核心能力")])]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[_("strong",[t._v("理解")])]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[_("strong",[t._v("生成")])]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[_("strong",[t._v("转换")])])]),t._v(" "),_("tr",[_("td",{staticStyle:{"text-align":"left"}},[_("strong",[t._v("代表模型")])]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[t._v("BERT, RoBERTa")]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[t._v("GPT系列, LLaMA")]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[t._v("T5, BART, 原始Transformer")])]),t._v(" "),_("tr",[_("td",{staticStyle:{"text-align":"left"}},[_("strong",[t._v("类比")])]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[_("strong",[t._v("阅读理解专家")])]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[_("strong",[t._v("故事讲述者")])]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[_("strong",[t._v("翻译官")])])])])]),t._v(" "),_("h3",{attrs:{id:"_5-在语言模型中强化学习的概念-它如何应用于chatgpt"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_5-在语言模型中强化学习的概念-它如何应用于chatgpt"}},[t._v("#")]),t._v(" 5. 在语言模型中强化学习的概念?它如何应用于ChatGPT？")]),t._v(" "),_("ul",[_("li",[t._v("强化学习里面包含，Action、State、Reward Model、Policy、Value Function等")]),t._v(" "),_("li",[t._v("Action：模型可以执行的操作")]),t._v(" "),_("li",[t._v("State：模型当前的状态")]),t._v(" "),_("li",[t._v("Reward Model：用于评估模型执行 Action 后的奖励")]),t._v(" "),_("li",[t._v("Policy：模型的策略，用于选择 Action")]),t._v(" "),_("li",[t._v("Value Function：模型的价值函数，用于评估模型在当前状态下的价值")]),t._v(" "),_("li",[t._v("强化学习，可以根据用户反馈或动作，根据得分及时更新策略，以循序渐进地形式，得到最大期望回报")]),t._v(" "),_("li",[t._v("强化学习里面的奖励信号可以是用户的反馈，也可以是模型自己的反馈")]),t._v(" "),_("li",[t._v("强化学习是一种通过奖励信号来训练模型的方法")]),t._v(" "),_("li",[t._v("强化学习可以应用于ChatGPT，通过与用户的交互来训练模型，使模型能够生成更符合用户需求的文本")])]),t._v(" "),_("h3",{attrs:{id:"_6-在gpt模型中-什么是温度系数"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_6-在gpt模型中-什么是温度系数"}},[t._v("#")]),t._v(" 6. 在GPT模型中，什么是温度系数？")]),t._v(" "),_("blockquote",[_("p",[t._v("温度系数是一个控制生成文本随机性和创造性的超参数。")])]),t._v(" "),_("ul",[_("li",[t._v("温度系数是一个超参数，用于控制模型的输出分布的多样性")]),t._v(" "),_("li",[t._v("温度系数越小，模型的输出分布越集中，模型的输出结果越确定")]),t._v(" "),_("li",[t._v("温度系数越大，模型的输出分布越分散，模型的输出结果越随机")])]),t._v(" "),_("h3",{attrs:{id:"_7-什么是旋转位置编码-rotary-position-encoding-简称rope"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_7-什么是旋转位置编码-rotary-position-encoding-简称rope"}},[t._v("#")]),t._v(" 7. 什么是旋转位置编码(Rotary Position Encoding)，简称ROPE？")]),t._v(" "),_("ul",[_("li",[t._v("旋转位置编码是一种用于Transformer模型的位置编码方法")]),t._v(" "),_("li",[t._v("旋转位置编码的核心思想是，将位置编码的维度分为两部分，分别对这两部分进行旋转")]),t._v(" "),_("li",[t._v("旋转位置编码的优势是，它可以保持模型的平移不变性，同时也可以保持模型的旋转不变性")]),t._v(" "),_("li",[t._v("旋转位置编码的劣势是，它的计算复杂度较高")])]),t._v(" "),_("h3",{attrs:{id:"_8-为什么现在的大模型大多是decoder-only的架构"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_8-为什么现在的大模型大多是decoder-only的架构"}},[t._v("#")]),t._v(" 8. 为什么现在的大模型大多是decoder-only的架构？")]),t._v(" "),_("ul",[_("li",[_("p",[_("strong",[t._v("Decoder 的天然属性")]),t._v("：Decoder-only 架构本身就是为自回归生成而设计的。它的核心机制是"),_("strong",[t._v("因果掩码")]),t._v("，确保在生成每个词时，只能看到它之前的词，而无法看到未来的词。这与文本生成的过程完全一致。")])]),t._v(" "),_("li",[_("p",[_("strong",[t._v("计算效率")]),t._v("：Decoder-only 模型架构"),_("strong",[t._v("高度统一和简化")]),t._v("。无论是预训练还是微调，它都在执行同一个核心任务：预测下一个词。这意味着整个计算图非常高效，可以更好地利用大规模并行计算（如 GPU/TPU）。")])]),t._v(" "),_("li",[_("p",[_("strong",[t._v("参数效率")]),t._v("：在 Encoder-Decoder 架构中，参数被分摊到两个结构不同的组件中。而有研究表明，在计算预算固定的情况下，**将所有参数集中在一个庞大的、统一的 Decoder 中，比将其分割给 Encoder 和 Decoder 能带来更好的性能。**即“大力出奇迹”的策略在 Decoder-only 模型上更有效。")])]),t._v(" "),_("li",[_("p",[t._v("scaling Laws（缩放定律）：OpenAI 等机构提出的缩放定律表明，模型的性能与模型大小、数据量和计算量之间存在可预测的幂律关系。"),_("strong",[t._v("Decoder-only 架构被证明是沿着这条 scaling law 进行扩展的最直接、最可靠的路径。")])])])]),t._v(" "),_("p",[t._v("总之，Decoder-only 架构成为主流，本质上"),_("strong",[t._v("是因为它在“生成能力”这个核心目标上，与任务本身最匹配")]),t._v("，并且在当今“算力为王”的时代，"),_("strong",[t._v("提供了最优的扩展性、效率和性能平衡。")])]),t._v(" "),_("h3",{attrs:{id:"_9-chatgpt的训练步骤有哪些"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_9-chatgpt的训练步骤有哪些"}},[t._v("#")]),t._v(" 9. ChatGPT的训练步骤有哪些？")]),t._v(" "),_("p",[_("img",{attrs:{src:"/hmblog/images/chat-gpt/chat-gpt-train.png",alt:"ChatGPT的训练步骤"}})]),t._v(" "),_("ol",[_("li",[t._v("第1步：预训练 - 构建知识基础")]),t._v(" "),_("li",[t._v("第2步：监督微调 - 学会对话格式")]),t._v(" "),_("li",[t._v("第3步：从人类反馈中强化学习 - 对齐人类偏好\n"),_("ul",[_("li",[t._v("3.1 训练奖励模型")]),t._v(" "),_("li",[t._v("3.2 使用强化学习优化策略")])])])]),t._v(" "),_("h3",{attrs:{id:"_10-为什么transformer模型需要位置编码"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_10-为什么transformer模型需要位置编码"}},[t._v("#")]),t._v(" 10. 为什么Transformer模型需要位置编码？")]),t._v(" "),_("ul",[_("li",[t._v("在 Transformer 模型中，由于不是循环（RNN）结构，模型本身无法捕捉输入序列中元素的位置信息。")]),t._v(" "),_("li",[t._v("因为Transformer的核心自注意力机制本身是“位置无关”的，它无法感知词语的顺序信息，而顺序对于理解语言至关重要。")])]),t._v(" "),_("h3",{attrs:{id:"_11-为什么对于chatgpt而言-提示工程很重要"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_11-为什么对于chatgpt而言-提示工程很重要"}},[t._v("#")]),t._v(" 11. 为什么对于ChatGPT而言，提示工程很重要？")]),t._v(" "),_("ul",[_("li",[t._v("帮助模型理解用户的意图，从而生成符合用户需求的文本")]),t._v(" "),_("li",[t._v("设定角色与人格：控制输出的风格和立场")]),t._v(" "),_("li",[t._v("提示工程是约束模型、让其忠于事实的强大工具。")]),t._v(" "),_("li",[t._v("实现复杂、多步骤的任务分解")])]),t._v(" "),_("p",[t._v("对于复杂任务，一个简单的指令会让模型不知所措。提示工程教你如何将大任务拆解为清晰的、可执行的步骤。")]),t._v(" "),_("ul",[_("li",[_("strong",[t._v("混乱的提示")]),t._v("："),_("code",[t._v('"帮我写一份市场计划，要关于新产品，包括社交媒体、预算和竞争对手分析。"')])]),t._v(" "),_("li",[_("strong",[t._v("工程化的提示")]),t._v("：\n"),_("ol",[_("li",[_("strong",[t._v("目标")]),t._v("："),_("code",[t._v('"为一款新的环保水瓶制定一份简要的市场计划。"')])]),t._v(" "),_("li",[_("strong",[t._v("步骤一")]),t._v("："),_("code",[t._v('"首先，分析当前市场上3个主要竞争对手及其优劣势。"')])]),t._v(" "),_("li",[_("strong",[t._v("步骤二")]),t._v("："),_("code",[t._v('"其次，提出一个针对千禧一代的社交媒体推广策略，包括建议使用的平台和内容类型。"')])]),t._v(" "),_("li",[_("strong",[t._v("步骤三")]),t._v("："),_("code",[t._v('"最后，草拟一个初步的月度预算分配表。"')])])])])]),t._v(" "),_("h3",{attrs:{id:"_12-如何缓解llms复读机问题"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_12-如何缓解llms复读机问题"}},[t._v("#")]),t._v(" 12. 如何缓解LLMs复读机问题？")]),t._v(" "),_("p",[t._v("要缓解这个问题，我们需要一个多管齐下的策略，主要从"),_("strong",[t._v("解码策略")]),t._v("、"),_("strong",[t._v("提示工程")]),t._v("和"),_("strong",[t._v("模型层面")]),t._v("入手。")]),t._v(" "),_("p",[_("img",{attrs:{src:"/hmblog/images/chat-gpt/LLM-repeat.png",alt:""}})]),t._v(" "),_("ul",[_("li",[t._v("因为LLMs模型的输出结果，是根据输入的提示词，生成的文本")]),t._v(" "),_("li",[t._v("所以，为了避免LLMs模型重复输出相同的文本，我们可以在提示词中，加入一些随机的噪声，如添加随机的单词、句子、段落等")]),t._v(" "),_("li",[t._v("这样，就可以避免LLMs模型重复输出相同的文本")]),t._v(" "),_("li",[t._v("同时，也可以避免LLMs模型输出重复的句子")])]),t._v(" "),_("h2",{attrs:{id:"阶段二"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#阶段二"}},[t._v("#")]),t._v(" 阶段二")]),t._v(" "),_("h3",{attrs:{id:"_1-解释下langchain-agent的概念"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-解释下langchain-agent的概念"}},[t._v("#")]),t._v(" 1. 解释下langchain Agent的概念？")]),t._v(" "),_("ul",[_("li",[t._v("它的核心能力是调用工具，拥有使用外部函数的能力，使智能Agent成为可能。")]),t._v(" "),_("li",[t._v("LLM 作为代理的“大脑”，负责推理、规划和决策，而工具则是它完成任务所依赖的外部手段。")]),t._v(" "),_("li",[t._v("具有 记忆能力 和  推理能力")]),t._v(" "),_("li",[t._v("LangChain提供了执行器(Agent Executor)，用来运行代理并执行其决策的工具。")])]),t._v(" "),_("h3",{attrs:{id:"_2-langchain的6大核心组件是什么-它们的作用分别是什么"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-langchain的6大核心组件是什么-它们的作用分别是什么"}},[t._v("#")]),t._v(" 2. langchain的6大核心组件是什么，它们的作用分别是什么？")]),t._v(" "),_("ul",[_("li",[t._v("模型（Models）：包含各大语言模型的LangChain接口和调用细节，以及输出解析机制。")]),t._v(" "),_("li",[t._v("提示模板（Prompts）：使提示工程流线化，进一步激发大语言模型的潜力。")]),t._v(" "),_("li",[t._v("数据检索（Indexes）：构建并操作文档的方法，接受用户的查询并返回最相关的文档，轻松搭建本地知识库。")]),t._v(" "),_("li",[t._v("记忆（Memory）：通过短时记忆和长时记忆，在对话过程中存储和检索数据，让ChatBot记住你。")]),t._v(" "),_("li",[t._v("链（Chains），以特定方式封装各种功能，并通过一系列的组合，自动而灵活地完成任务。")]),t._v(" "),_("li",[t._v("代理（Agents）：通过“代理”让大模型自主调用外部工具和内部工具，使智能Agent成为可能。")])]),t._v(" "),_("h3",{attrs:{id:"_3-langchain有哪些优点和明显的缺点"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_3-langchain有哪些优点和明显的缺点"}},[t._v("#")]),t._v(" 3. langchain有哪些优点和明显的缺点？")]),t._v(" "),_("blockquote",[_("p",[t._v("优点")])]),t._v(" "),_("div",{staticClass:"language- extra-class"},[_("pre",{pre:!0,attrs:{class:"language-text"}},[_("code",[t._v("1. 提供了大量的预置组件，让开发者可以快速构建应用\n2. 组件生态丰富\n3. LangChain提出的Chain、Agent、Tool、Memory等概念已经成为行业标准\n4. 社区活跃，文档完善\n")])])]),_("ol",[_("li",[t._v("快速原型开发能力")])]),t._v(" "),_("ul",[_("li",[t._v("它提供了高度抽象的概念和大量预制组件，让开发者可以像搭乐高一样快速构建LLM应用。")]),t._v(" "),_("li",[t._v("几行代码就能构建一个完整的RAG系统.")])]),t._v(" "),_("ol",{attrs:{start:"2"}},[_("li",[t._v("组件生态丰富")])]),t._v(" "),_("ul",[_("li",[t._v("50+ 文档加载器（PDF、HTML、Word、Notion等）")]),t._v(" "),_("li",[t._v("20+ 文本分割策略")]),t._v(" "),_("li",[t._v("30+ 向量数据库集成")]),t._v(" "),_("li",[t._v("10+ LLM提供商支持")])]),t._v(" "),_("ol",{attrs:{start:"3"}},[_("li",[t._v("LangChain提出的Chain、Agent、Tool、Memory等概念已经成为行业标准，帮助开发者建立心智模型：")])]),t._v(" "),_("ul",[_("li",[_("code",[t._v("Chain")]),t._v("：可复用的任务流水线")]),t._v(" "),_("li",[_("code",[t._v("Agent")]),t._v("：LLM驱动的决策系统")]),t._v(" "),_("li",[_("code",[t._v("Tool")]),t._v("：Agent可调用的函数")]),t._v(" "),_("li",[_("code",[t._v("Memory")]),t._v("：对话状态管理")])]),t._v(" "),_("ol",{attrs:{start:"4"}},[_("li",[_("strong",[t._v("社区活跃和文档完善")])])]),t._v(" "),_("ul",[_("li",[t._v("GitHub 80k+ stars，庞大的用户社区")]),t._v(" "),_("li",[t._v("详细的文档和示例代码")]),t._v(" "),_("li",[t._v("遇到问题容易找到解决方案")])]),t._v(" "),_("blockquote",[_("p",[t._v("缺点")])]),t._v(" "),_("ul",[_("li",[_("strong",[t._v("调试困难, 很难追踪问题")])]),t._v(" "),_("li",[t._v("性能开销")]),t._v(" "),_("li",[t._v("API 不稳定与快速迭代\n"),_("ul",[_("li",[t._v("LangChain 的 API 变化非常频繁，导致代码很容易过时，维护成本高。")])])]),t._v(" "),_("li",[t._v("灵活性不够\n"),_("ul",[_("li",[t._v("当需要实现一个非常定制化、非标准的功能时，LangChain 的“框框”可能会限制你。")])])])]),t._v(" "),_("h3",{attrs:{id:"_4-langchain有哪些替代方案"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_4-langchain有哪些替代方案"}},[t._v("#")]),t._v(" 4. langchain有哪些替代方案？")]),t._v(" "),_("p",[t._v("轻量级替代品的出现：像 LlamaIndex（更专注于 RAG 场景）和 LangGraph（由 LangChain 官方推出，用于构建有状态、多参与者的 Agent 应用）等工具，提供了更专注、更清晰的范式。")]),t._v(" "),_("ol",[_("li",[t._v("LlamaIndex")]),t._v(" "),_("li",[t._v("Haystack")]),t._v(" "),_("li",[t._v("Semantic Kernel（微软出品）")])]),t._v(" "),_("h4",{attrs:{id:"横向对比总结"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#横向对比总结"}},[t._v("#")]),t._v(" 横向对比总结")]),t._v(" "),_("table",[_("thead",[_("tr",[_("th",[t._v("维度")]),t._v(" "),_("th",[t._v("LangChain")]),t._v(" "),_("th",[t._v("LlamaIndex")]),t._v(" "),_("th",[t._v("Haystack")]),t._v(" "),_("th",[t._v("Semantic Kernel")])])]),t._v(" "),_("tbody",[_("tr",[_("td",[_("strong",[t._v("核心定位")])]),t._v(" "),_("td",[t._v("通用LLM应用框架")]),t._v(" "),_("td",[_("strong",[t._v("专业RAG框架")])]),t._v(" "),_("td",[t._v("NLP生产流水线")]),t._v(" "),_("td",[t._v("AI规划与集成框架")])]),t._v(" "),_("tr",[_("td",[_("strong",[t._v("设计哲学")])]),t._v(" "),_("td",[t._v("模块化组合")]),t._v(" "),_("td",[t._v("数据与检索优化")]),t._v(" "),_("td",[_("strong",[t._v("稳定流水线")])]),t._v(" "),_("td",[t._v("传统代码+AI规划")])]),t._v(" "),_("tr",[_("td",[_("strong",[t._v("学习曲线")])]),t._v(" "),_("td",[t._v("陡峭")]),t._v(" "),_("td",[t._v("中等")]),t._v(" "),_("td",[t._v("中等")]),t._v(" "),_("td",[t._v("较陡峭（概念独特）")])]),t._v(" "),_("tr",[_("td",[_("strong",[t._v("调试难度")])]),t._v(" "),_("td",[t._v("高（黑盒）")]),t._v(" "),_("td",[t._v("中等")]),t._v(" "),_("td",[_("strong",[t._v("低（清晰流水线）")])]),t._v(" "),_("td",[t._v("中等")])]),t._v(" "),_("tr",[_("td",[_("strong",[t._v("生产就绪")])]),t._v(" "),_("td",[t._v("中等")]),t._v(" "),_("td",[t._v("中等")]),t._v(" "),_("td",[_("strong",[t._v("高")])]),t._v(" "),_("td",[t._v("中等")])]),t._v(" "),_("tr",[_("td",[_("strong",[t._v("RAG专业性")])]),t._v(" "),_("td",[t._v("通用")]),t._v(" "),_("td",[_("strong",[t._v("最优")])]),t._v(" "),_("td",[t._v("良好")]),t._v(" "),_("td",[t._v("基础")])]),t._v(" "),_("tr",[_("td",[_("strong",[t._v("Agent支持")])]),t._v(" "),_("td",[_("strong",[t._v("强大")])]),t._v(" "),_("td",[t._v("有限")]),t._v(" "),_("td",[t._v("有限")]),t._v(" "),_("td",[t._v("独特规划方式")])]),t._v(" "),_("tr",[_("td",[_("strong",[t._v("生态集成")])]),t._v(" "),_("td",[_("strong",[t._v("最丰富")])]),t._v(" "),_("td",[t._v("专注数据源")]),t._v(" "),_("td",[t._v("良好")]),t._v(" "),_("td",[t._v("微软生态")])])])]),t._v(" "),_("h4",{attrs:{id:"如何选择"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#如何选择"}},[t._v("#")]),t._v(" 如何选择？")]),t._v(" "),_("p",[_("strong",[t._v("选择 LlamaIndex 如果：")])]),t._v(" "),_("ul",[_("li",[t._v("你主要就是做 RAG 应用")]),t._v(" "),_("li",[t._v("对检索质量有很高要求")]),t._v(" "),_("li",[t._v("想要更简单直接的 API")])]),t._v(" "),_("p",[_("strong",[t._v("选择 Haystack 如果：")])]),t._v(" "),_("ul",[_("li",[t._v("需要稳定部署到生产环境")]),t._v(" "),_("li",[t._v("重视可观测性和可维护性")]),t._v(" "),_("li",[t._v("构建的是复杂、多步骤的 NLP 流水线")])]),t._v(" "),_("p",[_("strong",[t._v("选择 Semantic Kernel 如果：")])]),t._v(" "),_("ul",[_("li",[t._v("你是微软技术栈用户")]),t._v(" "),_("li",[t._v("需要将 AI 深度集成到现有业务系统中")]),t._v(" "),_("li",[t._v("需要 AI 进行复杂的任务规划和分解")])]),t._v(" "),_("h3",{attrs:{id:"_5-什么是检索增强生成-rag"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_5-什么是检索增强生成-rag"}},[t._v("#")]),t._v(" 5. 什么是检索增强生成(RAG)？")]),t._v(" "),_("blockquote",[_("p",[t._v("通过检索外部数据，增强⼤模型的⽣成效果。")])]),t._v(" "),_("ul",[_("li",[t._v("RAG即检索增强⽣成，为LLM提供了从某些数据源检索到的信息，并基于此修正⽣成的答案。")]),t._v(" "),_("li",[t._v("RAG 基本上是Search + LLM 提示，可以通过⼤模型回答查询，并将搜索算法所找到的信息作为⼤模型的上下⽂。")]),t._v(" "),_("li",[t._v("查询和检索到的上下⽂都会被注⼊到发送到 LLM 的提示语中")])]),t._v(" "),_("h3",{attrs:{id:"_6-在做知识增强检索时-文本切分有哪些方法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_6-在做知识增强检索时-文本切分有哪些方法"}},[t._v("#")]),t._v(" 6. 在做知识增强检索时，文本切分有哪些方法？")]),t._v(" "),_("ul",[_("li",[t._v("按照句⼦来切分")]),t._v(" "),_("li",[t._v("按照字符数来切分")]),t._v(" "),_("li",[t._v("按固定字符数 结合overlap")]),t._v(" "),_("li",[t._v("递归⽅法：RecursiveCharacterTextSplitter")])]),t._v(" "),_("h3",{attrs:{id:"_7-目前主流的中文向量模型有哪些"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_7-目前主流的中文向量模型有哪些"}},[t._v("#")]),t._v(" 7. 目前主流的中文向量模型有哪些？")]),t._v(" "),_("table",[_("thead",[_("tr",[_("th",{staticStyle:{"text-align":"left"}},[t._v("模型系列 / 来源")]),t._v(" "),_("th",{staticStyle:{"text-align":"left"}},[t._v("代表性模型举例")]),t._v(" "),_("th",{staticStyle:{"text-align":"left"}},[t._v("核心特点与适用场景")])])]),t._v(" "),_("tbody",[_("tr",[_("td",{staticStyle:{"text-align":"left"}},[_("strong",[t._v("阿里通义千问 (Qwen)")])]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[_("code",[t._v("Qwen3-Embedding")]),t._v("系列 (如8B, 4B版本)")]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[t._v("专注于"),_("strong",[t._v("纯文本任务")]),t._v("，在MTEB等权威榜单上表现优异，支持超100种语言，适合智能搜索、文本分类和RAG 。")])]),t._v(" "),_("tr",[_("td",{staticStyle:{"text-align":"left"}},[_("strong",[t._v("智源研究院 (BGE)")])]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[_("code",[t._v("BGE-Code-v1")]),t._v(", "),_("code",[t._v("BGE-VL-v1.5")]),t._v(", "),_("code",[t._v("BGE-VL-Screenshot")])]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[t._v("生态丰富，覆盖"),_("strong",[t._v("代码、图文、截图")]),t._v("等多模态检索，在特定领域基准测试中成绩领先，适合需要处理非纯文本数据的场景 。")])]),t._v(" "),_("tr",[_("td",{staticStyle:{"text-align":"left"}},[_("strong",[t._v("火山引擎 (Seed)")])]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[_("code",[t._v("Seed1.6-Embedding")])]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[t._v("强调"),_("strong",[t._v("全模态")]),t._v("能力，支持文本、图像、视频的混合检索，提供自定义指令功能，适合复杂的多模态和跨模态搜索需求 。")])])])]),t._v(" "),_("blockquote",[_("p",[t._v("如果您的主要目的是构建一个高效的语义检索系统（例如用于RAG），那么选择BGE或Qwen-Embedding这类专用模型是更直接、更有效的方案。")])]),t._v(" "),_("h3",{attrs:{id:"_8-相比模型直接生成-rag的优势是什么"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_8-相比模型直接生成-rag的优势是什么"}},[t._v("#")]),t._v(" 8. 相比模型直接生成，RAG的优势是什么？")]),t._v(" "),_("ul",[_("li",[t._v("因为RAG是基于检索外部知识来生成的的，可以提高模型回答问题的准确性")]),t._v(" "),_("li",[t._v("直接生成是模型凭“记忆”和“直觉”回答问题，而 RAG 是让模型先“查阅资料”再回答问题。")])]),t._v(" "),_("blockquote",[_("p",[t._v("解决了直接生成的三大核心痛点")])]),t._v(" "),_("ol",[_("li",[t._v("知识滞后与事实性错误（幻觉）")]),t._v(" "),_("li",[t._v("无法溯源，可信度低")]),t._v(" "),_("li",[t._v("处理私有/领域知识时能力不足")])]),t._v(" "),_("h3",{attrs:{id:"_9-self-rag-是什么-self-rag如何提升大型语言模型的质量和准确性"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_9-self-rag-是什么-self-rag如何提升大型语言模型的质量和准确性"}},[t._v("#")]),t._v(" 9. SELF-RAG 是什么，SELF-RAG如何提升大型语言模型的质量和准确性？")]),t._v(" "),_("ul",[_("li",[_("strong",[t._v("SELF-RAG")]),t._v(" 是一种让LLM在生成过程中"),_("strong",[t._v("自我评估")]),t._v("、"),_("strong",[t._v("自我纠正")]),t._v("的框架。")]),t._v(" "),_("li",[t._v("与传统RAG不同，SELF-RAG让模型在生成每个段落时都主动决定是否需要检索、如何利用检索结果，以及评估生成内容的质量。")])]),t._v(" "),_("blockquote",[_("p",[t._v("SELF-RAG 流程")])]),t._v(" "),_("p",[t._v("用户提问 → 检索相关文档 → LLM 对文档进行批判性评估（反思） → 根据评估结果，有选择地、智能地利用文档 → 生成最终答案。")]),t._v(" "),_("p",[t._v("“反思”步骤是通过生成特殊的"),_("strong",[t._v("反思令牌（Special Tokens）")]),t._v(" 来实现的。这些令牌分为以下几类：")]),t._v(" "),_("ol",[_("li",[_("p",[_("strong",[t._v("检索令牌 - “要不要检索？”")])]),t._v(" "),_("ul",[_("li",[t._v("在生成答案的每一个阶段，模型会先自问：“我需要检索外部文档来帮助生成下一个段落吗？”")])])]),t._v(" "),_("li",[_("p",[_("strong",[t._v("相关性令牌 - “检索到的东西有用吗？”")])]),t._v(" "),_("ul",[_("li",[t._v("如果执行了检索，模型会评估每一篇检索到的文档。")])])]),t._v(" "),_("li",[_("p",[_("strong",[t._v("支持令牌 - “检索到的信息支持我的说法吗？”")])]),t._v(" "),_("ul",[_("li",[t._v("模型在生成具体陈述时，会判断该陈述是否得到了检索文档的支持。")])])]),t._v(" "),_("li",[_("p",[_("strong",[t._v("效用令牌 - “我生成的答案整体好吗？”")])]),t._v(" "),_("ul",[_("li",[t._v("最后，模型会对生成的完整段落进行整体评估。")]),t._v(" "),_("li",[t._v("评判标准："),_("code",[t._v("Good")]),t._v("， "),_("code",[t._v("Fair")]),t._v("， "),_("code",[t._v("Poor")]),t._v("。这确保了最终输出的综合质量。")])])])]),t._v(" "),_("blockquote",[_("p",[t._v("SELF-RAG 如何提升LLM的质量和准确性？")])]),t._v(" "),_("ol",[_("li",[_("p",[_("strong",[t._v("SELF-RAG")]),t._v("：通过 “支持令牌” ，模型只会生成有证据支持的陈述。如果证据不足或存在矛盾，模型会选择不生成或明确指出来，从而避免了传播错误信息。")])]),t._v(" "),_("li",[_("ul",[_("li",[t._v("模型不再是信息的被动接收者，而是主动的"),_("strong",[t._v("评估者")]),t._v("。它只会筛选并利用那些被它判定为 "),_("strong",[t._v("“相关”")]),t._v(" 和 "),_("strong",[t._v("“准确”")]),t._v(" 的信息，使得最终答案的根基更加牢固。")])])]),t._v(" "),_("li",[_("ul",[_("li",[t._v("而SELF-RAG可以识别出哪几篇是高度相关的，并"),_("strong",[t._v("重点利用")]),t._v("这些高质量信息，同时忽略或减少使用低质量信息。")])])]),t._v(" "),_("li",[_("ul",[_("li",[t._v("SELF-RAG 的输出可以附带其反思过程（例如，标注出哪些陈述有充分支持）。这为用户提供了"),_("strong",[t._v("可验证的线索")]),t._v("，让用户知道答案的来源和可信度，增强了模型的透明度和可信度。")])])]),t._v(" "),_("li",[_("ul",[_("li",[t._v("当模型自身知识足够时，它选择 "),_("code",[t._v("No Retrieve")]),t._v("，自信地回答；当不确定时，它主动检索 "),_("code",[t._v("Retrieve")]),t._v("；当检索结果不好时，它承认知识的局限性。这使得模型表现得更像一位严谨的专家，而不是一个不懂装懂的学生。")])])])]),t._v(" "),_("h3",{attrs:{id:"_10-rag-和-微调的区别是什么"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_10-rag-和-微调的区别是什么"}},[t._v("#")]),t._v(" 10. RAG 和 微调的区别是什么？")]),t._v(" "),_("ul",[_("li",[_("p",[t._v("RAG（检索增强⽣成）是把内部的⽂档数据先进⾏embedding，借助检索先获得⼤致的知识范围答案，再结合prompt给到LLM，让LLM⽣成最终的答案")])]),t._v(" "),_("li",[_("p",[t._v("Fine-tuning（微调）是⽤⼀定量的数据集对LLM进⾏局部参数的调整，以期望LLM更加理解我们的业务逻辑，有更好的zero-shot能⼒。")])])]),t._v(" "),_("h3",{attrs:{id:"_11-什么是graphrag"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_11-什么是graphrag"}},[t._v("#")]),t._v(" 11. 什么是GraphRAG？")]),t._v(" "),_("p",[t._v("GraphRAG 的核心思想是：将文档库中的信息提取并构建成"),_("strong",[t._v("一个结构化的知识图谱")]),t._v("，然后利用这个图谱来增强大模型的检索和推理能力。")]),t._v(" "),_("ul",[_("li",[_("strong",[t._v("GraphRAG")]),t._v("：先从文档中提取实体（如人物、地点、概念、事件）和它们之间的关系，构建一个知识图谱。检索时进行图遍历和关系推理。")])]),t._v(" "),_("blockquote",[_("p",[t._v("GraphRAG VS RAG")])]),t._v(" "),_("table",[_("thead",[_("tr",[_("th",{staticStyle:{"text-align":"left"}},[t._v("特性")]),t._v(" "),_("th",{staticStyle:{"text-align":"left"}},[t._v("传统 RAG")]),t._v(" "),_("th",{staticStyle:{"text-align":"left"}},[t._v("GraphRAG")])])]),t._v(" "),_("tbody",[_("tr",[_("td",{staticStyle:{"text-align":"left"}},[_("strong",[t._v("信息组织")])]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[t._v("扁平的文本片段")]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[t._v("结构化的关系网络")])]),t._v(" "),_("tr",[_("td",{staticStyle:{"text-align":"left"}},[_("strong",[t._v("检索方式")])]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[t._v("向量相似度")]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[_("strong",[t._v("关系与结构推理")])])]),t._v(" "),_("tr",[_("td",{staticStyle:{"text-align":"left"}},[_("strong",[t._v("推理能力")])]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[t._v("弱，基于局部上下文")]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[_("strong",[t._v("强，基于全局关系")])])]),t._v(" "),_("tr",[_("td",{staticStyle:{"text-align":"left"}},[_("strong",[t._v("可解释性")])]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[t._v("低（为什么检索这些片段？）")]),t._v(" "),_("td",{staticStyle:{"text-align":"left"}},[_("strong",[t._v("高（答案路径清晰可见）")])])])])]),t._v(" "),_("blockquote",[_("p",[t._v("GraphRAG 的典型应用场景\nGraphRAG 的优势决定了它更适合 “关联密集、需要推理” 的场景，而非简单的 “文本问答”：")])]),t._v(" "),_("ul",[_("li",[_("strong",[t._v("知识图谱问答（KGQA）")]),t._v("：如 “查询某明星的合作导演及其代表作”“某药物的适应症和禁忌症关联的疾病”；")]),t._v(" "),_("li",[_("strong",[t._v("商业情报分析")]),t._v("：如 “梳理某行业的产业链关系（上游原材料→中游制造→下游品牌）”“分析某公司的投资版图和竞争对手网络”；")]),t._v(" "),_("li",[_("strong",[t._v("事件脉络梳理")]),t._v("：如 “还原某历史事件的关键人物、时间线和因果关系（如‘二战主要战役的发起方和影响’）”；")]),t._v(" "),_("li",[_("strong",[t._v("合规与风控")]),t._v("：如 “核查某企业的股权穿透关系（是否存在关联交易）”“识别金融诈骗中的人物 - 账户 - 资金流向关联”。")])]),t._v(" "),_("h2",{attrs:{id:"阶段三"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#阶段三"}},[t._v("#")]),t._v(" 阶段三")]),t._v(" "),_("h3",{attrs:{id:"_1-prompt-design-prompt-tuning-fine-tuning-有什么区别"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-prompt-design-prompt-tuning-fine-tuning-有什么区别"}},[t._v("#")]),t._v(" 1. Prompt design, Prompt Tuning， Fine-tuning 有什么区别？")]),t._v(" "),_("blockquote",[_("p",[t._v("Prompt design：提示设计，或者叫"),_("code",[t._v("提示工程")])])]),t._v(" "),_("ol",[_("li",[t._v("**学习如何向模型“提问”。**你不动模型本身，只优化你的指令。")])]),t._v(" "),_("blockquote",[_("p",[t._v("Prompt Tuning：提示微调，即微调模型的提示词")])]),t._v(" "),_("ol",[_("li",[t._v("**教模型学会一种新的“内部提问方式”。**你给模型一些可以学习的“软提示”，而不是修改它的核心知识。")]),t._v(" "),_("li",[t._v("软提示有2种，1种是：soft prompt  1种是：hard prompt")])]),t._v(" "),_("blockquote",[_("p",[t._v("Fine-tuning：微调，即微调模型的参数")])]),t._v(" "),_("ul",[_("li",[t._v("全量微调的话: **给模型“回炉重造”，学习新专业。**你直接修改模型的核心参数，让它适应新任务。")])]),t._v(" "),_("ol",[_("li",[t._v("基于开源大模型进行微调，有全量参数微调，和 PEFT: 参数高效微调，也就是只有微调少量参数")])]),t._v(" "),_("h3",{attrs:{id:"_2-参数高效的fine-tuning-peft-是什么"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-参数高效的fine-tuning-peft-是什么"}},[t._v("#")]),t._v(" 2. 参数高效的fine-tuning(PEFT)是什么？")]),t._v(" "),_("p",[t._v("Parameter-Efficient Fine-Tuning")]),t._v(" "),_("ul",[_("li",[t._v("用一些策略，仅训练少量参数，大部分模型参数冻结")]),t._v(" "),_("li",[t._v("方法有：\n"),_("ul",[_("li",[t._v("适配器(Adapter)、软提示(Soft Prompts): Prompt Tuning、P-Tuning、Prefix-Tuning")]),t._v(" "),_("li",[t._v("模型参数冻结")]),t._v(" "),_("li",[t._v("LORA")])])])]),t._v(" "),_("h3",{attrs:{id:"_3-介绍一下prompt-tuning-技术"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_3-介绍一下prompt-tuning-技术"}},[t._v("#")]),t._v(" 3. 介绍一下Prompt-tuning 技术？")]),t._v(" "),_("p",[t._v("它的核心思想是："),_("strong",[t._v("冻结主模型参数，在训练数据前，加入一小段Prompt（只通过优化一小段可学习的“软提示”（Soft Prompt）），来激发模型解决特定任务的潜能。")])]),t._v(" "),_("ul",[_("li",[_("p",[t._v("只训练Prompt 的表示层，也就是一个Embedding 模块。")])]),t._v(" "),_("li",[_("p",[t._v("其中， Prompt 有两种形式， 一种是: hard prompt ， 一种是: soft prompt")])])]),t._v(" "),_("h4",{attrs:{id:"代码演示"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#代码演示"}},[t._v("#")]),t._v(" 代码演示")]),t._v(" "),_("div",{staticClass:"language-py extra-class"},[_("pre",{pre:!0,attrs:{class:"language-py"}},[_("code",[_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" peft "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" PromptTuningConfig"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" get_peft_model"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TaskType"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" PromptTuningInit\n\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Soft Prompt 不需要显示指定 prompt")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# config = PromptTuningConfig(task_type=TaskType.CAUSAL_LM, num_virtual_tokens=10)")]),t._v("\n\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Hard Prompt")]),t._v("\nconfig "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" PromptTuningConfig"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n   task_type"),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("TaskType"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("CAUSAL_LM"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n   prompt_tuning_init"),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("PromptTuningInit"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("TEXT"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n   prompt_tuning_init_text"),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),_("span",{pre:!0,attrs:{class:"token string"}},[t._v('"下面是一段人与机器人的对话。"')]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n   num_virtual_tokens"),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),_("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tokenizer"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),_("span",{pre:!0,attrs:{class:"token string"}},[t._v('"下面是一段人与机器人的对话。"')]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),_("span",{pre:!0,attrs:{class:"token string"}},[t._v('"input_ids"')]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n   tokenizer_name_or_path"),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),_("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Langboat/bloom-1b4-zh"')]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),_("h3",{attrs:{id:"_4-什么是prefix-tuning"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_4-什么是prefix-tuning"}},[t._v("#")]),t._v(" 4. 什么是Prefix Tuning？")]),t._v(" "),_("ul",[_("li",[t._v("核心思想：在每一层之前添加可学习的“前缀”。")]),t._v(" "),_("li",[t._v("相较于Prompt-Tuning和P-tuning,\n"),_("ul",[_("li",[t._v("Prefix-Tuning不再将Prompt加在输入的Embedding层,")]),t._v(" "),_("li",[t._v("而是将其作为可学习的前缀, 放置在Transsformer模型中的每一层中, 具体表现形式为past_key_values。")])])])]),t._v(" "),_("p",[_("img",{attrs:{src:"/hmblog//images/fine-tuning/Prefix-Tuning.png",alt:"Prefix Tuning"}})]),t._v(" "),_("ul",[_("li",[t._v("图中的Prefix Encoder 不会跟 右边的 Embedding 拼起来，而是会放到Transformer Blocks 层里，参与计算，")]),t._v(" "),_("li",[t._v("它是通过past_key_values 形式放进去的")])]),t._v(" "),_("p",[_("img",{attrs:{src:"/hmblog//images/fine-tuning/past_key_values.png",alt:"past_key_values"}})]),t._v(" "),_("ul",[_("li",[_("strong",[t._v("普通Prompt-Tuning")]),t._v("：只在模型的"),_("strong",[t._v("输入嵌入层（Input Embedding Layer）")]),t._v(" 添加可训练的提示向量。这相当于在对话开始时给模型一个总体的指令。")]),t._v(" "),_("li",[_("strong",[t._v("Prefix-Tuning")]),t._v("：不仅在输入层，而是在"),_("strong",[t._v("模型的每一层（或某几层）的激活（activation）之前")]),t._v("，都添加一组可训练的前缀向量。这相当于在模型思考的每一个步骤、每一个阶段都不断地进行引导和提醒，确保它不偏离轨道。")])]),t._v(" "),_("hr"),t._v(" "),_("p",[_("strong",[t._v("Prompt Tuning")]),t._v(" VS "),_("strong",[t._v("Prefix Tuning")])]),t._v(" "),_("ul",[_("li",[_("strong",[t._v("思想")]),t._v("：不修改模型本身，而是在输入序列前添加一些可训练的"),_("strong",[t._v("软提示向量")]),t._v("。模型通过这些提示向量来适应下游任务。")]),t._v(" "),_("li",[_("strong",[t._v("区别")]),t._v(":\n"),_("ul",[_("li",[t._v("Prompt Tuning 直接训练这些向量；")]),t._v(" "),_("li",[t._v("Prefix Tuning 通过一个小型的前馈网络来生成这些向量，训练的是这个网络的参数。")])])])]),t._v(" "),_("hr"),t._v(" "),_("h3",{attrs:{id:"_5-介绍下lora微调"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_5-介绍下lora微调"}},[t._v("#")]),t._v(" 5. 介绍下LORA微调？")]),t._v(" "),_("ul",[_("li",[t._v("在每一个要计算的大的矩阵(权重)旁边，新起一条分支，")]),t._v(" "),_("li",[t._v("这个分支的话，是由两个小矩阵组成, LoRA_A  和  LoRA_B")]),t._v(" "),_("li",[t._v("那我更新的时候只更新这两个小矩阵")]),t._v(" "),_("li",[t._v("训练完成之后，再把它合并回去，这就是LoRA")])]),t._v(" "),_("p",[_("img",{attrs:{src:"/hmblog//images/fine-tuning/Lora1.png",alt:"LoRA 的思想"}})]),t._v(" "),_("ul",[_("li",[t._v("LoRA 原理")])]),t._v(" "),_("p",[_("img",{attrs:{src:"/hmblog//images/fine-tuning/Lora2.png",alt:"Lora"}})]),t._v(" "),_("h3",{attrs:{id:"_6-相比lora-adalora的改进点是什么"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_6-相比lora-adalora的改进点是什么"}},[t._v("#")]),t._v(" 6. 相比LORA，AdaLoRA的改进点是什么？")]),t._v(" "),_("ul",[_("li",[_("strong",[t._v("思想")]),t._v("：LoRA 的自适应版本。它不是为所有选定的层分配固定的秩，而是根据重要性评分"),_("code",[t._v("动态地调整每个 LoRA 模块的秩（参数预算）")]),t._v("，将更多的参数分配给更重要的模块。")]),t._v(" "),_("li",[_("strong",[t._v("优势")]),t._v("：在相同的参数预算下，通常能获得比标准 LoRA 更好的性能。")])]),t._v(" "),_("blockquote",[_("p",[t._v("引入了3种关键技术")])]),t._v(" "),_("ol",[_("li",[_("strong",[t._v("参数重要性评分")])]),t._v(" "),_("li",[_("strong",[t._v("动态的预算分配和秩调整")])]),t._v(" "),_("li",[_("strong",[t._v("通过SVD参数化进行高效调整")])])]),t._v(" "),_("h4",{attrs:{id:"总结与类比"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结与类比"}},[t._v("#")]),t._v(" 总结与类比")]),t._v(" "),_("ul",[_("li",[_("strong",[t._v("LoRA")]),t._v(" 就像给公司每个部门分配"),_("strong",[t._v("固定且相同")]),t._v("的预算，不管这个部门是核心研发还是后勤支持。")]),t._v(" "),_("li",[_("strong",[t._v("AdaLoRA")]),t._v(" 则像一位"),_("strong",[t._v("精明的CEO")]),t._v("，他会根据每个部门的业绩（重要性分数）和公司总预算，定期进行审查：削减表现不佳部门的预算（修剪），并将资源重新分配给高绩效、高潜力的部门（生长）。")])]),t._v(" "),_("p",[t._v("因此，AdaLoRA的主要优势在于其"),_("strong",[t._v("自适应性")]),t._v("和"),_("strong",[t._v("效率")]),t._v("。")]),t._v(" "),_("h3",{attrs:{id:"_7-qlora模型有什么创新点"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_7-qlora模型有什么创新点"}},[t._v("#")]),t._v(" 7. QLORA模型有什么创新点？")]),t._v(" "),_("h3",{attrs:{id:"_8-稀疏微调是怎么工作的-有哪几个步骤"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_8-稀疏微调是怎么工作的-有哪几个步骤"}},[t._v("#")]),t._v(" 8. 稀疏微调是怎么工作的，有哪几个步骤？")]),t._v(" "),_("p",[_("strong",[t._v("只更新模型庞大参数中的一小部分（稀疏），而冻结其余大部分参数。")])]),t._v(" "),_("p",[t._v("目标： 极大地减少微调时需要更新的参数量。")]),t._v(" "),_("ul",[_("li",[t._v("核心思想是："),_("strong",[t._v("大型预训练模型已经包含了丰富的通用知识，对于特定的下游任务，我们只需要激发或调整其中与之相关的一小部分神经元或参数子集就足够了，而不需要动整个网络。")])])]),t._v(" "),_("p",[_("strong",[t._v("常见示例与步骤：")])]),t._v(" "),_("ol",[_("li",[_("strong",[t._v("只微调偏置项")]),t._v(" "),_("ul",[_("li",[_("strong",[t._v("步骤")]),t._v("：\n"),_("ul",[_("li",[t._v("冻结模型中所有的权重矩阵（如Linear、LayerNorm的权重）。")]),t._v(" "),_("li",[t._v("只将模型中所有的偏置项设置为可训练。")]),t._v(" "),_("li",[t._v("进行训练。由于偏置项的数量远少于权重，实现了稀疏更新。")])])])])]),t._v(" "),_("li",[_("strong",[t._v("只微调某几层")]),t._v(" "),_("ul",[_("li",[_("strong",[t._v("步骤")]),t._v("：\n"),_("ul",[_("li",[t._v("冻结模型的大部分层（例如，只更新最后4层Transformer块）。")]),t._v(" "),_("li",[t._v("只解冻靠近输出端的少数几层进行微调。")])])])])]),t._v(" "),_("li",[_("strong",[t._v("只微调注意力模块中的特定部分")]),t._v(" "),_("ul",[_("li",[_("strong",[t._v("步骤")]),t._v("：\n"),_("ul",[_("li",[t._v("冻结前馈神经网络。")]),t._v(" "),_("li",[t._v("只更新自注意力机制中的参数（如Query, Key, Value投影矩阵）。")])])])])])]),t._v(" "),_("h3",{attrs:{id:"方法三-基于附加稀疏适配器的微调-目前最流行"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#方法三-基于附加稀疏适配器的微调-目前最流行"}},[t._v("#")]),t._v(" 方法三：基于附加稀疏适配器的微调（目前最流行）")]),t._v(" "),_("p",[t._v("这是目前最主流的“稀疏微调”方式，也是"),_("strong",[t._v("Parameter-Efficient Fine-Tuning (PEFT)")]),t._v(" 的核心。它"),_("strong",[t._v("不直接更新原始模型参数")]),t._v("，而是"),_("strong",[t._v("引入一小部分额外的、可训练的参数（适配器）")]),t._v("，模型主体保持冻结。")]),t._v(" "),_("p",[_("strong",[t._v("工作原理：")])]),t._v(" "),_("ul",[_("li",[t._v("在预训练模型的架构中，插入一些小的、可训练的模块。")]),t._v(" "),_("li",[t._v("在微调时，"),_("strong",[t._v("只训练这些新增的适配器")]),t._v("，原始模型的"),_("strong",[t._v("所有参数都被冻结")]),t._v("。从参数更新的角度看，这是“稀疏”的，因为只有新增的那一小部分参数被更新。")])]),t._v(" "),_("p",[_("strong",[t._v("常见示例与步骤：")])]),t._v(" "),_("ol",[_("li",[_("strong",[t._v("LoRA及其变种")]),t._v(" "),_("ul",[_("li",[_("strong",[t._v("步骤")]),t._v("：\n"),_("ul",[_("li",[t._v("冻结整个预训练模型。")]),t._v(" "),_("li",[t._v("在原有的权重矩阵 ( W ) 旁，注入一个低秩适配器 ΔW = BA。")]),t._v(" "),_("li",[_("strong",[t._v("只训练 ( A ) 和 ( B ) 这两个小矩阵")]),t._v("。前向传播变为：( h = Wx + BAx )。")])])])])]),t._v(" "),_("li",[_("strong",[t._v("Adapter模块")]),t._v(" "),_("ul",[_("li",[_("strong",[t._v("步骤")]),t._v("：\n"),_("ul",[_("li",[t._v("冻结整个预训练模型。")]),t._v(" "),_("li",[t._v("在Transformer块中的前馈网络或注意力模块之后，插入一个小的前馈神经网络（Adapter）。")]),t._v(" "),_("li",[_("strong",[t._v("只训练这些插入的Adapter模块")]),t._v("。")])])])])])]),t._v(" "),_("p",[_("strong",[t._v("特点：")])]),t._v(" "),_("ul",[_("li",[_("strong",[t._v("附加式")]),t._v("：不改变原参数，而是增加新参数。")]),t._v(" "),_("li",[_("strong",[t._v("极高效")]),t._v("：通常参数量极小（仅为原模型的0.01%~1%）。")]),t._v(" "),_("li",[_("strong",[t._v("模块化与安全")]),t._v("：由于原模型不动，可以为一个模型创建多个适配器用于不同任务，且没有灾难性遗忘的风险。")])]),t._v(" "),_("h3",{attrs:{id:"_9-监督微调sft后llm表现下降的原因"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_9-监督微调sft后llm表现下降的原因"}},[t._v("#")]),t._v(" 9. 监督微调SFT后LLM表现下降的原因？")]),t._v(" "),_("ul",[_("li",[t._v("监督微调后模型表现下降，通常被称为 “灾难性遗忘” 或 “对齐税” 。")])]),t._v(" "),_("p",[_("img",{attrs:{src:"/hmblog/images/question/SFT-LLM.png",alt:"SFT 后LLM表现下降的原因分析"}})]),t._v(" "),_("h4",{attrs:{id:"如何缓解这些问题"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#如何缓解这些问题"}},[t._v("#")]),t._v(" 如何缓解这些问题？")]),t._v(" "),_("ol",[_("li",[_("strong",[t._v("提升数据质量")]),t._v("：精心清洗和构建SFT数据，确保正确性、多样性和高质量。"),_("strong",[t._v("“质量远胜于数量”")]),t._v(" 在SFT中尤其正确。")]),t._v(" "),_("li",[_("strong",[t._v("谨慎选择超参数")]),t._v("：使用"),_("strong",[t._v("较低的学习率")]),t._v("和"),_("strong",[t._v("较少的训练轮数")]),t._v("（通常1-3个epoch）。始终使用验证集来监控训练，防止过拟合。")]),t._v(" "),_("li",[_("strong",[t._v("使用参数高效微调技术")]),t._v("：如 "),_("strong",[t._v("LoRA")]),t._v("。这种方法只更新一小部分参数，大部分预训练参数保持不变，从而极大地减轻了灾难性遗忘。")])]),t._v(" "),_("h3",{attrs:{id:"_10-什么是p-tuning"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_10-什么是p-tuning"}},[t._v("#")]),t._v(" 10. 什么是P-Tuning？")]),t._v(" "),_("p",[t._v("P-Tuning的思想: 在Prompt-Tuning的基础上,对Prompt部分进行进一步的编码计算,加速收敛。")]),t._v(" "),_("ul",[_("li",[t._v("PEFT中支持两种编码方式,一种是LSTM,一种是MLP。")]),t._v(" "),_("li",[t._v("与Prompt-Tuning不同的是, Prompt的形式只有Soft Prompt。\n"),_("ul",[_("li",[t._v("MLP: 全连接层，3层全连接层")]),t._v(" "),_("li",[t._v("LSTM： 一层LSTM，2层全连接层")])])])]),t._v(" "),_("p",[_("img",{attrs:{src:"/hmblog//images/fine-tuning/P-Tuning.png",alt:"P-Tuning"}})]),t._v(" "),_("h3",{attrs:{id:"_11-多轮对话任务如何微调模型"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_11-多轮对话任务如何微调模型"}},[t._v("#")]),t._v(" 11. 多轮对话任务如何微调模型？")]),t._v(" "),_("p",[t._v("一. 选择PEFT 参数高效微调")]),t._v(" "),_("ol",[_("li",[t._v("选择 LoRA / QLoRA  或者 "),_("code",[t._v("Adapter")])]),t._v(" "),_("li",[t._v("对话格式构建与损失计算")]),t._v(" "),_("li",[t._v("step1: 构建带角色的对话模版")]),t._v(" "),_("li",[t._v("step2: 计算仅针对助理回复的损失")]),t._v(" "),_("li",[t._v("模型学会在上下文中生成回复")])]),t._v(" "),_("p",[_("strong",[t._v("LoRA")]),t._v(" 和 "),_("strong",[t._v("QLoRA")]),t._v("。它在全参数微调的基础上，引入了可训练的旁路矩阵，极大地降低了计算成本。")]),t._v(" "),_("p",[_("strong",[t._v("工作原理：")])]),t._v(" "),_("ol",[_("li",[t._v("冻结预训练模型的所有参数。")]),t._v(" "),_("li",[t._v("在模型的注意力层和全连接层旁，注入少量的可训练参数（LoRA 秩分解矩阵）。")]),t._v(" "),_("li",[t._v("训练时，只更新这些新增的参数，而不触动原始模型的巨大参数库。")])]),t._v(" "),_("p",[_("strong",[t._v("为什么PEFT对多轮对话特别有益？")])]),t._v(" "),_("ul",[_("li",[_("strong",[t._v("减轻灾难性遗忘")]),t._v("：多轮对话数据通常远少于预训练数据。PEFT 能更好地保留模型在预训练阶段获得的世界知识和语言能力，防止其因过度专注于学习对话结构而遗忘根本。")]),t._v(" "),_("li",[_("strong",[t._v("高效且成本低")]),t._v("：可以在消费级GPU上微调大模型。")]),t._v(" "),_("li",[_("strong",[t._v("模块化")]),t._v("：可以为不同的对话风格或任务训练不同的 LoRA 适配器，灵活切换。")])])])}),[],!1,null,null,null);_.default=r.exports}}]);