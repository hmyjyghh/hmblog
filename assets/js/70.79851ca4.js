(window.webpackJsonp=window.webpackJsonp||[]).push([[70],{516:function(t,s,a){"use strict";a.r(s);var n=a(3),r=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"数据分块"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#数据分块"}},[t._v("#")]),t._v(" 数据分块")]),t._v(" "),s("h3",{attrs:{id:"_1-什么是分块-为什么要做数据分块"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-什么是分块-为什么要做数据分块"}},[t._v("#")]),t._v(" 1. 什么是分块? 为什么要做数据分块?")]),t._v(" "),s("blockquote",[s("p",[t._v("分块就是把"),s("strong",[t._v("大段文本拆分成更小的片段")]),t._v("。")])]),t._v(" "),s("ul",[s("li",[t._v("这些更小的片段会被存储在"),s("code",[t._v("向量数据库")]),t._v("中, 方便后续"),s("strong",[t._v("检索")]),t._v(", 作为LLM生成答案的基础, 也就是作为LLM的上下文。")])]),t._v(" "),s("blockquote",[s("p",[t._v("为什么要做数据分块?")])]),t._v(" "),s("ul",[s("li",[t._v("分块的主要原因是为了确保我们"),s("strong",[t._v("嵌入的内容尽可能少的噪音")]),t._v(", "),s("strong",[t._v("同时仍然保持语义上的相关性")]),t._v("。")]),t._v(" "),s("li",[t._v("这对语言模型的输出是有显著的影响的, 提供精确且最相关的信息会大大提高LLM的准确性。")])]),t._v(" "),s("blockquote",[s("p",[t._v("总的来说，数据分块是为了：")])]),t._v(" "),s("ul",[s("li",[t._v("优化相关性: 分块有助于优化从"),s("code",[t._v("向量数据库")]),t._v("中检索内容的相关性。")]),t._v(" "),s("li",[t._v("减少噪音: 主要是为了确保我们"),s("strong",[t._v("嵌入的内容有尽可能少的噪音")]),t._v(", 同时保持语义相关。")]),t._v(" "),s("li",[t._v("改善搜索结果: 通过有效的分块策略, 我们可以确保搜索结果准确地捕捉到用户查询的核心。")]),t._v(" "),s("li",[t._v("管理token限制: 这有助于管理我们在每次请求中可以发送的token数量限制。")])]),t._v(" "),s("h3",{attrs:{id:"_2-影响分块大小的因素有哪些"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-影响分块大小的因素有哪些"}},[t._v("#")]),t._v(" 2. 影响分块大小的因素有哪些?")]),t._v(" "),s("ol",[s("li",[t._v("embedding 模型的选择")]),t._v(" "),s("li",[t._v("用户Query")]),t._v(" "),s("li",[t._v("分块的利用")])]),t._v(" "),s("blockquote",[s("p",[t._v("检索到一个分块后, 需要考虑"),s("strong",[t._v("如何在具体应用中利用这些结果")]),t._v("。比如:")])]),t._v(" "),s("ul",[s("li",[t._v("LLM的token限制是多少?")]),t._v(" "),s("li",[t._v("我们希望在一次LLM请求中包含多少个分块?")]),t._v(" "),s("li",[t._v("我们是否在使用LLM的链式结构, 也就是一个模型的输出传递给另一个模型?")])]),t._v(" "),s("h3",{attrs:{id:"_3-有哪些数据分块的方法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-有哪些数据分块的方法"}},[t._v("#")]),t._v(" 3. 有哪些数据分块的方法?")]),t._v(" "),s("ol",[s("li",[t._v("固定大小的分块")]),t._v(" "),s("li",[t._v("内容感知分块，包括句子分割, 递归分块, 特殊分块。")]),t._v(" "),s("li",[t._v("特殊分块，eg: MarkDown、LaTex")])]),t._v(" "),s("ul",[s("li",[t._v("固定大小的分块")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 可以使用langchain 里面的 `CharacterTextSplitter` 方法")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text_splitter "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" CharacterTextSplitter\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 初始化 CharacterTextSplitter")]),t._v("\ntext_splitter "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" CharacterTextSplitter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    separator"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\n"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 指定分隔符（默认是\\n\\n）")]),t._v("\n    chunk_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 每个分块的最大字符数")]),t._v("\n    chunk_overlap"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 分块间重叠字符数（避免语义断裂）")]),t._v("\n    length_function"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 计算长度的函数（默认按字符数）")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("ul",[s("li",[t._v("递归分块")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text_splitter "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" RecursiveCharacterTextSplitter\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 初始化 RecursiveCharacterTextSplitter")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 分隔符优先级：先按段落（\\n\\n）、再按换行（\\n）、再按句子（.）、最后按字符")]),t._v("\ntext_splitter "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RecursiveCharacterTextSplitter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    chunk_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("80")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("          "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 每个分块最大字符数")]),t._v("\n    chunk_overlap"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("       "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 分块间重叠字符数（保留上下文）")]),t._v("\n    separators"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\n\\n"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\n"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('". "')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 自定义分隔符优先级（按语义从大到小）")]),t._v("\n    length_function"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 执行切分")]),t._v("\nchunks "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" text_splitter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split_text"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sample_text"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出结果")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\nRecursiveCharacterTextSplitter 切分结果："')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" chunk "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("enumerate")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("chunks"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"分块 ')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("：")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("chunk"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("（长度：")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("chunk"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('）"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("ul",[s("li",[t._v("特殊分块")])]),t._v(" "),s("blockquote",[s("p",[t._v("在LangChain中, 我们可以使用"),s("code",[t._v("MarkdownTextSplitter")]),t._v("和 "),s("code",[t._v("LatexTexxtSplitter")])])]),t._v(" "),s("h3",{attrs:{id:"_4-如何找到理想的分块大小"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-如何找到理想的分块大小"}},[t._v("#")]),t._v(" 4. 如何找到理想的分块大小?")]),t._v(" "),s("blockquote",[s("p",[t._v("这是一个迭代的过程。")])]),t._v(" "),s("ul",[s("li",[t._v("可以通过以下几个步骤，"),s("strong",[t._v("找到或接近理想的分块大小")]),t._v("。")])]),t._v(" "),s("ol",[s("li",[t._v("首先, 需要预处理数据。")])]),t._v(" "),s("ul",[s("li",[t._v("需要先预处理数据, 确保数据的质量。")]),t._v(" "),s("li",[t._v("比如, 如果数据是通过网页抓取获得的, 那需要移除像HTML标签等的噪音元素")])]),t._v(" "),s("ol",{attrs:{start:"2"}},[s("li",[t._v("选择分块大小的范围。")])]),t._v(" "),s("ul",[s("li",[s("p",[t._v("数据预处理完成后, 然后就是选择一系列可能的分块大小进行测试。")])]),t._v(" "),s("li",[s("p",[t._v("要内容的性质：比如是短消息还是长篇文档;")])]),t._v(" "),s("li",[s("p",[t._v("以及我们将使用的嵌入模型和它的能力, 比如嵌入的模型是否有token限制? 是多少?")])]),t._v(" "),s("li",[s("p",[t._v("可以从探索各种分块大小开始,  包括较小的分块(比如128或256个token), 用于捕获更细粒度的语义信息; 以及较大的分块(比如512或1024个token), 用于保留更多的上下文。")])])]),t._v(" "),s("ol",{attrs:{start:"3"}},[s("li",[t._v("然后, 需要评估每个分块大小的性能。")])]),t._v(" "),s("ul",[s("li",[t._v("使用一个具有代表性的数据集, 为你想测试的分块大小创建嵌入, 并将它们保存到索引中。")]),t._v(" "),s("li",[s("strong",[t._v("然后运行各种查询, 评估质量, 比较不同分块大小的性能")]),t._v("。")]),t._v(" "),s("li",[t._v("这是一个迭代的过程, 需要针对不同的查询，测试不同的分块大小, 直到确定对于我们的内容和预期查询, 性能最好的分块小。")])]),t._v(" "),s("h3",{attrs:{id:"_5-处理复杂文档时-最有效的数字化和分块方法是"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5-处理复杂文档时-最有效的数字化和分块方法是"}},[t._v("#")]),t._v(" 5. 处理复杂文档时, 最有效的数字化和分块方法是?")]),t._v(" "),s("blockquote",[s("p",[t._v("布局感知分块(Layoutaware chunking) 是处理这类复杂文档的理想方法。")])]),t._v(" "),s("p",[t._v("该技术会保留文档的原始布局结构(如标题、页眉、段落), 而实现布局感知分块需要依赖"),s("strong",[t._v("布局理解模型")]),t._v("进行数字化处理。")]),t._v(" "),s("blockquote",[s("p",[t._v("布局理解模型的核心功能:")])]),t._v(" "),s("ol",[s("li",[t._v("解析文档布局: 自动分析文档的物理结构")]),t._v(" "),s("li",[t._v("保留格式提取内容: 允许从文档中提取内容时保持原有排版利阅读格式")]),t._v(" "),s("li",[t._v("识别关键元素: 可定位以下结构组件:")])]),t._v(" "),s("ul",[s("li",[t._v("标题")]),t._v(" "),s("li",[t._v("页眉")]),t._v(" "),s("li",[t._v("子标题")]),t._v(" "),s("li",[t._v("正文文本")]),t._v(" "),s("li",[t._v("表格")]),t._v(" "),s("li",[t._v("图表")]),t._v(" "),s("li",[t._v("列表")]),t._v(" "),s("li",[t._v("页脚")]),t._v(" "),s("li",[t._v("页码")]),t._v(" "),s("li",[t._v("键值对")])]),t._v(" "),s("h3",{attrs:{id:"_6-分块过程中如何处理表格"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_6-分块过程中如何处理表格"}},[t._v("#")]),t._v(" 6. 分块过程中如何处理表格?")]),t._v(" "),s("ul",[s("li",[t._v("通用的表现形式是: "),s("code",[t._v("markdown")])]),t._v(" "),s("li",[t._v("要注意表格跨页，要用工程化的代码，对跨页做合并")])]),t._v(" "),s("h3",{attrs:{id:"_7-如何处理大表并实现更高效的检索"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_7-如何处理大表并实现更高效的检索"}},[t._v("#")]),t._v(" 7. 如何处理大表并实现更高效的检索?")]),t._v(" "),s("h3",{attrs:{id:"_8-在分块过程中如何处理列表项"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_8-在分块过程中如何处理列表项"}},[t._v("#")]),t._v(" 8. 在分块过程中如何处理列表项?")]),t._v(" "),s("h3",{attrs:{id:"_9-如何构建生产级的文档处理与索引流水线"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_9-如何构建生产级的文档处理与索引流水线"}},[t._v("#")]),t._v(" 9. 如何构建生产级的文档处理与索引流水线?")])])}),[],!1,null,null,null);s.default=r.exports}}]);