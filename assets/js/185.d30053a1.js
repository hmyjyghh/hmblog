(window.webpackJsonp=window.webpackJsonp||[]).push([[185],{628:function(t,s,a){"use strict";a.r(s);var n=a(3),r=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"正则处理"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#正则处理"}},[t._v("#")]),t._v(" 正则处理")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" re\n\n")])])]),s("h2",{attrs:{id:"jieba-0-42-1"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#jieba-0-42-1"}},[t._v("#")]),t._v(" jieba==0.42.1")]),t._v(" "),s("p",[s("code",[t._v("jieba")]),t._v(" 是 Python 中一款非常流行的中文分词库，版本 "),s("code",[t._v("0.42.1")]),t._v(" 是其历史版本之一，主要作用是将连续的中文文本按照语义拆分成一个个独立的词语（分词），是中文自然语言处理（NLP）中最基础且常用的工具之一。")]),t._v(" "),s("p",[t._v("具体来说，它的核心功能包括：")]),t._v(" "),s("ol",[s("li",[s("strong",[t._v("中文分词")]),t._v("：支持精确模式（最常用，试图将句子最精确地切开）、全模式（把句子中所有可能的词语都扫描出来）、搜索引擎模式（在精确模式基础上，对长词再次切分，适合搜索引擎分词）。")]),t._v(" "),s("li",[s("strong",[t._v("自定义词典")]),t._v("：允许用户添加自定义词语，以解决专有名词（如人名、地名、专业术语）无法被正确识别的问题。")]),t._v(" "),s("li",[s("strong",[t._v("词性标注")]),t._v("：可以为分词后的词语标注词性（如名词、动词、形容词等）。")]),t._v(" "),s("li",[s("strong",[t._v("并行分词")]),t._v("：支持利用多线程加速分词过程，提升处理大量文本时的效率。")])]),t._v(" "),s("p",[t._v("由于中文文本不像英文那样有天然的空格分隔词语，分词是中文文本处理的前提步骤，因此 "),s("code",[t._v("jieba")]),t._v(" 广泛应用于文本挖掘、情感分析、信息检索等场景。")]),t._v(" "),s("h2",{attrs:{id:"线程池"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#线程池"}},[t._v("#")]),t._v(" 线程池")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" concurrent"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("futures"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ThreadPoolExecutor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("max_workers"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("MAX_WORKERS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" executor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    futures "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("doc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("metadata"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'unique_id'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" executor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("submit"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("chat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" LLM_CLEAN_PROMPT"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("doc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("page_content"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" doc "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" groups"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("在这段代码中，"),s("code",[t._v("concurrent.futures.ThreadPoolExecutor")]),t._v(" 是 Python 标准库中用于创建线程池的工具，其核心作用是"),s("strong",[t._v("高效地并发执行多个任务")]),t._v("，主要体现在以下几个方面：")]),t._v(" "),s("h3",{attrs:{id:"_1-管理线程资源-避免频繁创建-销毁线程的开销"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-管理线程资源-避免频繁创建-销毁线程的开销"}},[t._v("#")]),t._v(" 1. "),s("strong",[t._v("管理线程资源，避免频繁创建/销毁线程的开销")])]),t._v(" "),s("p",[t._v("线程的创建和销毁需要消耗系统资源（如 CPU、内存）。如果为每个任务单独创建一个线程，当任务数量较多时，频繁的线程创建/销毁会显著降低效率。"),s("br"),t._v(" "),s("code",[t._v("ThreadPoolExecutor")]),t._v(" 会预先创建指定数量的线程（通过 "),s("code",[t._v("max_workers")]),t._v(" 控制），并复用这些线程执行多个任务，减少资源消耗。")]),t._v(" "),s("h3",{attrs:{id:"_2-并发执行任务-提高程序运行效率"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-并发执行任务-提高程序运行效率"}},[t._v("#")]),t._v(" 2. "),s("strong",[t._v("并发执行任务，提高程序运行效率")])]),t._v(" "),s("p",[t._v("在这段代码中，"),s("code",[t._v("executor.submit(chat, ...)")]),t._v(" 会将 "),s("code",[t._v("chat")]),t._v(" 函数（可能是一个耗时操作，如调用 LLM 接口、网络请求等）提交到线程池。"),s("br"),t._v("\n线程池会自动分配空闲线程执行这些任务，实现多个 "),s("code",[t._v("chat")]),t._v(" 任务的"),s("strong",[t._v("并发执行")]),t._v("（注意：Python 由于 GIL 限制，CPU 密集型任务并发效果有限，但 I/O 密集型任务如网络请求、文件读写等能显著提升效率）。")]),t._v(" "),s("h3",{attrs:{id:"_3-简化并发编程逻辑"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-简化并发编程逻辑"}},[t._v("#")]),t._v(" 3. "),s("strong",[t._v("简化并发编程逻辑")])]),t._v(" "),s("p",[s("code",[t._v("ThreadPoolExecutor")]),t._v(" 封装了线程管理的细节（如线程创建、任务分配、结果回收等），无需手动操作 "),s("code",[t._v("threading")]),t._v(" 模块的线程对象。"),s("br"),t._v("\n通过 "),s("code",[t._v("futures")]),t._v(" 字典可以追踪每个任务（通过 "),s("code",[t._v("unique_id")]),t._v(" 关联），后续可通过 "),s("code",[t._v("future.result()")]),t._v(" 获取任务返回值，或处理异常。")]),t._v(" "),s("h3",{attrs:{id:"总结"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[t._v("#")]),t._v(" 总结")]),t._v(" "),s("p",[t._v("在这段代码中，"),s("code",[t._v("ThreadPoolExecutor")]),t._v(" 的作用是："),s("strong",[t._v("通过线程池并发执行多个 "),s("code",[t._v("chat")]),t._v(" 任务，减少线程管理开销，利用并发提升处理效率（尤其适合 I/O 密集型的 LLM 调用场景），同时简化并发逻辑的实现")]),t._v("。")]),t._v(" "),s("h2",{attrs:{id:"from-more-itertools-import-divide"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#from-more-itertools-import-divide"}},[t._v("#")]),t._v(" from more_itertools import divide")]),t._v(" "),s("p",[s("code",[t._v("from more_itertools import divide")]),t._v(" 中的 "),s("code",[t._v("divide")]),t._v(" 函数用于将一个可迭代对象（如列表、元组等）"),s("strong",[t._v("均匀地分割成指定数量的子序列")]),t._v("，返回一个包含这些子序列的迭代器。")]),t._v(" "),s("h3",{attrs:{id:"核心作用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#核心作用"}},[t._v("#")]),t._v(" 核心作用：")]),t._v(" "),s("p",[t._v("将原始可迭代对象拆分为 "),s("code",[t._v("n")]),t._v(" 个部分，尽可能让每个部分的元素数量相近（若总元素数不能被 "),s("code",[t._v("n")]),t._v(" 整除，前几个子序列会多1个元素）。")]),t._v(" "),s("h3",{attrs:{id:"示例"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#示例"}},[t._v("#")]),t._v(" 示例：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" more_itertools "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" divide\n\ndata "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 分成3个子序列")]),t._v("\nparts "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" divide"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("parts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出：[[1, 2, 3], [4, 5], [6, 7]]")]),t._v("\n")])])]),s("ul",[s("li",[t._v("总元素7个，分成3份：前1份3个元素，后2份各2个元素，尽可能均匀。")])]),t._v(" "),s("h3",{attrs:{id:"与普通分割的区别"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#与普通分割的区别"}},[t._v("#")]),t._v(" 与普通分割的区别：")]),t._v(" "),s("p",[t._v("普通切片（如 "),s("code",[t._v("data[i::n]")]),t._v("）是按“间隔取元素”分割，而 "),s("code",[t._v("divide")]),t._v(" 是按“连续片段”分割，更符合“均匀分块”的需求。")]),t._v(" "),s("p",[t._v("常用于需要将任务/数据平均分配给多个 worker（如多线程/多进程处理）的场景。")]),t._v(" "),s("h2",{attrs:{id:"文档解析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#文档解析"}},[t._v("#")]),t._v(" 文档解析")]),t._v(" "),s("h3",{attrs:{id:"pymupdf-别名-fitz"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#pymupdf-别名-fitz"}},[t._v("#")]),t._v(" PyMuPDF，别名：fitz")]),t._v(" "),s("blockquote",[s("p",[t._v("PyMuPDF 是处理 PDF 的轻量级高性能库，其核心优势, 在于能完美匹配"),s("strong",[t._v("布局感知分块的需求")])])]),t._v(" "),s("ul",[s("li",[t._v("PyMuPDF 能提取表格坐标，但复杂表格（合并单元格、跨页）需专用库。")])]),t._v(" "),s("h4",{attrs:{id:"_1-精准的布局元素解析能力"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-精准的布局元素解析能力"}},[t._v("#")]),t._v(" 1. 精准的布局元素解析能力")]),t._v(" "),s("p",[t._v("PyMuPDF 能直接提取PDF中每个文本/图形元素的"),s("strong",[t._v("几何坐标（x/y坐标、宽高、页码）")]),t._v("、字体属性（大小、粗细、颜色）、文本行/块归属，这些是“布局感知”的核心数据：")]),t._v(" "),s("ul",[s("li",[t._v("例：通过 "),s("code",[t._v('page.get_text("dict")')]),t._v(" 可获取结构化文本数据，包含每个文本块的"),s("code",[t._v("bbox")]),t._v("（边界框）、"),s("code",[t._v("lines")]),t._v("（行）、"),s("code",[t._v("spans")]),t._v("（字符段），能直接区分“标题（大字体、粗体、顶部位置）”“正文（常规字体、连续文本块）”“页眉页脚（固定坐标区域）”等；")]),t._v(" "),s("li",[s("strong",[t._v("支持提取表格的单元格坐标")]),t._v("、图片的位置和内容，为识别“表格/图表”等布局元素提供基础。")])]),t._v(" "),s("h4",{attrs:{id:"_2-轻量化-高性能"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-轻量化-高性能"}},[t._v("#")]),t._v(" 2. 轻量化+高性能")]),t._v(" "),s("p",[t._v("相比PDFMiner、pdfplumber等纯Python库，PyMuPDF基于C++实现，解析速度快（处理百页PDF仅秒级），内存占用低，"),s("strong",[t._v("适合批量文档处理的业务场景")]),t._v("（如合同解析、财报分析、档案数字化）。")]),t._v(" "),s("h4",{attrs:{id:"_3-灵活的内容提取与格式保留"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-灵活的内容提取与格式保留"}},[t._v("#")]),t._v(" 3. 灵活的内容提取与格式保留")]),t._v(" "),s("ul",[s("li",[t._v("可按布局区域提取文本（如只提取正文区域、过滤页眉页脚）；")]),t._v(" "),s("li",[t._v("支持保留文本的排版格式（如换行、缩进），甚至可提取带格式的HTML/Markdown，贴合“保留原始布局结构”的需求。")])]),t._v(" "),s("h3",{attrs:{id:"二、实际业务中用pymupdf做布局感知分块的核心流程"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#二、实际业务中用pymupdf做布局感知分块的核心流程"}},[t._v("#")]),t._v(" 二、实际业务中用PyMuPDF做布局感知分块的核心流程")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" fitz  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# PyMuPDF")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("layout_aware_chunking")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pdf_path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    doc "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" fitz"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pdf_path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    chunks "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 存储分块结果，每个块包含类型、内容、坐标、页码")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" page_num"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" page "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("enumerate")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("doc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1. 提取结构化文本（含布局信息）")]),t._v("\n        text_dict "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" page"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_text"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"dict"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" block "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" text_dict"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"blocks"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" block"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"type"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 文本块（排除图片/图形块）")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2. 分析布局特征（坐标、字体、文本长度）")]),t._v("\n                bbox "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" block"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bbox"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (x0, y0, x1, y1) 左上角/右下角坐标")]),t._v("\n                first_span "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" block"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"lines"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spans"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n                font_size "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" first_span"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"size"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n                font_bold "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" first_span"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"flags"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 粗体标识")]),t._v("\n                text "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("join"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("span"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"text"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" line "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" block"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"lines"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" span "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" line"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spans"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("strip"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                \n                "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3. 布局元素分类（核心：根据特征判断块类型）")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" font_size "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("16")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" font_bold"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    chunk_type "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"标题"')]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" font_size "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" font_bold"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    chunk_type "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"子标题"')]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" bbox"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 页面顶部50px内")]),t._v("\n                    chunk_type "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"页眉"')]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" bbox"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" page"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rect"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("height "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 页面底部50px内")]),t._v("\n                    chunk_type "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"页脚"')]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("text"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    chunk_type "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"正文文本"')]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    chunk_type "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"其他"')]),t._v("\n                \n                chunks"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"page"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" page_num "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"type"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" chunk_type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"content"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" text"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bbox"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" bbox\n                "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" chunks\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 调用示例")]),t._v("\npdf_chunks "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" layout_aware_chunking"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"复杂文档.pdf"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" chunk "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" pdf_chunks"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 打印前5个分块")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"页码：')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("chunk"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'page'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v(" | 类型：")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("chunk"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'type'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v(" | 内容：")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("chunk"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'content'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token format-spec"}},[t._v("50]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('..."')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"三、复杂场景"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#三、复杂场景"}},[t._v("#")]),t._v(" 三、复杂场景")]),t._v(" "),s("p",[t._v("PyMuPDF 擅长“原生PDF（可复制文本）”的布局解析，但面对以下场景需结合其他工具：")]),t._v(" "),s("h4",{attrs:{id:"_1-扫描件-图片型pdf-无文本"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-扫描件-图片型pdf-无文本"}},[t._v("#")]),t._v(" 1. 扫描件/图片型PDF（无文本）")]),t._v(" "),s("p",[t._v("需先做OCR提取文本+布局信息，常用组合：")]),t._v(" "),s("ul",[s("li",[t._v("PyMuPDF 提取图片 → Tesseract/OCRmyPDF 做OCR（保留坐标） → 再用PyMuPDF整合布局；")]),t._v(" "),s("li",[t._v("进阶：阿里云/百度OCR的“版式分析”接口（直接返回标题、正文、表格等布局元素）。")])]),t._v(" "),s("h4",{attrs:{id:"_2-高精度表格-复杂图表解析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-高精度表格-复杂图表解析"}},[t._v("#")]),t._v(" 2. 高精度表格/复杂图表解析")]),t._v(" "),s("p",[t._v("PyMuPDF 能提取表格坐标，但复杂表格（合并单元格、跨页）需专用库：")]),t._v(" "),s("ul",[s("li",[t._v("表格："),s("code",[t._v("pdfplumber")]),t._v("（基于坐标的表格解析）、"),s("code",[t._v("Camelot")]),t._v("；")]),t._v(" "),s("li",[t._v("图表：先截图（PyMuPDF）→ 用"),s("code",[t._v("Matplotlib")]),t._v("/"),s("code",[t._v("PIL")]),t._v("分析，或调用GPT-4V识别图表内容。")])]),t._v(" "),s("h4",{attrs:{id:"_3-多格式文档-word-excel-powerpoint"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-多格式文档-word-excel-powerpoint"}},[t._v("#")]),t._v(" 3. 多格式文档（Word/Excel/PowerPoint）")]),t._v(" "),s("p",[t._v("先转换为PDF（"),s("code",[t._v("python-docx")]),t._v("/"),s("code",[t._v("xlwings")]),t._v(" + PyMuPDF），再做布局分块；或直接用：")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("python-docx")]),t._v(" 解析Word的原生布局（标题级别、段落样式、表格）；")]),t._v(" "),s("li",[s("code",[t._v("pdf2docx")]),t._v(" 将PDF转为Word后解析布局（适合需保留格式的场景）。")])]),t._v(" "),s("h4",{attrs:{id:"_4-企业级布局理解-端到端模型"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-企业级布局理解-端到端模型"}},[t._v("#")]),t._v(" 4. 企业级布局理解（端到端模型）")]),t._v(" "),s("p",[t._v("若需“全自动识别所有布局元素”（无需手动规则），需结合"),s("strong",[t._v("布局理解模型")]),t._v("：")]),t._v(" "),s("ul",[s("li",[t._v("开源模型：LayoutLMv3（微软，支持中文，输入文本+坐标+图像，输出布局元素类型）；")]),t._v(" "),s("li",[t._v("商用模型：阿里云DocMind、腾讯文智的版式分析API，直接返回结构化的布局分块结果。")])]),t._v(" "),s("h3",{attrs:{id:"四、总结"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#四、总结"}},[t._v("#")]),t._v(" 四、总结")]),t._v(" "),s("ol",[s("li",[s("strong",[t._v("核心结论")]),t._v("：布局感知分块的业务场景中，PyMuPDF 是"),s("strong",[t._v("基础且核心的工具")]),t._v("，"),s("strong",[t._v("尤其适合可复制文本的PDF")]),t._v("，能快速获取布局坐标和文本信息，支撑分块规则的实现；")]),t._v(" "),s("li",[s("strong",[t._v("场景延伸")]),t._v("：\n"),s("ul",[s("li",[t._v("简单场景（原生PDF、常规布局）：仅用PyMuPDF即可完成布局分块；")]),t._v(" "),s("li",[s("strong",[t._v("复杂场景（扫描件、复杂表格、多格式）：PyMuPDF + OCR/专用解析库/布局理解模型；")])]),t._v(" "),s("li",[t._v("企业级场景：直接调用布局理解模型（LayoutLM/商用API），PyMuPDF 作为数据预处理工具。")])])])])])}),[],!1,null,null,null);s.default=r.exports}}]);