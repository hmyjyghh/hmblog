(window.webpackJsonp=window.webpackJsonp||[]).push([[190],{635:function(t,s,a){"use strict";a.r(s);var n=a(3),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"永久存储"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#永久存储"}},[t._v("#")]),t._v(" 永久存储")]),t._v(" "),s("ol",[s("li",[t._v("当我们程序运行起来的时候，大多数数据都是从硬盘转移到了内存中，内存跟我们CPU之间的数据传输速度，要比这个硬盘跟CPU之间要快上很多倍")])]),t._v(" "),s("h3",{attrs:{id:"打开文件"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#打开文件"}},[t._v("#")]),t._v(" 打开文件")]),t._v(" "),s("blockquote",[s("p",[t._v("open() 函数")])]),t._v(" "),s("ul",[s("li",[t._v("open() 函数所返回的文件对象类型取决于所使用的模式：\n"),s("ul",[s("li",[t._v("当使用 open() 以文本模式（'w'，'r'，'wt'，'rt' 等）打开文件时，它将返回 io.TextIOBase（准确的说是 io.TextIOWrapper）的一个子类")]),t._v(" "),s("li",[t._v("当使用缓冲以二进制模式打开文件时，返回的类是 io.BufferedIOBase 的一个子类，具体的类会有多种：在只读的二进制模式下，它将返回 io.BufferedReader；在写入二进制和追加二进制模式下，它将返回 io.BufferedWriter；而在读/写模式下，它将返回 io.BufferedRandom")]),t._v(" "),s("li",[t._v("当禁止缓冲时，则会返回原始流，即 io.RawIOBase，io.FileIO的一个子类 。")])])])]),t._v(" "),s("h3",{attrs:{id:"usage"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#usage"}},[t._v("#")]),t._v(" usage")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" mode"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'r'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" buffering"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" encoding"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" errors"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" newline"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" closefd"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" opener"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"file、mode-参数"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#file、mode-参数"}},[t._v("#")]),t._v(" file、mode 参数")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[t._v("参数")]),t._v(" "),s("th",[t._v("含义")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[s("strong",[t._v("file")])]),t._v(" "),s("td",[t._v("指定一个将要打开的文件的路径（绝对路径或相对路径）")])]),t._v(" "),s("tr",[s("td",[s("strong",[t._v("mode")])]),t._v(" "),s("td",[t._v("可选参数，指定文件的打开模式："),s("br"),s("br")])])])]),t._v(" "),s("p",[t._v("如果你希望将内部的表格也完全用 Markdown 嵌套表格形式表示，也可以这样（但 Markdown 本身不支持表格嵌套，因此一般用内嵌代码或列表表示）：")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[t._v("参数")]),t._v(" "),s("th",[t._v("含义")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[s("strong",[t._v("file")])]),t._v(" "),s("td",[t._v("指定一个将要打开的文件的路径（绝对路径或相对路径）")])]),t._v(" "),s("tr",[s("td",[s("strong",[t._v("mode")])]),t._v(" "),s("td",[t._v("可选参数，指定文件的打开模式："),s("br"),t._v("可选值包括："),s("br"),t._v("- "),s("code",[t._v("'r'")]),t._v("：读取（默认）"),s("br"),t._v("- "),s("code",[t._v("'w'")]),t._v("：写入（如果文件已存在则先截断清空文件）"),s("br"),t._v("- "),s("code",[t._v("'x'")]),t._v("：排他性创建文件（如果文件已存在则打开失败）"),s("br"),t._v("- "),s("code",[t._v("'a'")]),t._v("：追加（如果文件已存在则在末尾追加内容），注1"),s("br"),t._v("- "),s("code",[t._v("'b'")]),t._v("：二进制模式，注2"),s("br"),t._v("- "),s("code",[t._v("'t'")]),t._v("：文本模式（默认），注3"),s("br"),t._v("- "),s("code",[t._v("'+'")]),t._v("：更新文件（读取和写入）")])])])]),t._v(" "),s("h3",{attrs:{id:"文件读取-读取-写入"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#文件读取-读取-写入"}},[t._v("#")]),t._v(" 文件读取， 读取，写入")]),t._v(" "),s("ul",[s("li",[t._v("注意打开一个文件(以写的模式打开)， 可能会把文件内容给清空，特别注意！！！")]),t._v(" "),s("li",[t._v('以写入模式("w")，打开文件，直接关闭，会把内容清空')])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[t._v("f "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hm.txt"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"w"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 打开完之后，我不做任何事情，就把文件对象关闭，会把内容清掉")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# mode="write", 这是文件操作系统，一定要注意的！！！')]),t._v("\n")])])]),s("h3",{attrs:{id:"文件对象的各种方法大合集"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#文件对象的各种方法大合集"}},[t._v("#")]),t._v(" 文件对象的各种方法大合集")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[t._v("方法")]),t._v(" "),s("th",[t._v("含义")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[s("code",[t._v("f.close()")])]),t._v(" "),s("td",[t._v("关闭文件对象")])]),t._v(" "),s("tr",[s("td",[s("code",[t._v("f.flush()")])]),t._v(" "),s("td",[t._v("将文件对象中的缓存数据写入到文件中（不一定有效）")])]),t._v(" "),s("tr",[s("td",[s("code",[t._v("f.read(size=-1, /)")])]),t._v(" "),s("td",[t._v("从文件对象中读取指定数量的字符（或者遇到 EOF 停止）；当未指定该参数，或该参数为负值的时候，读取剩余的所有字符")])]),t._v(" "),s("tr",[s("td",[s("code",[t._v("f.readable()")])]),t._v(" "),s("td",[t._v("判断该文件对象是否支持读取（如果返回的值为 "),s("code",[t._v("False")]),t._v("，则调用 "),s("code",[t._v("read()")]),t._v(" 方法会导致 "),s("code",[t._v("OSError")]),t._v(" 异常）")])]),t._v(" "),s("tr",[s("td",[s("code",[t._v("f.readline(size=-1, /)")])]),t._v(" "),s("td",[t._v("从文件对象中读取一行字符串（包括换行符），如果指定了 "),s("code",[t._v("size")]),t._v(" 参数，则表示读取 "),s("code",[t._v("size")]),t._v(" 个字符")])]),t._v(" "),s("tr",[s("td",[s("code",[t._v("f.readlines(size=-1, /)")])]),t._v(" "),s("td",[t._v("从文件对象中读取所有字符串（包括换行符），然后按行为单位存储到列表中。如果指定了 "),s("code",[t._v("size")]),t._v(" 参数，则表示读取 "),s("code",[t._v("size")]),t._v(" 个字符（如果 "),s("code",[t._v("size")]),t._v(" 参数指定的字符个数少于第一行字符个数，则仍然存放第一行字符，其他行也一样，它是按“行”为单位存储的）")])]),t._v(" "),s("tr",[s("td",[s("code",[t._v("f.seek(offset, whence=0, /)")])]),t._v(" "),s("td",[t._v("修改文件指针的位置，从 "),s("code",[t._v("whence")]),t._v(" 参数指定的位置（0 代表文件起始位置，1 代表当前位置，2 代表文件末尾）偏移 "),s("code",[t._v("offset")]),t._v(" 个字节，返回值是新的索引位置")])]),t._v(" "),s("tr",[s("td",[s("code",[t._v("f.seekable()")])]),t._v(" "),s("td",[t._v("判断该文件对象是否支持修改文件指针的位置（如果返回的值为 "),s("code",[t._v("False")]),t._v("，则调用 "),s("code",[t._v("seek()")]),t._v("、"),s("code",[t._v("tell()")]),t._v("、"),s("code",[t._v("truncate()")]),t._v(" 方法都会导致 "),s("code",[t._v("OSError")]),t._v(" 异常）")])]),t._v(" "),s("tr",[s("td",[s("code",[t._v("f.tell()")])]),t._v(" "),s("td",[t._v("返回当前文件指针在文件对象中的位置")])]),t._v(" "),s("tr",[s("td",[s("code",[t._v("f.truncate(pos=None, /)")])]),t._v(" "),s("td",[t._v("将文件对象截取到 "),s("code",[t._v("pos")]),t._v(" 的位置，默认是截取到文件指针当前指定的位置")])]),t._v(" "),s("tr",[s("td",[s("code",[t._v("f.write(text, /)")])]),t._v(" "),s("td",[t._v("将字符串写入到文件对象中，并返回写入的字符数量（字符串的长度）")])]),t._v(" "),s("tr",[s("td",[s("code",[t._v("f.writable()")])]),t._v(" "),s("td",[t._v("判断该文件对象是否支持写入（如果返回的值为 "),s("code",[t._v("False")]),t._v("，则调用 "),s("code",[t._v("write()")]),t._v(" 方法会导致 "),s("code",[t._v("OSError")]),t._v(" 异常）")])]),t._v(" "),s("tr",[s("td",[s("code",[t._v("f.writelines(lines, /)")])]),t._v(" "),s("td",[t._v("将一系列字符串写入到文件对象中（不会自动添加换行符，所以通常是人为地加在每个字符串的末尾）")])])])]),t._v(" "),s("blockquote",[s("p",[t._v("有两种方法可以将字符串写入到文件对象中是不是")])]),t._v(" "),s("ol",[s("li",[t._v("write()")]),t._v(" "),s("li",[t._v("writelines()\n"),s("ul",[s("li",[t._v("这个writelines(), 它不会自动添加这个换行符")]),t._v(" "),s("li",[t._v("所以，如果希望传入进去的多个字符串，带换行的话，需要显示指定"),s("code",[t._v("\\n")])])])])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[t._v("f "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hm.txt"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"w"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 默认写入当前文件，所在根目录")]),t._v("\nf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"I love Python hh."')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 会返回写入的字符数, 16")]),t._v("\nf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("writelines"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"I love Hmyjy.\\n"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"I love my wife."')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 没有返回值")]),t._v("\n\n\nf "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hm.txt"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"r+"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# r+ 的形式(也就是以更新文件的形式来打开)，既可以写入，也可以读取")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("writable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# True 既可以写入")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("readable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# True 也可以读取")]),t._v("\n")])])]),s("ul",[s("li",[t._v("由于Python的文件呢是支持迭代的, 我们是可以将文件放到for语句里面去实现读取")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[t._v("f "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hm.txt"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"r+"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# r+ 的形式(也就是以更新文件的形式来打开)，既可以写入，也可以读取")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" e "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("e"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# I love Python hh.I love Hmyjy.")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# I love my wife.")]),t._v("\n\nf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tell"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seek"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 将文件指针重新移动到开头的位置")]),t._v("\n\nf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("readline"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 每次读取一行, I love Python hh.I love Hmyjy.")]),t._v("\n\nf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# read的话, 就是读取到EOF的位置(也就是文件的这个末尾)")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 截取")]),t._v("\nf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("truncate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("29")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 那么就是截取到文件指针当前指定的位置")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出: I love Python hh.I love Hmyjy")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# f.flush(), 可以在不执行close()的情况下，将文本写入文件")]),t._v("\n")])])]),s("h2",{attrs:{id:"with语句和上下文管理器"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#with语句和上下文管理器"}},[t._v("#")]),t._v(" with语句和上下文管理器")]),t._v(" "),s("ul",[s("li",[t._v("with语句，也就是上下文管理器，它为文件操作提供了一种更为优雅的实现方式")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[t._v("f "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hm.txt"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"w"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"I love Hmyjy.\\n I Love 520."')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"fishC.txt"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"w"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"I love fishC."')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 这里是特意注释掉的，使用with 语句，不需要再手动关闭文件")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# f.close() # 注意，使用with 我们就不需要再去关闭文件了")]),t._v("\n")])])]),s("h3",{attrs:{id:"文件操作的三板斧"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#文件操作的三板斧"}},[t._v("#")]),t._v(" 文件操作的三板斧")]),t._v(" "),s("ol",[s("li",[t._v("上文就是打开文件")]),t._v(" "),s("li",[t._v("往文件里写入东西")]),t._v(" "),s("li",[t._v("下文就是关闭文件")])]),t._v(" "),s("ul",[s("li",[t._v("这就是上下文管理器做的事情")]),t._v(" "),s("li",[t._v("使用了上下文管理器，我们就不需要再去手动的关闭文件")]),t._v(" "),s("li",[t._v("文件处理的代码只需要放在with语句的缩进里边，就可以了，这样的代码，显得更优雅")]),t._v(" "),s("li",[t._v("使用上下文管理器最大的优势，是能够确保资源的释放(在这里，也就是文件的正常关闭了，我们不用去手动关闭文件了)")])]),t._v(" "),s("h3",{attrs:{id:"使用with-语句的好处"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#使用with-语句的好处"}},[t._v("#")]),t._v(" 使用with 语句的好处")]),t._v(" "),s("ol",[s("li",[t._v("任意新建一个.py 文件，写入")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[t._v("f "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hm.txt"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"w"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"I Love hmyjy."')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 由于这一步报错，导致f.close() 函数未能执行，所以内容未能写入文件")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果代码报错，程序并没有机会执行到这个文件关闭的一个操作")]),t._v("\nf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 但是如果使用 with, 情况就会不一样")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"fishC.txt"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"w"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"I love fishC."')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 虽然这一步报错了，但是with 上下文管理器，依然帮你确保这个文件可以正常的关闭")]),t._v("\n")])])]),s("h2",{attrs:{id:"pickle"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#pickle"}},[t._v("#")]),t._v(" pickle")]),t._v(" "),s("blockquote",[s("p",[t._v("pickle模块解决的就是一个，"),s("strong",[t._v("永久存储Python对象的问题")])])]),t._v(" "),s("ul",[s("li",[t._v("它允许你将字符串、列表、字典, 这些Python对象给保存为文件的形式")])]),t._v(" "),s("blockquote",[s("p",[t._v("将python 对象(元组、列表、字典)序列化的一个操作")])]),t._v(" "),s("ul",[s("li",[s("p",[t._v("所谓序列化，就是将Python对象转换为二进制字节流的这么一个过程")])]),t._v(" "),s("li",[s("p",[t._v("就是将源代码，变成0101001的二进制组合")])]),t._v(" "),s("li",[s("p",[t._v("dump()")])]),t._v(" "),s("li",[s("p",[t._v("load()")])])]),t._v(" "),s("h3",{attrs:{id:"dump"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#dump"}},[t._v("#")]),t._v(" dump()")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pickle\n\nx"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" z "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\ns "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Hmyjy"')]),t._v(" \nl "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"寒梦"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("520")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.14")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" \nd "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"one"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"two"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 后缀名为:.pkl 格式，写入模式，指定为二进制格式")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"data.pkl"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"wb"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" \n    pickle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dump"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n    pickle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dump"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n    pickle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dump"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("z"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n    pickle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dump"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n    pickle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dump"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("l"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n    pickle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dump"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"load"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#load"}},[t._v("#")]),t._v(" load()")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pickle\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"data.pkl"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"rb"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    x "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pickle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    y "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pickle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    z "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pickle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    s "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pickle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    l "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pickle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    d "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pickle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" z"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" s"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" l"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" sep"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\n"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 每输出一个值，加一个换行符")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Hmyjy")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ['寒梦', 520, 3.14]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# {'one': 1, 'two': 2}")]),t._v("\n")])])]),s("h3",{attrs:{id:"优化写法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#优化写法"}},[t._v("#")]),t._v(" 优化写法")]),t._v(" "),s("ul",[s("li",[t._v("一个个写，太麻烦了，使用元组的形式，进行序列化")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pickle\n\nx"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" z "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\ns "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Hmyjy"')]),t._v(" \nl "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"寒梦"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("520")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.14")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" \nd "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"one"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"two"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 后缀名为:.pkl 格式，写入模式，指定为二进制格式")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 这里第一个参数传入一个元组的形式这样子")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"data.pkl"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"wb"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" \n    pickle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dump"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("z"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("s"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("l"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 读取，解包")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"data.pkl"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"rb"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" \n    x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" z"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" s"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" l"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" d "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pickle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 解包的形式，读取对应的值")]),t._v("\n")])])]),s("h2",{attrs:{id:"路径处理之pathlib"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#路径处理之pathlib"}},[t._v("#")]),t._v(" 路径处理之pathlib")]),t._v(" "),s("ul",[s("li",[t._v("Windows系统它使用反斜杠，而其他大多数操作系统则是使用斜杠")]),t._v(" "),s("li",[t._v("Windows系统中的反斜杠，跟字符串中的转义字符的反斜杠，其实是一样的")]),t._v(" "),s("li",[t._v("如果想要在Windows上使用反斜杠来分隔路径，\n"),s("ul",[s("li",[t._v("使用另一条反斜杠来转义反斜杠本身")]),t._v(" "),s("li",[t._v('或者直接使用这个原始字符串(可以直接使用r(""))')])])])]),t._v(" "),s("blockquote",[s("p",[t._v("新旧路径处理模块大比拼(pathlib vs os.path)")])]),t._v(" "),s("h3",{attrs:{id:"文件读取路径"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#文件读取路径"}},[t._v("#")]),t._v(" 文件读取路径")]),t._v(" "),s("blockquote",[s("p",[s("code",[t._v("pathlib")]),t._v("是 Python3.4 之后新添加的模块, 它可以让文件和路径操作变得快捷方便, 完美代替os.path模块。")])]),t._v(" "),s("ul",[s("li",[t._v("pathlib VS os.path")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pathlib "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Path\n\ncwd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 获取当前目录的路径")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cwd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# D:\\ghh\\blog-model-vuepress")]),t._v("\n\n\nis_dir"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 判断一个路径是否为一个文件夹")]),t._v("\n\nexists"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 检查一个路径是否存在")]),t._v("\n\nname 属性，"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 获取路径的最后一个部分")]),t._v("\n\nsuffix"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 获取文件后缀")]),t._v("\n\nparent"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 获取父级目录")]),t._v("\nparents，"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 获取逻辑祖先路径构成的序列")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pathlib "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Path\n\np "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'D:/ghh/blog-model-vuepress/docs/pystudy'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parents"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" e "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parents"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("e"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 4")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# D:\\ghh\\blog-model-vuepress\\docs")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# D:\\ghh\\blog-model-vuepress")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# D:\\ghh")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# D:\\")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 还支持索引")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pathlib "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Path\n\np "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'D:/ghh/blog-model-vuepress/docs/pystudy'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nps "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parents\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ps"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# for e in ps:")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#     print(e)")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 还支持索引")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ps"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# D:\\ghh\\blog-model-vuepress")]),t._v("\n\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pathlib "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Path\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cwd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\np "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'C:/Users/xxx/AppData/Local/Programs/Python/Python39'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nq "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" p "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hm.txt"')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("q"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_dir"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("q"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_dir"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("q"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exists"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("q"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exists"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"C:/404"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exists"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("q"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("q"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("q"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("suffix"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 获取父级目录")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("q"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pathlib "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Path\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(Path.cwd()) # D:\\ghh\\blog-model-vuepress")]),t._v("\n\n\np "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"D:/ghh/blog-model-vuepress"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nq "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" p "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"test.txt"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 这个写法，在这个目录下，新建个文件")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("q"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# D:\\ghh\\blog-model-vuepress\\test.txt")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# stem属性, 获取文件名")]),t._v("\nq"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stem\n")])])]),s("h3",{attrs:{id:"parts"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#parts"}},[t._v("#")]),t._v(" parts")]),t._v(" "),s("ul",[s("li",[t._v("将路径的各个组件，拆分成元组,")]),t._v(" "),s("li",[t._v("各个组件拆分成元组的形式给放起来")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pathlib "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Path\n\np "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'D:/ghh/blog-model-vuepress/docs/pystudy'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 还支持索引")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ('D:\\\\', 'ghh', 'blog-model-vuepress', 'docs', 'pystudy')")]),t._v("\n")])])]),s("h3",{attrs:{id:"stat"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#stat"}},[t._v("#")]),t._v(" stat()")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pathlib "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Path\n\np "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'D:/ghh/blog-model-vuepress/docs/pystudy'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("st_size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 12288, 是字节数, / 1024 = 12KB")]),t._v("\n")])])]),s("h3",{attrs:{id:"相对路径-vs-绝对路径"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#相对路径-vs-绝对路径"}},[t._v("#")]),t._v(" 相对路径 vs 绝对路径")]),t._v(" "),s("ul",[s("li",[t._v("绝对路径，是文件真正存在的路径")]),t._v(" "),s("li",[t._v("相对路径, 是以当前目录为基准，进行一级一级的这个目录推导的一个路径")]),t._v(" "),s("li",[t._v("我们使用"),s("code",[t._v("./")]),t._v(" 来表示当前所在目录")]),t._v(" "),s("li",[t._v("使用"),s("code",[t._v("../")]),t._v(" 来表示上一级目录")])]),t._v(" "),s("h3",{attrs:{id:"resolve"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#resolve"}},[t._v("#")]),t._v(" resolve()")]),t._v(" "),s("ul",[s("li",[t._v("将相对路径转换为绝对路径")])]),t._v(" "),s("h3",{attrs:{id:"iterdir"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#iterdir"}},[t._v("#")]),t._v(" iterdir()")]),t._v(" "),s("ul",[s("li",[t._v("获取当前路径下所有子文件和子文件夹")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pathlib "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Path\n\np "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'D:/ghh/model/blog/model-blog/docs/pystudy'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(p.iterdir())")]),t._v("\np_dir "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("iterdir"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" e "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" p_dir"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("e"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 调用iterdir()，得到了一个 <map object at 0x000002B91E388130>")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# map object，就可以使用for 循环，进行遍历。")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" e "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("iterdir"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("e"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 将当前路径下的，文件和文件夹这些对象都给打印出来了")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 再使用列表推导式，过滤出文件(把文件夹过滤掉)")]),t._v("\n\nx "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("e "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" e "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("iterdir"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" e"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])])]),s("p",[s("strong",[t._v("上面就是用的比较多的，与路径查询相关的这些函数")])]),t._v(" "),s("h2",{attrs:{id:"修改路径"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#修改路径"}},[t._v("#")]),t._v(" 修改路径")]),t._v(" "),s("h3",{attrs:{id:"mkdir"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#mkdir"}},[t._v("#")]),t._v(" mkdir()")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pathlib "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Path\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# mkdir() # 创建文件夹")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pathlib "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Path\n\np "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'D:/ghh/model/blog/model-blog/docs/pystudy'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nn "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" p "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hm"')]),t._v("\n\nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mkdir"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 已经创建了hm 这个文件夹")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 再次创建，会报错")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# n.mkdir() # FileExistsError: [WinError 183] 当文件已存在时，无法创建该文件。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 但是可以通过一个参数，来忽略这种错误")]),t._v("\nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mkdir"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("exist_ok"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pathlib "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Path\n\np "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'D:/ghh/model/blog/model-blog/docs/pystudy'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nn "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" p "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hm/A/B/C"')]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# n.mkdir() # FileNotFoundError: [WinError 3] 系统找不到指定的路径。: 'D:\\\\ghh\\\\model\\\\blog\\\\model-blog\\\\docs\\\\pystudy\\\\hm\\\\A\\\\B\\\\C'")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 遇到这个错误，将它的parents参数设置为True 即可")]),t._v("\nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mkdir"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("parents"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2个参数一起传")]),t._v("\nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mkdir"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("parents"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" exist_ok"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"open"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#open"}},[t._v("#")]),t._v(" open()")]),t._v(" "),s("ul",[s("li",[t._v("打开文件")]),t._v(" "),s("li",[t._v("跟调用open() 函数是一样的，只是不用传路径")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pathlib "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Path\n\np "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'D:/ghh/model/blog/model-blog/docs/pystudy'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nn "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" p "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hm.txt"')]),t._v("\n\nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mkdir"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("parents"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" exist_ok"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nf "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"w"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"I Love Hmyjy."')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 要执行close() 函数，内容才会从这个文件对象的缓冲区写入文件里")]),t._v("\nf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"rename"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#rename"}},[t._v("#")]),t._v(" rename()")]),t._v(" "),s("blockquote",[s("p",[t._v("修改文件或者文件夹名字")])]),t._v(" "),s("p",[s("strong",[t._v("特别注意")])]),t._v(" "),s("ul",[s("li",[t._v("那就是我们给到新名字参数的时候，没有包含路径，直接给了一个 文件名，")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pathlib "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Path\n\np "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'D:/ghh/model/blog/model-blog/docs/pystudy'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nn "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" p "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hm.txt"')]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# n.mkdir(parents=True, exist_ok=True)")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 因为没有指定路径，所以直接跑到了 项目根目录下，而且生成的是文件夹，并不是名字")]),t._v("\nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rename"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"newHm.txt"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 这个写法，不仅没有看到 newHm.txt， 还把 hm.txt 干没了")]),t._v("\n")])])]),s("h3",{attrs:{id:"replace"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#replace"}},[t._v("#")]),t._v(" replace()")]),t._v(" "),s("blockquote",[s("p",[t._v("替换指定的文件或文件夹")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pathlib "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Path\n\np "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'D:/ghh/model/blog/model-blog/docs/pystudy'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nn "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" p "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hm.txt"')]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# n.mkdir()")]),t._v("\n\nm "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'new.txt'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("m"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nm"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("replace"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"删除操作"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#删除操作"}},[t._v("#")]),t._v(" 删除操作")]),t._v(" "),s("ul",[s("li",[t._v("rmdir(), 删除文件夹;")]),t._v(" "),s("li",[t._v("unlink(), 删除文件")])]),t._v(" "),s("ol",[s("li",[t._v("rmdir() 删除文件夹的时候，如果文件夹里有文件(会提示，目录不是空的)")]),t._v(" "),s("li",[t._v("需要先使用unlink() 函数，将文件给删除")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pathlib "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Path\n\np "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'D:/ghh/model/blog/model-blog/docs/pystudy'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nn "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" p "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hm.txt"')]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# n.parent.rmdir() # 切记不要删掉博客的在用的文件夹，可以新建个项目，验证这个点")]),t._v("\nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("unlink"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# n.parent.rmdir()")]),t._v("\n")])])]),s("h3",{attrs:{id:"glob"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#glob"}},[t._v("#")]),t._v(" glob()")]),t._v(" "),s("blockquote",[s("p",[t._v("功能强大的查找功能")])]),t._v(" "),s("ul",[s("li",[t._v("查找当前文件夹下面的所有以"),s("code",[t._v(".txt")]),t._v("为后缀的文件")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pathlib "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Path\n\np "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 查找当前文件夹下面的所有以.txt为后缀的文件")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("glob"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"*.md"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 给到的是一个：<map object at 0x0000016038C16B60>")]),t._v("\n\nps "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("glob"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"*.md"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 可以将ps 变成一个列表的形式, list(ps)")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 可以对 ps 进行遍历")]),t._v("\n")])])]),s("ul",[s("li",[t._v("查找当前目录下的下一级目录中的所有.py后缀的这个文件")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pathlib "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Path\n\np "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nps "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("glob"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"*/*.py"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("ul",[s("li",[t._v("如果希望进行向下的递归搜索, 也就是：查找当前目录以及该目录下面的所有子目录")]),t._v(" "),s("li",[t._v("可以使用两个星号来表示")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pathlib "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Path\n\nps "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("glob"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"**/*.py"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);