<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>寒梦的博客</title>
    <meta name="generator" content="VuePress 1.9.4">
    <link rel="icon" href="/hmblog/logo.png">
    <meta name="description" content="宝剑锋从磨砺出，梅花香自苦寒来。">
    
    <link rel="preload" href="/hmblog/assets/css/0.styles.b92e6d01.css" as="style"><link rel="preload" href="/hmblog/assets/js/app.ba48173d.js" as="script"><link rel="preload" href="/hmblog/assets/js/3.ac02bfbd.js" as="script"><link rel="preload" href="/hmblog/assets/js/1.ba4d6411.js" as="script"><link rel="preload" href="/hmblog/assets/js/70.bed5cdee.js" as="script"><link rel="preload" href="/hmblog/assets/js/9.d5a05a45.js" as="script"><link rel="prefetch" href="/hmblog/assets/js/10.cdd9f1fd.js"><link rel="prefetch" href="/hmblog/assets/js/100.6bd782a8.js"><link rel="prefetch" href="/hmblog/assets/js/101.aa82f15d.js"><link rel="prefetch" href="/hmblog/assets/js/102.02a5e952.js"><link rel="prefetch" href="/hmblog/assets/js/103.f64270f5.js"><link rel="prefetch" href="/hmblog/assets/js/104.28c05f95.js"><link rel="prefetch" href="/hmblog/assets/js/105.4a3c3d99.js"><link rel="prefetch" href="/hmblog/assets/js/106.d7163a41.js"><link rel="prefetch" href="/hmblog/assets/js/107.03567d93.js"><link rel="prefetch" href="/hmblog/assets/js/108.9c57ec7a.js"><link rel="prefetch" href="/hmblog/assets/js/109.0b5cc849.js"><link rel="prefetch" href="/hmblog/assets/js/11.513bb120.js"><link rel="prefetch" href="/hmblog/assets/js/110.c000ed58.js"><link rel="prefetch" href="/hmblog/assets/js/111.288d96b3.js"><link rel="prefetch" href="/hmblog/assets/js/112.8a5358fb.js"><link rel="prefetch" href="/hmblog/assets/js/113.a1de3201.js"><link rel="prefetch" href="/hmblog/assets/js/114.d8618f6d.js"><link rel="prefetch" href="/hmblog/assets/js/115.17026eb3.js"><link rel="prefetch" href="/hmblog/assets/js/116.f0cb16ec.js"><link rel="prefetch" href="/hmblog/assets/js/117.66402938.js"><link rel="prefetch" href="/hmblog/assets/js/118.e16ec272.js"><link rel="prefetch" href="/hmblog/assets/js/119.53ee2325.js"><link rel="prefetch" href="/hmblog/assets/js/12.6eb5f340.js"><link rel="prefetch" href="/hmblog/assets/js/120.b2631c22.js"><link rel="prefetch" href="/hmblog/assets/js/121.9b598b7e.js"><link rel="prefetch" href="/hmblog/assets/js/122.05f086d4.js"><link rel="prefetch" href="/hmblog/assets/js/123.ee628a51.js"><link rel="prefetch" href="/hmblog/assets/js/124.3309b897.js"><link rel="prefetch" href="/hmblog/assets/js/125.8ba7f05f.js"><link rel="prefetch" href="/hmblog/assets/js/126.363ab065.js"><link rel="prefetch" href="/hmblog/assets/js/127.3dc43128.js"><link rel="prefetch" href="/hmblog/assets/js/128.ead549d4.js"><link rel="prefetch" href="/hmblog/assets/js/129.0219dd0d.js"><link rel="prefetch" href="/hmblog/assets/js/13.41ba4240.js"><link rel="prefetch" href="/hmblog/assets/js/130.50036dbd.js"><link rel="prefetch" href="/hmblog/assets/js/131.43d759e2.js"><link rel="prefetch" href="/hmblog/assets/js/132.73426bd0.js"><link rel="prefetch" href="/hmblog/assets/js/133.bf6d3d08.js"><link rel="prefetch" href="/hmblog/assets/js/134.2eb9f09e.js"><link rel="prefetch" href="/hmblog/assets/js/135.06734521.js"><link rel="prefetch" href="/hmblog/assets/js/136.82c90848.js"><link rel="prefetch" href="/hmblog/assets/js/137.8569b3cd.js"><link rel="prefetch" href="/hmblog/assets/js/138.8e5559db.js"><link rel="prefetch" href="/hmblog/assets/js/139.d7e6536d.js"><link rel="prefetch" href="/hmblog/assets/js/14.bd0b82cb.js"><link rel="prefetch" href="/hmblog/assets/js/140.8481dfb3.js"><link rel="prefetch" href="/hmblog/assets/js/15.491bfa3e.js"><link rel="prefetch" href="/hmblog/assets/js/16.00b7c2a7.js"><link rel="prefetch" href="/hmblog/assets/js/17.2edfa6dd.js"><link rel="prefetch" href="/hmblog/assets/js/18.c1ed5355.js"><link rel="prefetch" href="/hmblog/assets/js/19.127093b0.js"><link rel="prefetch" href="/hmblog/assets/js/20.13018e45.js"><link rel="prefetch" href="/hmblog/assets/js/21.af0d47de.js"><link rel="prefetch" href="/hmblog/assets/js/22.94430091.js"><link rel="prefetch" href="/hmblog/assets/js/23.7f4160d8.js"><link rel="prefetch" href="/hmblog/assets/js/24.53f66321.js"><link rel="prefetch" href="/hmblog/assets/js/25.70c7adf7.js"><link rel="prefetch" href="/hmblog/assets/js/26.ed970703.js"><link rel="prefetch" href="/hmblog/assets/js/27.61f08265.js"><link rel="prefetch" href="/hmblog/assets/js/28.47f448c8.js"><link rel="prefetch" href="/hmblog/assets/js/29.3a6d76f5.js"><link rel="prefetch" href="/hmblog/assets/js/30.fcf9b535.js"><link rel="prefetch" href="/hmblog/assets/js/31.8a27a1da.js"><link rel="prefetch" href="/hmblog/assets/js/32.e4efef75.js"><link rel="prefetch" href="/hmblog/assets/js/33.ea12175d.js"><link rel="prefetch" href="/hmblog/assets/js/34.bc951939.js"><link rel="prefetch" href="/hmblog/assets/js/35.adfc7113.js"><link rel="prefetch" href="/hmblog/assets/js/36.f4b05b10.js"><link rel="prefetch" href="/hmblog/assets/js/37.b160f43f.js"><link rel="prefetch" href="/hmblog/assets/js/38.182e0a40.js"><link rel="prefetch" href="/hmblog/assets/js/39.f6688462.js"><link rel="prefetch" href="/hmblog/assets/js/4.e51e222a.js"><link rel="prefetch" href="/hmblog/assets/js/40.9edf4cd4.js"><link rel="prefetch" href="/hmblog/assets/js/41.6ee87788.js"><link rel="prefetch" href="/hmblog/assets/js/42.e15f3316.js"><link rel="prefetch" href="/hmblog/assets/js/43.a703d986.js"><link rel="prefetch" href="/hmblog/assets/js/44.73bbf228.js"><link rel="prefetch" href="/hmblog/assets/js/45.c5ced175.js"><link rel="prefetch" href="/hmblog/assets/js/46.c039688e.js"><link rel="prefetch" href="/hmblog/assets/js/47.85473c5e.js"><link rel="prefetch" href="/hmblog/assets/js/48.011447cd.js"><link rel="prefetch" href="/hmblog/assets/js/49.64ffd976.js"><link rel="prefetch" href="/hmblog/assets/js/5.60398f15.js"><link rel="prefetch" href="/hmblog/assets/js/50.d4938794.js"><link rel="prefetch" href="/hmblog/assets/js/51.13d55290.js"><link rel="prefetch" href="/hmblog/assets/js/52.506ef0e3.js"><link rel="prefetch" href="/hmblog/assets/js/53.fbe62579.js"><link rel="prefetch" href="/hmblog/assets/js/54.72aa5c58.js"><link rel="prefetch" href="/hmblog/assets/js/55.8a3c2734.js"><link rel="prefetch" href="/hmblog/assets/js/56.4d420373.js"><link rel="prefetch" href="/hmblog/assets/js/57.57103446.js"><link rel="prefetch" href="/hmblog/assets/js/58.9aab8a53.js"><link rel="prefetch" href="/hmblog/assets/js/59.ec40cafa.js"><link rel="prefetch" href="/hmblog/assets/js/6.775d6c13.js"><link rel="prefetch" href="/hmblog/assets/js/60.05b1112b.js"><link rel="prefetch" href="/hmblog/assets/js/61.5dd88b4a.js"><link rel="prefetch" href="/hmblog/assets/js/62.4bf0f31f.js"><link rel="prefetch" href="/hmblog/assets/js/63.5fa24c27.js"><link rel="prefetch" href="/hmblog/assets/js/64.98804cd8.js"><link rel="prefetch" href="/hmblog/assets/js/65.9d6391ad.js"><link rel="prefetch" href="/hmblog/assets/js/66.afa16de6.js"><link rel="prefetch" href="/hmblog/assets/js/67.23a13c5e.js"><link rel="prefetch" href="/hmblog/assets/js/68.faffe00e.js"><link rel="prefetch" href="/hmblog/assets/js/69.8d2c347b.js"><link rel="prefetch" href="/hmblog/assets/js/7.e91fdee2.js"><link rel="prefetch" href="/hmblog/assets/js/71.712a04f2.js"><link rel="prefetch" href="/hmblog/assets/js/72.67728c96.js"><link rel="prefetch" href="/hmblog/assets/js/73.a49f5b5b.js"><link rel="prefetch" href="/hmblog/assets/js/74.fa293c83.js"><link rel="prefetch" href="/hmblog/assets/js/75.9452e054.js"><link rel="prefetch" href="/hmblog/assets/js/76.24ad0c90.js"><link rel="prefetch" href="/hmblog/assets/js/77.94b04afb.js"><link rel="prefetch" href="/hmblog/assets/js/78.97c9f7fb.js"><link rel="prefetch" href="/hmblog/assets/js/79.be8996a8.js"><link rel="prefetch" href="/hmblog/assets/js/8.968ba87b.js"><link rel="prefetch" href="/hmblog/assets/js/80.002c12e9.js"><link rel="prefetch" href="/hmblog/assets/js/81.724c88b9.js"><link rel="prefetch" href="/hmblog/assets/js/82.c17fc6b0.js"><link rel="prefetch" href="/hmblog/assets/js/83.b1e421f1.js"><link rel="prefetch" href="/hmblog/assets/js/84.94eacc74.js"><link rel="prefetch" href="/hmblog/assets/js/85.089b8ca8.js"><link rel="prefetch" href="/hmblog/assets/js/86.fb003f4f.js"><link rel="prefetch" href="/hmblog/assets/js/87.b6fd3eaa.js"><link rel="prefetch" href="/hmblog/assets/js/88.d8b79d91.js"><link rel="prefetch" href="/hmblog/assets/js/89.f6d32768.js"><link rel="prefetch" href="/hmblog/assets/js/90.89f31336.js"><link rel="prefetch" href="/hmblog/assets/js/91.47343b87.js"><link rel="prefetch" href="/hmblog/assets/js/92.2e8d45e3.js"><link rel="prefetch" href="/hmblog/assets/js/93.5e7328c6.js"><link rel="prefetch" href="/hmblog/assets/js/94.bde570da.js"><link rel="prefetch" href="/hmblog/assets/js/95.f0d4415e.js"><link rel="prefetch" href="/hmblog/assets/js/96.d48d924f.js"><link rel="prefetch" href="/hmblog/assets/js/97.3cea1091.js"><link rel="prefetch" href="/hmblog/assets/js/98.158fd54d.js"><link rel="prefetch" href="/hmblog/assets/js/99.ca68782b.js">
    <link rel="stylesheet" href="/hmblog/assets/css/0.styles.b92e6d01.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar" data-v-1c636796><div data-v-1c636796><div class="password-shadow password-wrapper-out" style="display:none;" data-v-2c3e9f55 data-v-1c636796 data-v-1c636796><h3 class="title" data-v-2c3e9f55>寒梦的博客</h3> <p class="description" data-v-2c3e9f55>宝剑锋从磨砺出，梅花香自苦寒来。</p> <label id="box" class="inputBox" data-v-2c3e9f55><input type="password" value="" data-v-2c3e9f55> <span data-v-2c3e9f55>Konck! Knock!</span> <button data-v-2c3e9f55>OK</button></label> <div class="footer" data-v-2c3e9f55><span data-v-2c3e9f55><i class="iconfont reco-theme" data-v-2c3e9f55></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-2c3e9f55>vuePress-theme-reco</a></span> <span data-v-2c3e9f55><i class="iconfont reco-copyright" data-v-2c3e9f55></i> <a data-v-2c3e9f55><span data-v-2c3e9f55>寒梦</span>
          
        <!---->
        2025
      </a></span></div></div> <div class="hide" data-v-1c636796><header class="navbar" data-v-1c636796><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/hmblog/" class="home-link router-link-active"><!----> <span class="site-name">寒梦的博客</span></a> <div class="links"><div class="color-picker"><a class="color-button"><i class="iconfont reco-color"></i></a> <div class="color-picker-menu" style="display:none;"><div class="mode-options"><h4 class="title">Choose mode</h4> <ul class="color-mode-options"><li class="dark">dark</li><li class="auto active">auto</li><li class="light">light</li></ul></div></div></div> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="undefined"></i>
      强大的MCP
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/hmblog/mcpstudy/mcp-knowledge.html" class="nav-link"><i class="undefined"></i>
  MCP 是什么
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/mcpstudy/ide-mcp-server.html" class="nav-link"><i class="undefined"></i>
  IDE 使用MCP Server实操
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="undefined"></i>
      Python
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/basic.html" class="nav-link"><i class="undefined"></i>
  Python 基础
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/data-structure.html" class="nav-link"><i class="undefined"></i>
  Python 数据结构
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/builtin-function.html" class="nav-link"><i class="undefined"></i>
  Python 内置函数的使用
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/function.html" class="nav-link"><i class="undefined"></i>
  Python 函数
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/class.html" class="nav-link"><i class="undefined"></i>
  Python 类
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/module.html" class="nav-link"><i class="undefined"></i>
  Python 模块
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/package.html" class="nav-link"><i class="undefined"></i>
  Python 包
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/exception.html" class="nav-link"><i class="undefined"></i>
  Python 异常
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/file.html" class="nav-link"><i class="undefined"></i>
  Python 文件操作
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/regex.html" class="nav-link"><i class="undefined"></i>
  Python 正则表达式
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/thread.html" class="nav-link"><i class="undefined"></i>
  Python 多线程
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/process.html" class="nav-link"><i class="undefined"></i>
  Python 多进程
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/network.html" class="nav-link"><i class="undefined"></i>
  Python 网络编程
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/database.html" class="nav-link"><i class="undefined"></i>
  Python 数据库
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/numpy.html" class="nav-link"><i class="undefined"></i>
  Python numpy
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/array-operation.html" class="nav-link"><i class="undefined"></i>
  Python 数组操作
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/use-library.html" class="nav-link"><i class="undefined"></i>
  Python 常用库
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/string-function.html" class="nav-link"><i class="undefined"></i>
  Python 字符串函数
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/practice.html" class="nav-link"><i class="undefined"></i>
  Python 日常练习
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/use-pip-install.html" class="nav-link"><i class="undefined"></i>
  pip 那些事
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/line-continue.html" class="nav-link"><i class="undefined"></i>
  Python 中的行续行符
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/technology-point.html" class="nav-link"><i class="undefined"></i>
  Python 中技术点练习
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/pandas-study.html" class="nav-link"><i class="undefined"></i>
  pandas 库的使用
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="undefined"></i>
      大模型应用开发
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/whatIsModel.html" class="nav-link"><i class="undefined"></i>
  什么是大模型应用开发
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-basic.html" class="nav-link"><i class="undefined"></i>
  大模型应用开发基础
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model.html" class="nav-link"><i class="undefined"></i>
  大模型应用开发构建
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-deploy.html" class="nav-link"><i class="undefined"></i>
  大模型应用开发部署
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/vector-database.html" class="nav-link"><i class="undefined"></i>
  向量数据库
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-pytorch.html" class="nav-link"><i class="undefined"></i>
  Fine-tuning框架PyTorch 和 Hugging face 框架使用
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/transformer-code.html" class="nav-link"><i class="undefined"></i>
  手撕Transformer 代码
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/transformer-knowledge.html" class="nav-link"><i class="undefined"></i>
  理解Transformer 代码必看
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/transformer-related.html" class="nav-link"><i class="undefined"></i>
  transformer 相关源码
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-transformer.html" class="nav-link"><i class="undefined"></i>
  Transformers实战
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-train.html" class="nav-link"><i class="undefined"></i>
  Transformers实战2
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-train-code.html" class="nav-link"><i class="undefined"></i>
  模型训练代码分析
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/transformer-learn.html" class="nav-link"><i class="undefined"></i>
  Transformer 核心组件学习路线
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/transformer-question.html" class="nav-link"><i class="undefined"></i>
  Transformer 论文精读中的常见问题
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-english.html" class="nav-link"><i class="undefined"></i>
  大模型相关的英语词汇
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-case.html" class="nav-link"><i class="undefined"></i>
  大模型应用开发案例
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-summary.html" class="nav-link"><i class="undefined"></i>
  大模型应用开发总结
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-question.html" class="nav-link"><i class="undefined"></i>
  大模型应用常见问题
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/impl-transformer.html" class="nav-link"><i class="undefined"></i>
  手撕Transformer
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-RNN.html" class="nav-link"><i class="undefined"></i>
  RNN（循环神经网络）是什么？
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-evaluate.html" class="nav-link"><i class="undefined"></i>
  大模型评估指标
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-langchain-rag.html" class="nav-link"><i class="undefined"></i>
  Langchain &amp; RAG
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-langchain.html" class="nav-link"><i class="undefined"></i>
  Langchain 核心知识点
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-rag.html" class="nav-link"><i class="undefined"></i>
  RAG 知识点
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/langchain-study.html" class="nav-link"><i class="undefined"></i>
  Langchain 学习
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-rag-pain.html" class="nav-link"><i class="undefined"></i>
  RAG 痛点分析
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-function-calling.html" class="nav-link"><i class="undefined"></i>
  Function Calling
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/langchain-agent-practice.html" class="nav-link"><i class="undefined"></i>
  Langchain agent 实战作业二
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/extended-learning.html" class="nav-link"><i class="undefined"></i>
  扩展学习知识
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/self-function-calling.html" class="nav-link"><i class="undefined"></i>
  Function Calling 自己练习
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-fine-tuning.html" class="nav-link"><i class="undefined"></i>
  模型微调需要的库或者方法
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/lora-fine-tuning.html" class="nav-link"><i class="undefined"></i>
  LoRA 微调
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/agent.html" class="nav-link"><i class="undefined"></i>
  Agent 相关
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/langchain-prompt.html" class="nav-link"><i class="undefined"></i>
  练习langchain prompt的使用
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/construct-dataset.html" class="nav-link"><i class="undefined"></i>
  如何构造数据集
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/auto-model-desc.html" class="nav-link"><i class="undefined"></i>
  加载模型
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/compute-metrics.html" class="nav-link"><i class="undefined"></i>
  评估函数的使用
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/ner-instruct-task.html" class="nav-link"><i class="undefined"></i>
  NER 任务指令数据构造
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/finetuning-exercises-code.html" class="nav-link"><i class="undefined"></i>
  Fine-Tuning 实战作业三
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/finetuning-error-collect.html" class="nav-link"><i class="undefined"></i>
  微调实战三错误收集
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/finetuning-warn-collect.html" class="nav-link"><i class="undefined"></i>
  微调实战三警告收集
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/finetuning-f1-scores.html" class="nav-link"><i class="undefined"></i>
  微调实战F1 分数打印
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-train-analyze.html" class="nav-link"><i class="undefined"></i>
  训练完结果分析
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/finetuing-step5.html" class="nav-link"><i class="undefined"></i>
  微调实战-step5--数据处理函数
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/finetuing-step9.html" class="nav-link"><i class="undefined"></i>
  微调实战-step9--评估函数的使用
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/vLLM-intro.html" class="nav-link"><i class="undefined"></i>
  vLLM
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="undefined"></i>
      算法
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/sort.html" class="nav-link"><i class="undefined"></i>
  排序算法
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/double-pointer.html" class="nav-link"><i class="undefined"></i>
  双指针算法
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/binary-tree.html" class="nav-link"><i class="undefined"></i>
  二叉树
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/receive-rain.html" class="nav-link"><i class="undefined"></i>
  接雨水
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/dynamic-plan.html" class="nav-link"><i class="undefined"></i>
  动态规划
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/greedy.html" class="nav-link"><i class="undefined"></i>
  贪心算法
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/longasc-sequence.html" class="nav-link"><i class="undefined"></i>
  最长上升子序列
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/binary-search.html" class="nav-link"><i class="undefined"></i>
  二分查找
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/reverse-list.html" class="nav-link"><i class="undefined"></i>
  反转链表
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/del-single-list.html" class="nav-link"><i class="undefined"></i>
  删除单链表-集合
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/other.html" class="nav-link"><i class="undefined"></i>
  其他
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/compare-al.html" class="nav-link"><i class="undefined"></i>
  m个数，最多用n次比较，找出第二大的数
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/effect-bracket.html" class="nav-link"><i class="undefined"></i>
  有效的括号
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="undefined"></i>
      其他
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/hmblog/other/ai-agent.html" class="nav-link"><i class="undefined"></i>
  AI项目
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/python.html" class="nav-link"><i class="undefined"></i>
  python学习
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/conda.html" class="nav-link"><i class="undefined"></i>
  Conda 使用
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/using-packages.html" class="nav-link"><i class="undefined"></i>
  Pytorch 框架使用
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/pytorch-know.html" class="nav-link"><i class="undefined"></i>
  Pytorch 框架知识点
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/transformer-learn.html" class="nav-link"><i class="undefined"></i>
  transformer库中那些常用函数
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/transformer-collect.html" class="nav-link"><i class="undefined"></i>
  transformer库学习哪些事
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/transformer-1.html" class="nav-link"><i class="undefined"></i>
  transformer 使用T5模型
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/transformer-2.html" class="nav-link"><i class="undefined"></i>
  torch DataLoader
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/transformer-3.html" class="nav-link"><i class="undefined"></i>
  设置随机种子
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/model-refrence.html" class="nav-link"><i class="undefined"></i>
  优秀的参考文档
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/git-operate.html" class="nav-link"><i class="undefined"></i>
  git 操作命令
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/fine-tuning-adapters.html" class="nav-link"><i class="undefined"></i>
  PEFT 之Adapters
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/swanLab-info.html" class="nav-link"><i class="undefined"></i>
  深度学习之SwanLab
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/lora-0-1.html" class="nav-link"><i class="undefined"></i>
  从0到1手撕LoRA类
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="undefined"></i>
      关于我
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/hmyjyghh" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="undefined"></i>
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://gitee.com/ghh_" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="undefined"></i>
  Gitee
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.zhihu.com/people/cool-62-29/columns" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="undefined"></i>
  知乎
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://hmyjyghh.github.io/" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="undefined"></i>
  博客
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-1c636796></div> <aside class="sidebar" data-v-1c636796><div class="personal-info-wrapper" data-v-6f92ba70 data-v-1c636796><!----> <h3 class="name" data-v-6f92ba70>
    寒梦
  </h3> <div class="num" data-v-6f92ba70><div data-v-6f92ba70><h3 data-v-6f92ba70>100</h3> <h6 data-v-6f92ba70>Articles</h6></div> <div data-v-6f92ba70><h3 data-v-6f92ba70>4</h3> <h6 data-v-6f92ba70>Tags</h6></div></div> <ul class="social-links" data-v-6f92ba70></ul> <hr data-v-6f92ba70></div> <nav class="nav-links"><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="undefined"></i>
      强大的MCP
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/hmblog/mcpstudy/mcp-knowledge.html" class="nav-link"><i class="undefined"></i>
  MCP 是什么
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/mcpstudy/ide-mcp-server.html" class="nav-link"><i class="undefined"></i>
  IDE 使用MCP Server实操
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="undefined"></i>
      Python
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/basic.html" class="nav-link"><i class="undefined"></i>
  Python 基础
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/data-structure.html" class="nav-link"><i class="undefined"></i>
  Python 数据结构
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/builtin-function.html" class="nav-link"><i class="undefined"></i>
  Python 内置函数的使用
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/function.html" class="nav-link"><i class="undefined"></i>
  Python 函数
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/class.html" class="nav-link"><i class="undefined"></i>
  Python 类
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/module.html" class="nav-link"><i class="undefined"></i>
  Python 模块
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/package.html" class="nav-link"><i class="undefined"></i>
  Python 包
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/exception.html" class="nav-link"><i class="undefined"></i>
  Python 异常
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/file.html" class="nav-link"><i class="undefined"></i>
  Python 文件操作
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/regex.html" class="nav-link"><i class="undefined"></i>
  Python 正则表达式
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/thread.html" class="nav-link"><i class="undefined"></i>
  Python 多线程
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/process.html" class="nav-link"><i class="undefined"></i>
  Python 多进程
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/network.html" class="nav-link"><i class="undefined"></i>
  Python 网络编程
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/database.html" class="nav-link"><i class="undefined"></i>
  Python 数据库
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/numpy.html" class="nav-link"><i class="undefined"></i>
  Python numpy
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/array-operation.html" class="nav-link"><i class="undefined"></i>
  Python 数组操作
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/use-library.html" class="nav-link"><i class="undefined"></i>
  Python 常用库
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/string-function.html" class="nav-link"><i class="undefined"></i>
  Python 字符串函数
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/practice.html" class="nav-link"><i class="undefined"></i>
  Python 日常练习
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/use-pip-install.html" class="nav-link"><i class="undefined"></i>
  pip 那些事
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/line-continue.html" class="nav-link"><i class="undefined"></i>
  Python 中的行续行符
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/technology-point.html" class="nav-link"><i class="undefined"></i>
  Python 中技术点练习
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/pystudy/pandas-study.html" class="nav-link"><i class="undefined"></i>
  pandas 库的使用
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="undefined"></i>
      大模型应用开发
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/whatIsModel.html" class="nav-link"><i class="undefined"></i>
  什么是大模型应用开发
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-basic.html" class="nav-link"><i class="undefined"></i>
  大模型应用开发基础
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model.html" class="nav-link"><i class="undefined"></i>
  大模型应用开发构建
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-deploy.html" class="nav-link"><i class="undefined"></i>
  大模型应用开发部署
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/vector-database.html" class="nav-link"><i class="undefined"></i>
  向量数据库
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-pytorch.html" class="nav-link"><i class="undefined"></i>
  Fine-tuning框架PyTorch 和 Hugging face 框架使用
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/transformer-code.html" class="nav-link"><i class="undefined"></i>
  手撕Transformer 代码
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/transformer-knowledge.html" class="nav-link"><i class="undefined"></i>
  理解Transformer 代码必看
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/transformer-related.html" class="nav-link"><i class="undefined"></i>
  transformer 相关源码
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-transformer.html" class="nav-link"><i class="undefined"></i>
  Transformers实战
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-train.html" class="nav-link"><i class="undefined"></i>
  Transformers实战2
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-train-code.html" class="nav-link"><i class="undefined"></i>
  模型训练代码分析
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/transformer-learn.html" class="nav-link"><i class="undefined"></i>
  Transformer 核心组件学习路线
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/transformer-question.html" class="nav-link"><i class="undefined"></i>
  Transformer 论文精读中的常见问题
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-english.html" class="nav-link"><i class="undefined"></i>
  大模型相关的英语词汇
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-case.html" class="nav-link"><i class="undefined"></i>
  大模型应用开发案例
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-summary.html" class="nav-link"><i class="undefined"></i>
  大模型应用开发总结
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-question.html" class="nav-link"><i class="undefined"></i>
  大模型应用常见问题
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/impl-transformer.html" class="nav-link"><i class="undefined"></i>
  手撕Transformer
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-RNN.html" class="nav-link"><i class="undefined"></i>
  RNN（循环神经网络）是什么？
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-evaluate.html" class="nav-link"><i class="undefined"></i>
  大模型评估指标
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-langchain-rag.html" class="nav-link"><i class="undefined"></i>
  Langchain &amp; RAG
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-langchain.html" class="nav-link"><i class="undefined"></i>
  Langchain 核心知识点
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-rag.html" class="nav-link"><i class="undefined"></i>
  RAG 知识点
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/langchain-study.html" class="nav-link"><i class="undefined"></i>
  Langchain 学习
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-rag-pain.html" class="nav-link"><i class="undefined"></i>
  RAG 痛点分析
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-function-calling.html" class="nav-link"><i class="undefined"></i>
  Function Calling
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/langchain-agent-practice.html" class="nav-link"><i class="undefined"></i>
  Langchain agent 实战作业二
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/extended-learning.html" class="nav-link"><i class="undefined"></i>
  扩展学习知识
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/self-function-calling.html" class="nav-link"><i class="undefined"></i>
  Function Calling 自己练习
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-fine-tuning.html" class="nav-link"><i class="undefined"></i>
  模型微调需要的库或者方法
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/lora-fine-tuning.html" class="nav-link"><i class="undefined"></i>
  LoRA 微调
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/agent.html" class="nav-link"><i class="undefined"></i>
  Agent 相关
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/langchain-prompt.html" class="nav-link"><i class="undefined"></i>
  练习langchain prompt的使用
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/construct-dataset.html" class="nav-link"><i class="undefined"></i>
  如何构造数据集
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/auto-model-desc.html" class="nav-link"><i class="undefined"></i>
  加载模型
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/compute-metrics.html" class="nav-link"><i class="undefined"></i>
  评估函数的使用
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/ner-instruct-task.html" class="nav-link"><i class="undefined"></i>
  NER 任务指令数据构造
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/finetuning-exercises-code.html" class="nav-link"><i class="undefined"></i>
  Fine-Tuning 实战作业三
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/finetuning-error-collect.html" class="nav-link"><i class="undefined"></i>
  微调实战三错误收集
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/finetuning-warn-collect.html" class="nav-link"><i class="undefined"></i>
  微调实战三警告收集
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/finetuning-f1-scores.html" class="nav-link"><i class="undefined"></i>
  微调实战F1 分数打印
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/model-train-analyze.html" class="nav-link"><i class="undefined"></i>
  训练完结果分析
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/finetuing-step5.html" class="nav-link"><i class="undefined"></i>
  微调实战-step5--数据处理函数
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/finetuing-step9.html" class="nav-link"><i class="undefined"></i>
  微调实战-step9--评估函数的使用
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/modelstudy/vLLM-intro.html" class="nav-link"><i class="undefined"></i>
  vLLM
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="undefined"></i>
      算法
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/sort.html" class="nav-link"><i class="undefined"></i>
  排序算法
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/double-pointer.html" class="nav-link"><i class="undefined"></i>
  双指针算法
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/binary-tree.html" class="nav-link"><i class="undefined"></i>
  二叉树
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/receive-rain.html" class="nav-link"><i class="undefined"></i>
  接雨水
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/dynamic-plan.html" class="nav-link"><i class="undefined"></i>
  动态规划
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/greedy.html" class="nav-link"><i class="undefined"></i>
  贪心算法
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/longasc-sequence.html" class="nav-link"><i class="undefined"></i>
  最长上升子序列
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/binary-search.html" class="nav-link"><i class="undefined"></i>
  二分查找
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/reverse-list.html" class="nav-link"><i class="undefined"></i>
  反转链表
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/del-single-list.html" class="nav-link"><i class="undefined"></i>
  删除单链表-集合
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/other.html" class="nav-link"><i class="undefined"></i>
  其他
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/compare-al.html" class="nav-link"><i class="undefined"></i>
  m个数，最多用n次比较，找出第二大的数
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/algorithm/effect-bracket.html" class="nav-link"><i class="undefined"></i>
  有效的括号
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="undefined"></i>
      其他
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/hmblog/other/ai-agent.html" class="nav-link"><i class="undefined"></i>
  AI项目
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/python.html" class="nav-link"><i class="undefined"></i>
  python学习
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/conda.html" class="nav-link"><i class="undefined"></i>
  Conda 使用
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/using-packages.html" class="nav-link"><i class="undefined"></i>
  Pytorch 框架使用
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/pytorch-know.html" class="nav-link"><i class="undefined"></i>
  Pytorch 框架知识点
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/transformer-learn.html" class="nav-link"><i class="undefined"></i>
  transformer库中那些常用函数
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/transformer-collect.html" class="nav-link"><i class="undefined"></i>
  transformer库学习哪些事
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/transformer-1.html" class="nav-link"><i class="undefined"></i>
  transformer 使用T5模型
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/transformer-2.html" class="nav-link"><i class="undefined"></i>
  torch DataLoader
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/transformer-3.html" class="nav-link"><i class="undefined"></i>
  设置随机种子
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/model-refrence.html" class="nav-link"><i class="undefined"></i>
  优秀的参考文档
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/git-operate.html" class="nav-link"><i class="undefined"></i>
  git 操作命令
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/fine-tuning-adapters.html" class="nav-link"><i class="undefined"></i>
  PEFT 之Adapters
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/swanLab-info.html" class="nav-link"><i class="undefined"></i>
  深度学习之SwanLab
</a></li><li class="dropdown-item"><!----> <a href="/hmblog/other/lora-0-1.html" class="nav-link"><i class="undefined"></i>
  从0到1手撕LoRA类
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="undefined"></i>
      关于我
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/hmyjyghh" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="undefined"></i>
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://gitee.com/ghh_" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="undefined"></i>
  Gitee
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.zhihu.com/people/cool-62-29/columns" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="undefined"></i>
  知乎
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://hmyjyghh.github.io/" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="undefined"></i>
  博客
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav> <!----> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-2c3e9f55 data-v-1c636796><h3 class="title" data-v-2c3e9f55></h3> <!----> <label id="box" class="inputBox" data-v-2c3e9f55><input type="password" value="" data-v-2c3e9f55> <span data-v-2c3e9f55>Konck! Knock!</span> <button data-v-2c3e9f55>OK</button></label> <div class="footer" data-v-2c3e9f55><span data-v-2c3e9f55><i class="iconfont reco-theme" data-v-2c3e9f55></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-2c3e9f55>vuePress-theme-reco</a></span> <span data-v-2c3e9f55><i class="iconfont reco-copyright" data-v-2c3e9f55></i> <a data-v-2c3e9f55><span data-v-2c3e9f55>寒梦</span>
          
        <!---->
        2025
      </a></span></div></div> <div data-v-1c636796><div data-v-1c636796><main class="page"><section style="display:;"><div class="page-title"><h1 class="title"></h1> <div data-v-6acedb3b><i class="iconfont reco-account" data-v-6acedb3b><span data-v-6acedb3b>寒梦</span></i> <!----> <!----> <!----></div></div> <div class="theme-reco-content content__default"><p>LangChain 有很多优秀的替代方案，每个都有不同的设计哲学和适用场景。以下是主要的替代方案：</p> <h2 id="_1-llamaindex-最流行的替代品"><a href="#_1-llamaindex-最流行的替代品" class="header-anchor">#</a> 1. <strong>LlamaIndex</strong>（最流行的替代品）</h2> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> llama_index <span class="token keyword">import</span> VectorStoreIndex<span class="token punctuation">,</span> SimpleDirectoryReader
<span class="token keyword">from</span> llama_index<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI

<span class="token comment"># 更专注于数据连接和检索</span>
documents <span class="token operator">=</span> SimpleDirectoryReader<span class="token punctuation">(</span><span class="token string">&quot;data&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span>
index <span class="token operator">=</span> VectorStoreIndex<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>documents<span class="token punctuation">)</span>
query_engine <span class="token operator">=</span> index<span class="token punctuation">.</span>as_query_engine<span class="token punctuation">(</span><span class="token punctuation">)</span>
response <span class="token operator">=</span> query_engine<span class="token punctuation">.</span>query<span class="token punctuation">(</span><span class="token string">&quot;你的问题&quot;</span><span class="token punctuation">)</span>
</code></pre></div><p><strong>特点</strong>：</p> <ul><li>专长于数据连接和检索增强生成(RAG)</li> <li>更简单的API，学习曲线平缓</li> <li>优秀的文档和向量存储集成</li></ul> <h2 id="_2-haystack-企业级选择"><a href="#_2-haystack-企业级选择" class="header-anchor">#</a> 2. <strong>Haystack</strong>（企业级选择）</h2> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> haystack <span class="token keyword">import</span> Pipeline
<span class="token keyword">from</span> haystack<span class="token punctuation">.</span>document_stores <span class="token keyword">import</span> InMemoryDocumentStore
<span class="token keyword">from</span> haystack<span class="token punctuation">.</span>nodes <span class="token keyword">import</span> EmbeddingRetriever<span class="token punctuation">,</span> PromptNode

<span class="token comment"># 面向生产环境的管道设计</span>
document_store <span class="token operator">=</span> InMemoryDocumentStore<span class="token punctuation">(</span><span class="token punctuation">)</span>
retriever <span class="token operator">=</span> EmbeddingRetriever<span class="token punctuation">(</span>document_store<span class="token operator">=</span>document_store<span class="token punctuation">)</span>
prompt_node <span class="token operator">=</span> PromptNode<span class="token punctuation">(</span>model_name_or_path<span class="token operator">=</span><span class="token string">&quot;gpt-3.5-turbo&quot;</span><span class="token punctuation">)</span>

pipeline <span class="token operator">=</span> Pipeline<span class="token punctuation">(</span><span class="token punctuation">)</span>
pipeline<span class="token punctuation">.</span>add_node<span class="token punctuation">(</span>component<span class="token operator">=</span>retriever<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&quot;Retriever&quot;</span><span class="token punctuation">,</span> inputs<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&quot;Query&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
pipeline<span class="token punctuation">.</span>add_node<span class="token punctuation">(</span>component<span class="token operator">=</span>prompt_node<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&quot;PromptNode&quot;</span><span class="token punctuation">,</span> inputs<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&quot;Retriever&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><p><strong>特点</strong>：</p> <ul><li>企业级稳定性和性能</li> <li>强大的管道(Pipeline)系统</li> <li>优秀的监控和部署工具</li></ul> <h2 id="_3-semantic-kernel-微软出品"><a href="#_3-semantic-kernel-微软出品" class="header-anchor">#</a> 3. <strong>Semantic Kernel</strong>（微软出品）</h2> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> semantic_kernel <span class="token keyword">as</span> sk
<span class="token keyword">from</span> semantic_kernel<span class="token punctuation">.</span>planning <span class="token keyword">import</span> BasicPlanner

<span class="token comment"># 微软的AI应用框架</span>
kernel <span class="token operator">=</span> sk<span class="token punctuation">.</span>Kernel<span class="token punctuation">(</span><span class="token punctuation">)</span>
planner <span class="token operator">=</span> BasicPlanner<span class="token punctuation">(</span><span class="token punctuation">)</span>
plan <span class="token operator">=</span> <span class="token keyword">await</span> planner<span class="token punctuation">.</span>create_plan_async<span class="token punctuation">(</span><span class="token string">&quot;任务描述&quot;</span><span class="token punctuation">,</span> kernel<span class="token punctuation">)</span>
</code></pre></div><p><strong>特点</strong>：</p> <ul><li>微软官方支持，与Azure深度集成</li> <li>强大的规划(Planning)能力</li> <li>良好的企业级特性</li></ul> <h2 id="_4-autogpt-agentgpt-自主代理"><a href="#_4-autogpt-agentgpt-自主代理" class="header-anchor">#</a> 4. <strong>AutoGPT</strong> / <strong>AgentGPT</strong>（自主代理）</h2> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 专注于自主AI代理</span>
<span class="token keyword">from</span> autogpt <span class="token keyword">import</span> AutoGPT
<span class="token keyword">from</span> autogpt<span class="token punctuation">.</span>agent <span class="token keyword">import</span> Agent

agent <span class="token operator">=</span> Agent<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">&quot;BusinessAnalyst&quot;</span><span class="token punctuation">)</span>
agent<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token string">&quot;分析市场数据并生成报告&quot;</span><span class="token punctuation">)</span>
</code></pre></div><p><strong>特点</strong>：</p> <ul><li>专注于自主任务执行</li> <li>强大的工具使用能力</li> <li>适合自动化工作流</li></ul> <h2 id="_5-transformers-agents-hugging-face"><a href="#_5-transformers-agents-hugging-face" class="header-anchor">#</a> 5. <strong>Transformers Agents</strong>（Hugging Face）</h2> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> transformers <span class="token keyword">import</span> HfAgent

<span class="token comment"># 直接使用Hugging Face模型</span>
agent <span class="token operator">=</span> HfAgent<span class="token punctuation">(</span><span class="token string">&quot;https://api-inference.huggingface.co/models/bigcode/starcoder&quot;</span><span class="token punctuation">)</span>
result <span class="token operator">=</span> agent<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token string">&quot;生成一个数据可视化代码&quot;</span><span class="token punctuation">)</span>
</code></pre></div><p><strong>特点</strong>：</p> <ul><li>直接集成Hugging Face生态系统</li> <li>丰富的预训练模型</li> <li>开源友好</li></ul> <h2 id="_6-langchain-lite-替代方案"><a href="#_6-langchain-lite-替代方案" class="header-anchor">#</a> 6. <strong>LangChain Lite</strong> 替代方案</h2> <h3 id="minichain-极简替代"><a href="#minichain-极简替代" class="header-anchor">#</a> <strong>MiniChain</strong>（极简替代）</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 超轻量级的链式操作</span>
<span class="token keyword">from</span> minichain <span class="token keyword">import</span> OpenAI<span class="token punctuation">,</span> prompt<span class="token punctuation">,</span> transform

<span class="token decorator annotation punctuation">@prompt</span><span class="token punctuation">(</span>OpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">answer_question</span><span class="token punctuation">(</span>context<span class="token punctuation">,</span> question<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token string-interpolation"><span class="token string">f&quot;&quot;&quot;基于以下上下文：</span><span class="token interpolation"><span class="token punctuation">{</span>context<span class="token punctuation">}</span></span><span class="token string">
    问题：</span><span class="token interpolation"><span class="token punctuation">{</span>question<span class="token punctuation">}</span></span><span class="token string">
    答案：&quot;&quot;&quot;</span></span>

response <span class="token operator">=</span> answer_question<span class="token punctuation">(</span><span class="token string">&quot;上下文内容&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;问题&quot;</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="chainlit-专注于ui"><a href="#chainlit-专注于ui" class="header-anchor">#</a> <strong>Chainlit</strong>（专注于UI）</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> chainlit <span class="token keyword">as</span> cl

<span class="token comment"># 快速构建ChatGPT式界面</span>
<span class="token decorator annotation punctuation">@cl<span class="token punctuation">.</span>on_message</span>
<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span>message<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 处理消息</span>
    <span class="token keyword">await</span> cl<span class="token punctuation">.</span>Message<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">&quot;回复&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>send<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="_7-专业领域替代方案"><a href="#_7-专业领域替代方案" class="header-anchor">#</a> 7. <strong>专业领域替代方案</strong></h2> <h3 id="对于数据分析-pandas-ai"><a href="#对于数据分析-pandas-ai" class="header-anchor">#</a> <strong>对于数据分析</strong>：Pandas AI</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> pandasai <span class="token keyword">import</span> SmartDataframe
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">&quot;data.csv&quot;</span><span class="token punctuation">)</span>
sdf <span class="token operator">=</span> SmartDataframe<span class="token punctuation">(</span>df<span class="token punctuation">)</span>
response <span class="token operator">=</span> sdf<span class="token punctuation">.</span>chat<span class="token punctuation">(</span><span class="token string">&quot;绘制销售趋势图&quot;</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="对于对话ai-rasa-botpress"><a href="#对于对话ai-rasa-botpress" class="header-anchor">#</a> <strong>对于对话AI</strong>：Rasa / Botpress</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 企业级对话AI平台</span>
<span class="token comment"># 更适合复杂的对话流程管理</span>
</code></pre></div><h3 id="对于搜索引擎-weaviate-chroma"><a href="#对于搜索引擎-weaviate-chroma" class="header-anchor">#</a> <strong>对于搜索引擎</strong>：Weaviate / Chroma</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 专注于向量搜索</span>
<span class="token keyword">import</span> weaviate
client <span class="token operator">=</span> weaviate<span class="token punctuation">.</span>Client<span class="token punctuation">(</span><span class="token string">&quot;http://localhost:8080&quot;</span><span class="token punctuation">)</span>
<span class="token comment"># 更专业的向量数据库解决方案</span>
</code></pre></div><h2 id="详细对比表格"><a href="#详细对比表格" class="header-anchor">#</a> 详细对比表格</h2> <table><thead><tr><th>框架</th> <th>优点</th> <th>缺点</th> <th>适用场景</th></tr></thead> <tbody><tr><td><strong>LangChain</strong></td> <td>功能全面，生态丰富</td> <td>学习曲线陡峭，API复杂</td> <td>复杂AI应用，原型开发</td></tr> <tr><td><strong>LlamaIndex</strong></td> <td>RAG专家，API简洁</td> <td>功能相对专注</td> <td>文档问答，数据检索</td></tr> <tr><td><strong>Haystack</strong></td> <td>企业级稳定，监控完善</td> <td>相对笨重</td> <td>生产环境，企业应用</td></tr> <tr><td><strong>Semantic Kernel</strong></td> <td>微软生态集成，规划强大</td> <td>主要面向.NET/Python</td> <td>企业级，Azure用户</td></tr> <tr><td><strong>AutoGPT</strong></td> <td>自主性强，自动化好</td> <td>资源消耗大</td> <td>自动化任务，AI代理</td></tr> <tr><td><strong>Transformers Agents</strong></td> <td>HF生态丰富，开源友好</td> <td>依赖HF基础设施</td> <td>研究，开源项目</td></tr></tbody></table> <h2 id="选择建议"><a href="#选择建议" class="header-anchor">#</a> 选择建议</h2> <h3 id="根据需求选择"><a href="#根据需求选择" class="header-anchor">#</a> <strong>根据需求选择</strong>：</h3> <ol><li><strong>快速原型开发</strong>：LangChain 或 LlamaIndex</li> <li><strong>生产环境</strong>：Haystack 或 Semantic Kernel</li> <li><strong>专注RAG</strong>：LlamaIndex</li> <li><strong>自主代理</strong>：AutoGPT</li> <li><strong>轻量级应用</strong>：MiniChain 或 直接使用OpenAI API</li> <li><strong>企业级</strong>：Haystack、Semantic Kernel</li></ol> <h3 id="简单项目推荐直接使用sdk"><a href="#简单项目推荐直接使用sdk" class="header-anchor">#</a> <strong>简单项目推荐直接使用SDK</strong>：</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 很多时候不需要完整框架</span>
<span class="token keyword">from</span> openai <span class="token keyword">import</span> OpenAI
client <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span>

response <span class="token operator">=</span> client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
    model<span class="token operator">=</span><span class="token string">&quot;gpt-3.5-turbo&quot;</span><span class="token punctuation">,</span>
    messages<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">&quot;role&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;user&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;content&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;你好&quot;</span><span class="token punctuation">}</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>
</code></pre></div><h2 id="迁移示例"><a href="#迁移示例" class="header-anchor">#</a> 迁移示例</h2> <h3 id="从-langchain-迁移到-llamaindex"><a href="#从-langchain-迁移到-llamaindex" class="header-anchor">#</a> 从 LangChain 迁移到 LlamaIndex：</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># LangChain 方式</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>document_loaders <span class="token keyword">import</span> TextLoader
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>text_splitter <span class="token keyword">import</span> CharacterTextSplitter
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> Chroma

<span class="token comment"># LlamaIndex 方式（更简洁）</span>
<span class="token keyword">from</span> llama_index <span class="token keyword">import</span> SimpleDirectoryReader<span class="token punctuation">,</span> VectorStoreIndex
documents <span class="token operator">=</span> SimpleDirectoryReader<span class="token punctuation">(</span><span class="token string">&quot;data&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span>
index <span class="token operator">=</span> VectorStoreIndex<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>documents<span class="token punctuation">)</span>
</code></pre></div><h3 id="从-langchain-迁移到-haystack"><a href="#从-langchain-迁移到-haystack" class="header-anchor">#</a> 从 LangChain 迁移到 Haystack：</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># LangChain 方式</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>agents <span class="token keyword">import</span> initialize_agent<span class="token punctuation">,</span> Tool

<span class="token comment"># Haystack 方式（更模块化）</span>
<span class="token keyword">from</span> haystack <span class="token keyword">import</span> Pipeline
<span class="token keyword">from</span> haystack<span class="token punctuation">.</span>nodes <span class="token keyword">import</span> PromptNode
</code></pre></div><h2 id="总结"><a href="#总结" class="header-anchor">#</a> 总结</h2> <p><strong>最佳选择策略</strong>：</p> <ul><li><strong>初学者/简单项目</strong>：LlamaIndex 或 直接使用SDK</li> <li><strong>企业生产环境</strong>：Haystack</li> <li><strong>研究/实验</strong>：LangChain（生态丰富）</li> <li><strong>微软生态</strong>：Semantic Kernel</li> <li><strong>想要更现代API</strong>：Agno</li></ul> <p>没有&quot;最好&quot;的框架，只有最适合你项目需求的框架。对于大多数场景，<strong>LlamaIndex</strong> 是 LangChain 最直接和友好的替代品。</p> <p>当前中文向量模型的发展非常活跃，多家机构和公司都推出了性能卓越的模型。为了让你能快速了解，我将主流的选择整理成了下面的表格。</p> <table><thead><tr><th style="text-align:left;">模型系列 / 来源</th> <th style="text-align:left;">代表性模型举例</th> <th style="text-align:left;">核心特点与适用场景</th></tr></thead> <tbody><tr><td style="text-align:left;"><strong>阿里通义千问 (Qwen)</strong></td> <td style="text-align:left;"><code>Qwen3-Embedding</code>系列 (如8B, 4B版本)</td> <td style="text-align:left;">专注于<strong>纯文本任务</strong>，在MTEB等权威榜单上表现优异，支持超100种语言，适合智能搜索、文本分类和RAG 。</td></tr> <tr><td style="text-align:left;"><strong>智源研究院 (BGE)</strong></td> <td style="text-align:left;"><code>BGE-Code-v1</code>, <code>BGE-VL-v1.5</code>, <code>BGE-VL-Screenshot</code></td> <td style="text-align:left;">生态丰富，覆盖<strong>代码、图文、截图</strong>等多模态检索，在特定领域基准测试中成绩领先，适合需要处理非纯文本数据的场景 。</td></tr> <tr><td style="text-align:left;"><strong>火山引擎 (Seed)</strong></td> <td style="text-align:left;"><code>Seed1.6-Embedding</code></td> <td style="text-align:left;">强调<strong>全模态</strong>能力，支持文本、图像、视频的混合检索，提供自定义指令功能，适合复杂的多模态和跨模态搜索需求 。</td></tr></tbody></table> <h3 id="💡-如何选择适合的模型"><a href="#💡-如何选择适合的模型" class="header-anchor">#</a> 💡 如何选择适合的模型？</h3> <p>面对这些优秀的模型，你可以根据以下思路来做出决策：</p> <ul><li><p><strong>明确你的任务类型</strong></p> <ul><li>如果你的应用场景完全是<strong>文本处理</strong>（如文档检索、问答系统），那么<strong>Qwen3-Embedding</strong>系列是一个性能强劲且经过广泛验证的选择 。</li> <li>如果你的需求涉及<strong>代码理解</strong>（如代码库搜索）、<strong>图像描述检索</strong>或<strong>网页/文档截图分析</strong>，那么<strong>智源BGE</strong>系列的专用模型会更有优势 。</li> <li>如果你的业务需要同时处理<strong>文本、图片甚至视频</strong>，并希望它们能在同一个向量空间中进行混合检索，可以重点关注<strong>火山引擎的Seed模型</strong> 。</li></ul></li> <li><p><strong>考虑部署条件</strong></p> <ul><li><strong>开源部署</strong>：上述模型基本都在Hugging Face、魔搭（ModelScope）等平台开源，适合希望自行部署、微调以掌控数据和模型的团队 。</li> <li><strong>API服务调用</strong>：如果你希望快速集成、避免维护模型的复杂性，可以关注模型提供商官方的API服务，例如通过阿里云百炼调用Qwen模型，或通过火山方舟调用Seed模型 。</li></ul></li></ul> <p>希望这份梳理能帮助你更好地了解当前的主流选择。如果你能分享一下你计划将模型用在什么具体项目上，或许我可以提供更细致的建议。</p> <p>好的，作为您的“高级大模型应用开发工程师”同事，我非常乐意为您深入剖析一下 <strong>Prompt-tuning</strong> 这项关键且实用的技术。</p> <p>如果说传统的<strong>微调（Fine-tuning）</strong> 是给预训练大模型“动手术”，通过更新<strong>所有</strong>参数来让它适应新任务，那么 <strong>Prompt-tuning 可以看作是一种“催眠术”或“引导术”</strong>。它的核心思想是：<strong>保持预训练大模型的所有参数冻结（不动），只通过优化一小段可学习的“软提示”（Soft Prompt），来激发模型解决特定任务的潜能。</strong></p> <hr> <h3 id="一、核心思想-从-硬提示-到-软提示"><a href="#一、核心思想-从-硬提示-到-软提示" class="header-anchor">#</a> 一、核心思想：从“硬提示”到“软提示”</h3> <p>为了更好地理解，我们先看一个对比：</p> <ol><li><p><strong>硬提示（Hard Prompt / 手工提示）</strong>：</p> <ul><li>这是我们平时与ChatGPT等模型交互的方式。我们通过自然语言精心设计指令，例如：
<blockquote><p><strong>指令</strong>：“将以下文本分类为正面或负面情感。文本：'这部电影太精彩了！'”</p></blockquote></li> <li><strong>缺点</strong>：这需要大量的人工尝试和调整（Prompt Engineering），效果不稳定，且找到最优提示如同大海捞针。</li></ul></li> <li><p><strong>软提示（Soft Prompt）</strong>：</p> <ul><li>Prompt-tuning 不再使用人类可读的词语作为提示。而是<strong>引入一小段可训练的、由模型嵌入空间中的向量（一组数字）组成的“提示”</strong>。</li> <li>这些向量没有直接的语义对应，它们是通过梯度下降算法在数据上<strong>自动学习出来的“最优指令”</strong>。可以把它理解为一种模型能“心领神会”的密语。</li></ul></li></ol> <p>下面的流程图清晰地展示了Prompt-tuning在应用时与Fine-tuning的区别：</p> <div class="language-mermaid extra-class"><pre class="language-mermaid"><code><span class="token keyword">flowchart</span> TD
    A<span class="token text string">[输入文本]</span> <span class="token arrow operator">--&gt;</span> B

    <span class="token keyword">subgraph</span> B <span class="token text string">[方法选择]</span>
        B1<span class="token text string">[Fine-tuning&lt;br&gt;更新全部模型参数]</span>
        B2<span class="token text string">[Prompt-tuning&lt;br&gt;仅优化提示向量]</span>
    <span class="token keyword">end</span>

    B1 <span class="token arrow operator">--&gt;</span> C1<span class="token text string">[模型参数被改变&lt;br&gt;“动了手术”]</span>
    B2 <span class="token arrow operator">--&gt;</span> C2<span class="token text string">[模型参数保持冻结&lt;br&gt;“被催眠引导”]</span>

    C1 <span class="token operator">&amp;</span> C2 <span class="token arrow operator">--&gt;</span> D<span class="token text string">[任务输出]</span>
</code></pre></div><hr> <h3 id="二、prompt-tuning-的主要优势"><a href="#二、prompt-tuning-的主要优势" class="header-anchor">#</a> 二、Prompt-tuning 的主要优势</h3> <p>为什么我们要使用Prompt-tuning？相比于传统的Fine-tuning，它带来了革命性的好处：</p> <ol><li><p><strong>参数效率极高（Parameter-Efficient）</strong></p> <ul><li>传统微调需要更新整个模型（可能包含数十亿甚至数千亿参数），计算和存储成本巨大。</li> <li>Prompt-tuning 只优化极少量的参数（通常只占模型总参数的0.01%~1%），大大降低了硬件门槛。</li></ul></li> <li><p><strong>避免灾难性遗忘（Catastrophic Forgetting）</strong></p> <ul><li>传统微调可能会为了让模型适应新任务而覆盖掉预训练时学到的通用知识。</li> <li>Prompt-tuning 保持原模型参数不变，完美保留了模型在预训练阶段获得的所有知识和能力。</li></ul></li> <li><p><strong>易于部署和切换</strong></p> <ul><li>对于一个基础模型（如LLaMA 3），你可以为不同任务（情感分析、命名实体识别、文本摘要）训练出多个不同的“软提示”。</li> <li>部署时，你只需要保存和加载这些小小的提示文件（几KB到几MB），即可让同一个模型实例瞬间切换为不同任务的专家，而无需维护多个完整的模型副本（每个都可能是几个GB）。</li></ul></li> <li><p><strong>效果逼近全量微调</strong></p> <ul><li>尤其是在模型规模足够大（例如超过100亿参数）时，Prompt-tuning 的性能可以逼近甚至在某些任务上超越全量微调。</li></ul></li></ol> <hr> <h3 id="三、prompt-tuning-的家族成员"><a href="#三、prompt-tuning-的家族成员" class="header-anchor">#</a> 三、Prompt-tuning 的家族成员</h3> <p>Prompt-tuning 是一个大家族，主要包括以下几种演进的技术：</p> <table><thead><tr><th style="text-align:left;">技术名称</th> <th style="text-align:left;">核心思想</th> <th style="text-align:left;">示意图简释</th></tr></thead> <tbody><tr><td style="text-align:left;"><strong>Prompt Tuning</strong> (狭义)</td> <td style="text-align:left;">只在输入层添加可训练的提示向量。</td> <td style="text-align:left;"><code>[可训练向量] + [输入文本] -&gt; [冻结的模型]</code></td></tr> <tr><td style="text-align:left;"><strong>Prefix-Tuning</strong></td> <td style="text-align:left;">不仅在输入层，还在模型的每一层（或中间层）前面添加可训练的前缀向量，控制能力更强。</td> <td style="text-align:left;"><code>[可训练向量] + [每层的激活值] -&gt; [冻结的下一层]</code></td></tr> <tr><td style="text-align:left;"><strong>P-Tuning</strong> / <strong>P-Tuning v2</strong></td> <td style="text-align:left;">一种更先进的优化方式，使用一个轻量级的“提示编码器”（如LSTM或MLP）来生成提示向量，而非直接优化，效果更稳定。P-Tuning v2 将其扩展到了所有层，类似Prefix-Tuning。</td> <td style="text-align:left;"><code>[输入文本] -&gt; [轻量级提示编码器] -&gt; [可训练向量] -&gt; [冻结的模型]</code></td></tr> <tr><td style="text-align:left;"><strong>LoRA (Low-Rank Adaptation)</strong></td> <td style="text-align:left;">虽然不完全是Prompt-tuning，但同属<strong>参数高效性微调（PEFT）</strong> 家族。它通过向模型内部注入低秩矩阵来间接模拟参数更新，而非添加提示。</td> <td style="text-align:left;"><code>[冻结的模型权重] + [低秩矩阵A&amp;B] -&gt; [适应后的效果]</code></td></tr></tbody></table> <p>现在，这些方法通常被统称为 <strong>PEFT</strong>。</p> <hr> <h3 id="四、一个简单的类比"><a href="#四、一个简单的类比" class="header-anchor">#</a> 四、一个简单的类比</h3> <p>为了让您印象更深刻，我们来做一个有趣的类比：</p> <ul><li><strong>预训练大模型</strong>：一位<strong>知识渊博的全科医生</strong>，掌握了全面的医学理论。</li> <li><strong>新任务</strong>：快速成为一名<strong>顶级的皮肤科专家</strong>。</li> <li><strong>全量微调（Fine-tuning）</strong>：让这位全科医生<strong>重新回医学院，花几年时间重修所有科目，但重点强化皮肤科</strong>。代价巨大，而且可能忘了其他科的知识。</li> <li><strong>提示工程（Hard Prompt）</strong>：你每次都对他说：“<strong>请你现在扮演一个皮肤科专家，看看这个病例……</strong>” 效果取决于你的指令水平，不稳定。</li> <li><strong>提示调优（Prompt-tuning）</strong>：你通过一种“催眠术”，为他植入一段<strong>特定的“思维导图”（软提示）</strong>。一旦植入，他看任何病患时，都会自动切换到皮肤科专家的思维模式，无需你再每次口头指令。这段“思维导图”就是学习出来的提示向量。</li></ul> <h3 id="总结-2"><a href="#总结-2" class="header-anchor">#</a> 总结</h3> <p><strong>Prompt-tuning/PEFT 技术是大模型时代应用落地的关键技术之一。</strong> 它极大地降低了定制和使用大模型的成本，让更多的研究者和开发者能够在不具备强大算力的情况下，高效地让通用大模型为自身的专属任务服务。</p> <p>在实际工作中，当我们拿到一个如 Qwen、ChatGLM 这样的优秀基座模型后，第一步往往就是尝试使用 Prompt-tuning 或 LoRA 等技术对其进行高效适配，而不是直接进行全量微调。</p> <p>好的，我们来深入探讨一下 <strong>Prefix Tuning</strong>。作为大模型应用开发者，理解这项技术至关重要，因为它是一种非常经典且高效的参数高效性微调（PEFT）方法。</p> <p>如果说传统的微调（Fine-tuning）是给大模型“换脑手术”，那么 <strong>Prefix-Tuning 可以看作是一种“深度催眠”或“前置引导”</strong>。它比我们之前讨论的普通Prompt-Tuning更进了一步，引导得更深、更有效。</p> <hr> <h3 id="一、核心思想-在每一层之前添加可学习的-前缀"><a href="#一、核心思想-在每一层之前添加可学习的-前缀" class="header-anchor">#</a> 一、核心思想：在每一层之前添加可学习的“前缀”</h3> <p>为了直观理解它的工作原理，我们将其与普通微调和基础Prompt-Tuning进行对比：</p> <p><img src="/hmblog//images/fine-tuning/prefix-tuning.png" alt="Prefix Tuning"></p> <p>从上图可以看出Prefix-Tuning的独特之处：</p> <ul><li><strong>普通Prompt-Tuning</strong>：只在模型的<strong>输入嵌入层（Input Embedding Layer）</strong> 添加可训练的提示向量。这相当于在对话开始时给模型一个总体的指令。</li> <li><strong>Prefix-Tuning</strong>：不仅在输入层，而是在<strong>模型的每一层（或某几层）的激活（activation）之前</strong>，都添加一组可训练的前缀向量。这相当于在模型思考的每一个步骤、每一个阶段都不断地进行引导和提醒，确保它不偏离轨道。</li></ul> <p><strong>关键比喻：</strong>
想象你在指导一位实习生写报告。</p> <ul><li><strong>Fine-tuning</strong>：你把他送去重新培训，改变他的整个知识结构。</li> <li><strong>Prompt-Tuning</strong>：你在任务开始时给他一份详细的书面指令。</li> <li><strong>Prefix-Tuning</strong>：你不仅给了书面指令，还在他写报告的每一个章节（引言、正文、结论）开始时，都在他旁边给予针对性的提示和引导。这种“持续陪伴”式的指导显然更深入、更有效。</li></ul> <hr> <h3 id="二、技术细节-它是如何工作的"><a href="#二、技术细节-它是如何工作的" class="header-anchor">#</a> 二、技术细节：它是如何工作的？</h3> <ol><li><p><strong>冻结主模型</strong>：预训练大模型的所有参数被<strong>冻结（Freeze）</strong>，不允许更新。这最大程度保留了模型原有的知识，避免了灾难性遗忘。</p></li> <li><p><strong>引入前缀矩阵（Prefix Matrix）</strong>：</p> <ul><li>我们为模型需要添加前缀的每一层，都初始化一个小的、可训练的矩阵，称为前缀矩阵。</li> <li>这个矩阵的每一行都是一个向量，代表一个“前缀token”。这些向量不是自然语言词汇的嵌入，而是<strong>在模型的隐藏空间（Hidden Space）中通过训练学习得到的“软提示”（Soft Prompts）</strong>。</li></ul></li> <li><p><strong>拼接（Concatenation）与前向传播（Forward Pass）</strong>：</p> <ul><li>在模型每一层的前向计算过程中，我们将学习到的前缀向量（<code>[PREFIX]</code>）与该层原始的输入序列向量（<code>[INPUT]</code>）进行拼接，形成 <code>[PREFIX; INPUT]</code>。</li> <li>然后，将这个拼接后的序列送给该层的Transformer模块进行处理。</li> <li>由于前缀向量是可训练的，在训练过程中，通过梯度下降来优化这些向量，使得它们能够最有效地“刺激”或“引导”冻结的模型去完成特定任务。</li></ul></li></ol> <hr> <h3 id="三、prefix-tuning-的主要优势"><a href="#三、prefix-tuning-的主要优势" class="header-anchor">#</a> 三、Prefix-Tuning 的主要优势</h3> <p>相比于普通的Prompt-Tuning和全量微调，Prefix-Tuning的优势非常突出：</p> <ol><li><p><strong>更强的表现力与控制力</strong>：</p> <ul><li>由于引导信号（前缀）被注入到了模型的更深层，它能更直接地影响模型每一层的注意力机制（Attention）和前馈网络（FFN）的计算，从而对模型的行为实现更精细、更强大的控制。效果通常比只在输入层添加提示的Prompt-Tuning更好。</li></ul></li> <li><p><strong>极高的参数效率</strong>：</p> <ul><li>和所有PEFT方法一样，它只训练极小部分的参数（仅占模型总参数的0.1%~3%），极大地降低了计算和存储成本。你可以为一个基础模型训练无数个不同的“前缀”，来应对不同的任务，部署时只需切换这个小文件即可。</li></ul></li> <li><p><strong>保留通用知识</strong>：</p> <ul><li>主模型参数被冻结，其强大的语言理解和生成能力得以完整保留，完美避免了灾难性遗忘。</li></ul></li> <li><p><strong>训练更稳定</strong>：</p> <ul><li>相较于早期直接优化嵌入向量的Prompt-Tuning，Prefix-Tuning的效果通常更稳定。后来的一些改进（如将前缀向量通过一个小的神经网络来生成，而非直接优化）进一步提升了其稳定性。</li></ul></li></ol> <hr> <h3 id="四、与相关技术的对比"><a href="#四、与相关技术的对比" class="header-anchor">#</a> 四、与相关技术的对比</h3> <table><thead><tr><th style="text-align:left;">技术</th> <th style="text-align:left;">训练参数</th> <th style="text-align:left;">作用位置</th> <th style="text-align:left;">特点</th></tr></thead> <tbody><tr><td style="text-align:left;"><strong>Full Fine-tuning（全量微调）</strong></td> <td style="text-align:left;">全部（100%）</td> <td style="text-align:left;">模型所有参数</td> <td style="text-align:left;">效果可能最好，但成本极高，易遗忘，产生模型副本。</td></tr> <tr><td style="text-align:left;"><strong>Prompt-Tuning</strong></td> <td style="text-align:left;">极少（~0.01%）</td> <td style="text-align:left;"><strong>仅输入嵌入层</strong></td> <td style="text-align:left;">最简单，参数量最少，但在模型较小时效果不佳。</td></tr> <tr><td style="text-align:left;"><strong>Prefix-Tuning</strong></td> <td style="text-align:left;">少（~0.1%-3%）</td> <td style="text-align:left;"><strong>每一层（或中间层）的激活之前</strong></td> <td style="text-align:left;">控制力强，效果通常优于Prompt-Tuning，是更优的选择。</td></tr> <tr><td style="text-align:left;"><strong>LoRA</strong></td> <td style="text-align:left;">少（~0.1%-3%）</td> <td style="text-align:left;"><strong>注入到注意力层的旁路矩阵</strong></td> <td style="text-align:left;">通过低秩适应间接更新权重，效果与Prefix-Tuning相当，常是首选。</td></tr></tbody></table> <h3 id="总结-3"><a href="#总结-3" class="header-anchor">#</a> 总结</h3> <p><strong>Prefix-Tuning 的核心贡献在于，它证明了不需要改动庞大的模型参数，只需要在模型的合适深度（每一层）插入极少量可学习的“刺激信号”，就能高效地引导大模型完成特定任务。</strong></p> <p>它是通向更高效、更模块化的大模型定制之路上的一个关键里程碑。在实际应用中，如今我们更常使用其思想的后继者（如 <strong>P-Tuning v2</strong>）或另一种流行技术 <strong>LoRA</strong>，但它们的基本理念与Prefix-Tuning一脉相承：<strong>用最小的代价，实现最有效的引导。</strong></p> <p>希望这个解释能帮助您透彻地理解Prefix-Tuning！</p> <p>直接问 deepseek
https://github.com/huggingface/peft/blob/main/examples/sft/run_peft.sh</p> <p>这个文件怎么运行，里面的  --model_name_or_path &quot;mistralai/Mistral-7B-v0.1&quot; <br>
--dataset_name &quot;smangrul/ultrachat-10k-chatml&quot; \</p> <p>模型  和  dataset   是不是都要下载到本地</p> <hr> <p>回答：</p> <p>看了这个脚本，我来详细解释一下运行方式：</p> <h2 id="运行方式"><a href="#运行方式" class="header-anchor">#</a> 运行方式</h2> <h3 id="_1-直接运行-推荐网络条件好的情况"><a href="#_1-直接运行-推荐网络条件好的情况" class="header-anchor">#</a> 1. 直接运行（推荐网络条件好的情况）</h3> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># 克隆仓库</span>
<span class="token function">git</span> clone https://github.com/huggingface/peft.git
<span class="token builtin class-name">cd</span> peft/examples/sft

<span class="token comment"># 直接运行脚本</span>
<span class="token function">bash</span> run_peft.sh
</code></pre></div><h3 id="_2-模型和数据集下载问题"><a href="#_2-模型和数据集下载问题" class="header-anchor">#</a> 2. 模型和数据集下载问题</h3> <p><strong>模型（mistralai/Mistral-7B-v0.1）</strong>：</p> <ul><li><strong>默认</strong>：会自动从Hugging Face Hub下载（需要约15GB空间）</li> <li><strong>本地已有</strong>：如果本地有该模型，可以修改路径指向本地目录</li></ul> <p><strong>数据集（smangrul/ultrachat-10k-chatml）</strong>：</p> <ul><li><strong>默认</strong>：会自动下载（数据量较小）</li> <li><strong>本地已有</strong>：同样可以修改路径</li></ul> <h2 id="本地下载方案"><a href="#本地下载方案" class="header-anchor">#</a> 本地下载方案</h2> <p>如果你希望预先下载到本地：</p> <h3 id="下载模型到本地"><a href="#下载模型到本地" class="header-anchor">#</a> 下载模型到本地</h3> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># 使用huggingface-cli</span>
pip <span class="token function">install</span> huggingface_hub
huggingface-cli download mistralai/Mistral-7B-v0.1 --local-dir ./mistral-7b-local

<span class="token comment"># 或者使用Python</span>
from transformers <span class="token function">import</span> AutoModel, AutoTokenizer
model <span class="token operator">=</span> AutoModel.from_pretrained<span class="token punctuation">(</span><span class="token string">&quot;mistralai/Mistral-7B-v0.1&quot;</span>, <span class="token assign-left variable">cache_dir</span><span class="token operator">=</span><span class="token string">&quot;./models&quot;</span><span class="token punctuation">)</span>
tokenizer <span class="token operator">=</span> AutoTokenizer.from_pretrained<span class="token punctuation">(</span><span class="token string">&quot;mistralai/Mistral-7B-v0.1&quot;</span>, <span class="token assign-left variable">cache_dir</span><span class="token operator">=</span><span class="token string">&quot;./models&quot;</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="修改脚本使用本地路径"><a href="#修改脚本使用本地路径" class="header-anchor">#</a> 修改脚本使用本地路径</h3> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># 修改run_peft.sh中的相关行</span>
<span class="token parameter variable">--model_name_or_path</span> <span class="token string">&quot;./mistral-7b-local&quot;</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--dataset_name</span> <span class="token string">&quot;./local-dataset&quot;</span> <span class="token punctuation">\</span>
</code></pre></div><h2 id="注意事项"><a href="#注意事项" class="header-anchor">#</a> 注意事项</h2> <ol><li><strong>存储空间</strong>：Mistral-7B模型需要约15GB空间</li> <li><strong>网络要求</strong>：首次运行需要稳定网络连接下载资源</li> <li><strong>内存要求</strong>：需要足够RAM来加载模型（建议16GB+）</li> <li><strong>GPU要求</strong>：脚本默认使用GPU，如需CPU运行需要修改相关参数</li></ol> <h2 id="替代方案-如果下载困难"><a href="#替代方案-如果下载困难" class="header-anchor">#</a> 替代方案（如果下载困难）</h2> <p>如果下载大模型有困难，可以考虑：</p> <ol><li><p><strong>使用小模型</strong>：替换为较小的模型如：</p> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token parameter variable">--model_name_or_path</span> <span class="token string">&quot;facebook/opt-1.3b&quot;</span> <span class="token punctuation">\</span>
</code></pre></div></li> <li><p><strong>使用本地小数据集</strong>：准备自己的数据集格式</p></li></ol> <p>需要我帮你修改脚本适配本地资源或提供更详细的配置说明吗？</p> <h3 id="langchain-练习"><a href="#langchain-练习" class="header-anchor">#</a> langchain 练习</h3> <p>我来帮你将 Agently 的提示词改造为 Langchain 的 PromptTemplate 写法：</p> <h2 id="_1-完整的-langchain-prompt-实现"><a href="#_1-完整的-langchain-prompt-实现" class="header-anchor">#</a> 1. 完整的 Langchain Prompt 实现</h2> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> ChatPromptTemplate<span class="token punctuation">,</span> SystemMessagePromptTemplate<span class="token punctuation">,</span> HumanMessagePromptTemplate
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>schema <span class="token keyword">import</span> SystemMessage<span class="token punctuation">,</span> HumanMessage

<span class="token comment"># 创建系统提示词</span>
system_template <span class="token operator">=</span> <span class="token triple-quoted-string string">&quot;&quot;&quot;你是一个分析诈骗案例并且擅长写作的专家，你的任务是将诈骗的案发过程以口语对话的形式完整的还原。

请遵循以下要求：
1. 分析用户提供的文本中描述的案发过程，识别出诈骗者和受害者角色，并为每个角色生成一个中文姓名。
2. 发挥你的想象力，按照前后经过，将案发过程以诈骗者和受害者之间的对话来循序渐进地展开，目的是还原整个诈骗案件的详细对话过程。
3. 诈骗者的发言内容需要尽可能的伪装，让自己的身份和操作都听起来正规，以避免受害者怀疑。
4. 从第一句发言开始，依次分析每条发言内容是否存在明确的欺诈内容。

请以以下JSON格式输出结果：
{{
    &quot;result&quot;: [
        {{
            &quot;speaker&quot;: &quot;发言人的中文姓名(不含角色)&quot;,
            &quot;content&quot;: &quot;发言的详细内容&quot;, 
            &quot;is_fraud&quot;: &quot;true或false，表示该发言中是否存在明确具体、不可辩驳的欺诈内容&quot;
        }}
    ]
}}
&quot;&quot;&quot;</span>

system_message_prompt <span class="token operator">=</span> SystemMessagePromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span>system_template<span class="token punctuation">)</span>

<span class="token comment"># 创建用户输入模板</span>
human_template <span class="token operator">=</span> <span class="token triple-quoted-string string">&quot;&quot;&quot;请分析以下诈骗案例文本：

{text}&quot;&quot;&quot;</span>

human_message_prompt <span class="token operator">=</span> HumanMessagePromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span>human_template<span class="token punctuation">)</span>

<span class="token comment"># 组合成完整的 ChatPromptTemplate</span>
chat_prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_messages<span class="token punctuation">(</span><span class="token punctuation">[</span>
    system_message_prompt<span class="token punctuation">,</span>
    human_message_prompt
<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="_2-使用方式"><a href="#_2-使用方式" class="header-anchor">#</a> 2. 使用方式</h2> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>chat_models <span class="token keyword">import</span> ChatOpenAI
<span class="token keyword">import</span> json

<span class="token comment"># 初始化 DeepSeek 模型</span>
llm <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>
    model<span class="token operator">=</span><span class="token string">&quot;deepseek-chat&quot;</span><span class="token punctuation">,</span>
    openai_api_key<span class="token operator">=</span><span class="token string">&quot;your_deepseek_api_key&quot;</span><span class="token punctuation">,</span>
    openai_api_base<span class="token operator">=</span><span class="token string">&quot;https://api.deepseek.com/v1&quot;</span><span class="token punctuation">,</span>
    temperature<span class="token operator">=</span><span class="token number">0.1</span>
<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">analyze_fraud_case</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    分析诈骗案例并生成对话
    &quot;&quot;&quot;</span>
    <span class="token comment"># 构建提示词</span>
    messages <span class="token operator">=</span> chat_prompt<span class="token punctuation">.</span>format_messages<span class="token punctuation">(</span>text<span class="token operator">=</span>text<span class="token punctuation">)</span>
    
    <span class="token comment"># 调用模型</span>
    response <span class="token operator">=</span> llm<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>messages<span class="token punctuation">)</span>
    
    <span class="token comment"># 解析响应</span>
    <span class="token keyword">if</span> <span class="token builtin">hasattr</span><span class="token punctuation">(</span>response<span class="token punctuation">,</span> <span class="token string">'content'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">try</span><span class="token punctuation">:</span>
            <span class="token comment"># 清理可能的markdown格式</span>
            content <span class="token operator">=</span> response<span class="token punctuation">.</span>content
            content <span class="token operator">=</span> content<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'```json'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'```'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
            result <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>content<span class="token punctuation">)</span>
            <span class="token keyword">return</span> result
        <span class="token keyword">except</span> json<span class="token punctuation">.</span>JSONDecodeError <span class="token keyword">as</span> e<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;JSON解析错误: </span><span class="token interpolation"><span class="token punctuation">{</span>e<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;原始响应: </span><span class="token interpolation"><span class="token punctuation">{</span>response<span class="token punctuation">.</span>content<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
            <span class="token keyword">return</span> <span class="token boolean">None</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>

<span class="token comment"># 使用示例</span>
text <span class="token operator">=</span> dataset<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>column_content<span class="token punctuation">]</span>
result <span class="token operator">=</span> analyze_fraud_case<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>result<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="_3-更简洁的版本-使用字符串模板"><a href="#_3-更简洁的版本-使用字符串模板" class="header-anchor">#</a> 3. 更简洁的版本（使用字符串模板）</h2> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate

<span class="token comment"># 创建完整的提示词模板</span>
prompt_template <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&quot;text&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    template<span class="token operator">=</span><span class="token triple-quoted-string string">&quot;&quot;&quot;你是一个分析诈骗案例并且擅长写作的专家，你的任务是将诈骗的案发过程以口语对话的形式完整的还原。

请分析以下诈骗案例文本：
{text}

要求：
1. 分析文本中描述的案发过程，识别出诈骗者和受害者角色，并为每个角色生成一个中文姓名。
2. 发挥你的想象力，按照前后经过，将案发过程以诈骗者和受害者之间的对话来循序渐进地展开，目的是还原整个诈骗案件的详细对话过程。
3. 诈骗者的发言内容需要尽可能的伪装，让自己的身份和操作都听起来正规，以避免受害者怀疑。
4. 从第一句发言开始，依次分析每条发言内容是否存在明确的欺诈内容。

请以以下JSON格式输出结果：
{{
    &quot;result&quot;: [
        {{
            &quot;speaker&quot;: &quot;发言人的中文姓名(不含角色)&quot;,
            &quot;content&quot;: &quot;发言的详细内容&quot;, 
            &quot;is_fraud&quot;: &quot;true或false，表示该发言中是否存在明确具体、不可辩驳的欺诈内容&quot;
        }}
    ]
}}

请直接返回JSON格式的结果，不要添加其他解释。&quot;&quot;&quot;</span>
<span class="token punctuation">)</span>

<span class="token comment"># 使用方式</span>
<span class="token keyword">def</span> <span class="token function">analyze_fraud_case_simple</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    formatted_prompt <span class="token operator">=</span> prompt_template<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>text<span class="token operator">=</span>text<span class="token punctuation">)</span>
    response <span class="token operator">=</span> llm<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>formatted_prompt<span class="token punctuation">)</span>
    
    <span class="token keyword">if</span> <span class="token builtin">hasattr</span><span class="token punctuation">(</span>response<span class="token punctuation">,</span> <span class="token string">'content'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">try</span><span class="token punctuation">:</span>
            content <span class="token operator">=</span> response<span class="token punctuation">.</span>content
            content <span class="token operator">=</span> content<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'```json'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'```'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">return</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>content<span class="token punctuation">)</span>
        <span class="token keyword">except</span> json<span class="token punctuation">.</span>JSONDecodeError<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;解析失败，返回原始内容&quot;</span><span class="token punctuation">)</span>
            <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">&quot;raw_response&quot;</span><span class="token punctuation">:</span> content<span class="token punctuation">}</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>
</code></pre></div><h2 id="_4-使用-lcel-链式调用-推荐"><a href="#_4-使用-lcel-链式调用-推荐" class="header-anchor">#</a> 4. 使用 LCEL 链式调用（推荐）</h2> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>output_parsers <span class="token keyword">import</span> JsonOutputParser
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> ChatPromptTemplate

<span class="token comment"># 创建输出解析器</span>
output_parser <span class="token operator">=</span> JsonOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 创建提示词模板</span>
prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_messages<span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">&quot;system&quot;</span><span class="token punctuation">,</span> <span class="token triple-quoted-string string">&quot;&quot;&quot;你是一个分析诈骗案例并且擅长写作的专家。你的任务是将诈骗的案发过程以口语对话的形式完整的还原。
    
要求：
1. 分析案发过程，识别诈骗者和受害者角色，为每个角色生成中文姓名
2. 以对话形式循序渐进展开案发过程
3. 诈骗者发言要伪装得正规可信
4. 分析每条发言是否存在明确欺诈内容&quot;&quot;&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">&quot;human&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;请分析以下诈骗案例：{text}&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">&quot;human&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;请以指定JSON格式输出：{format_instructions}&quot;</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 构建链</span>
chain <span class="token operator">=</span> prompt <span class="token operator">|</span> llm <span class="token operator">|</span> output_parser

<span class="token comment"># 使用链</span>
<span class="token keyword">def</span> <span class="token function">analyze_fraud_with_chain</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        result <span class="token operator">=</span> chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">{</span>
            <span class="token string">&quot;text&quot;</span><span class="token punctuation">:</span> text<span class="token punctuation">,</span>
            <span class="token string">&quot;format_instructions&quot;</span><span class="token punctuation">:</span> output_parser<span class="token punctuation">.</span>get_format_instructions<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> result
    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;分析失败: </span><span class="token interpolation"><span class="token punctuation">{</span>e<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token boolean">None</span>

<span class="token comment"># 使用示例</span>
text <span class="token operator">=</span> dataset<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>column_content<span class="token punctuation">]</span>
result <span class="token operator">=</span> analyze_fraud_with_chain<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
</code></pre></div><h2 id="主要变化说明"><a href="#主要变化说明" class="header-anchor">#</a> 主要变化说明：</h2> <ol><li><strong>角色定义</strong>：从 <code>.role()</code> 改为 SystemMessage</li> <li><strong>输入处理</strong>：从 <code>.input()</code> 改为 HumanMessage 中的变量替换</li> <li><strong>指令</strong>：从 <code>.instruct()</code> 改为提示词中的具体要求列表</li> <li><strong>输出格式</strong>：从 <code>.output()</code> 改为在提示词中描述JSON格式</li> <li><strong>执行</strong>：从 <code>.start()</code> 改为 <code>.invoke()</code></li></ol> <p>这样的改造保持了原有的功能，同时符合 Langchain 的编程范式。</p> <p>你遇到的问题是 Python 字典的默认显示方式，不是模型生成的问题。让我解释一下：</p> <h2 id="问题分析"><a href="#问题分析" class="header-anchor">#</a> 问题分析</h2> <p>你看到的单引号和首字母大写的 True/False 是 <strong>Python 字典的默认表示形式</strong>，不是模型生成的 JSON 格式问题。</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 这是 Python 字典的显示方式（单引号，True/False 首字母大写）</span>
<span class="token punctuation">{</span><span class="token string">'result'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'speaker'</span><span class="token punctuation">:</span> <span class="token string">'张伟'</span><span class="token punctuation">,</span> <span class="token string">'content'</span><span class="token punctuation">:</span> <span class="token string">'...'</span><span class="token punctuation">,</span> <span class="token string">'is_fraud'</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span>

<span class="token comment"># 这是标准的 JSON 格式（双引号，true/false 小写）</span>
<span class="token punctuation">{</span><span class="token string">&quot;result&quot;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">&quot;speaker&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;张伟&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;content&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;...&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;is_fraud&quot;</span><span class="token punctuation">:</span> true<span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
</code></pre></div><h2 id="验证方法"><a href="#验证方法" class="header-anchor">#</a> 验证方法</h2> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 检查实际的 JSON 内容</span>
<span class="token keyword">import</span> json

<span class="token comment"># 假设 result 是你得到的字典</span>
result <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'result'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'speaker'</span><span class="token punctuation">:</span> <span class="token string">'张伟'</span><span class="token punctuation">,</span> <span class="token string">'content'</span><span class="token punctuation">:</span> <span class="token string">'...'</span><span class="token punctuation">,</span> <span class="token string">'is_fraud'</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span>

<span class="token comment"># 1. 转换为 JSON 字符串查看实际格式</span>
json_str <span class="token operator">=</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>result<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;JSON 字符串格式:&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>json_str<span class="token punctuation">)</span>
<span class="token comment"># 输出: {&quot;result&quot;: [{&quot;speaker&quot;: &quot;张伟&quot;, &quot;content&quot;: &quot;...&quot;, &quot;is_fraud&quot;: true}]}</span>

<span class="token comment"># 2. 检查是否可以正常解析</span>
parsed <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>json_str<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;解析后的类型:&quot;</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>parsed<span class="token punctuation">[</span><span class="token string">'result'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'is_fraud'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="解决方案"><a href="#解决方案" class="header-anchor">#</a> 解决方案</h2> <h3 id="方法1-直接使用-json-处理"><a href="#方法1-直接使用-json-处理" class="header-anchor">#</a> 方法1：直接使用 JSON 处理</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> json

<span class="token keyword">def</span> <span class="token function">analyze_fraud_case</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># ... 调用模型的代码 ...</span>
    
    <span class="token keyword">if</span> <span class="token builtin">hasattr</span><span class="token punctuation">(</span>response<span class="token punctuation">,</span> <span class="token string">'content'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 清理响应内容</span>
        content <span class="token operator">=</span> response<span class="token punctuation">.</span>content<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
        content <span class="token operator">=</span> content<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'```json'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'```'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token keyword">try</span><span class="token punctuation">:</span>
            <span class="token comment"># 直接解析为 Python 对象</span>
            result <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>content<span class="token punctuation">)</span>
            <span class="token keyword">return</span> result
        <span class="token keyword">except</span> json<span class="token punctuation">.</span>JSONDecodeError <span class="token keyword">as</span> e<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;JSON解析错误: </span><span class="token interpolation"><span class="token punctuation">{</span>e<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
            <span class="token keyword">return</span> <span class="token boolean">None</span>

<span class="token comment"># 使用时，结果已经是正确的 Python 字典</span>
result <span class="token operator">=</span> analyze_fraud_case<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
</code></pre></div><h3 id="方法2-增强提示词约束"><a href="#方法2-增强提示词约束" class="header-anchor">#</a> 方法2：增强提示词约束</h3> <div class="language-python extra-class"><pre class="language-python"><code>system_template <span class="token operator">=</span> <span class="token triple-quoted-string string">&quot;&quot;&quot;你是一个分析诈骗案例并且擅长写作的专家。任务：将诈骗案发过程以口语对话形式还原。

要求：
1. 识别诈骗者和受害者角色，生成中文姓名
2. 以对话形式展开案发过程  
3. 诈骗者发言要伪装正规
4. 分析每条发言是否存在欺诈内容

严格的JSON格式要求：
- 必须使用双引号包围所有字符串键和值
- 布尔值必须使用小写 true 或 false
- 不要使用单引号
- 确保是有效的JSON格式

输出示例：
{
    &quot;result&quot;: [
        {
            &quot;speaker&quot;: &quot;张三&quot;,
            &quot;content&quot;: &quot;对话内容&quot;,
            &quot;is_fraud&quot;: true
        }
    ]
}

重要：直接输出纯净JSON，不要任何其他文字！&quot;&quot;&quot;</span>
</code></pre></div><h3 id="方法3-使用-langchain-的-json-解析器"><a href="#方法3-使用-langchain-的-json-解析器" class="header-anchor">#</a> 方法3：使用 Langchain 的 JSON 解析器</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>output_parsers <span class="token keyword">import</span> JsonOutputParser

output_parser <span class="token operator">=</span> JsonOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">analyze_fraud_case</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 构建提示词</span>
    messages <span class="token operator">=</span> <span class="token punctuation">[</span>
        <span class="token punctuation">(</span><span class="token string">&quot;system&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;你是诈骗案例分析专家...&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token string">&quot;human&quot;</span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f&quot;分析案例：</span><span class="token interpolation"><span class="token punctuation">{</span>text<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token string">&quot;human&quot;</span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f&quot;格式要求：</span><span class="token interpolation"><span class="token punctuation">{</span>output_parser<span class="token punctuation">.</span>get_format_instructions<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
    <span class="token punctuation">]</span>
    
    <span class="token comment"># 调用模型并解析</span>
    response <span class="token operator">=</span> llm<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>messages<span class="token punctuation">)</span>
    result <span class="token operator">=</span> output_parser<span class="token punctuation">.</span>parse<span class="token punctuation">(</span>response<span class="token punctuation">.</span>content<span class="token punctuation">)</span>
    <span class="token keyword">return</span> result
</code></pre></div><h2 id="验证代码正确性"><a href="#验证代码正确性" class="header-anchor">#</a> 验证代码正确性</h2> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 测试你的结果</span>
test_result <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'result'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'speaker'</span><span class="token punctuation">:</span> <span class="token string">'张伟'</span><span class="token punctuation">,</span> <span class="token string">'content'</span><span class="token punctuation">:</span> <span class="token string">'...'</span><span class="token punctuation">,</span> <span class="token string">'is_fraud'</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span>

<span class="token comment"># 1. 检查是否可以序列化为标准 JSON</span>
json_str <span class="token operator">=</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>test_result<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;标准JSON格式:&quot;</span><span class="token punctuation">,</span> json_str<span class="token punctuation">)</span>

<span class="token comment"># 2. 检查是否可以保存到文件并读取</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'test_output.json'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    json<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>test_result<span class="token punctuation">,</span> f<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'test_output.json'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    file_content <span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;从文件读取的内容:&quot;</span><span class="token punctuation">,</span> file_content<span class="token punctuation">)</span>
</code></pre></div><p><strong>总结</strong>：你看到的单引号和首字母大写的 True/False 只是 Python 字典的显示方式，实际在 JSON 序列化时会自动转换为标准的双引号和小写 true/false。你的代码很可能是正确的！</p> <hr> <h3 id="_10-03"><a href="#_10-03" class="header-anchor">#</a> 10.03</h3> <p>很好！你的 <code>label2id</code> 映射是正确的。现在基于你已有的标签映射，我来提供一个完整的 <code>collote_fn</code> 实现：</p> <h2 id="完整的-collote-fn-函数"><a href="#完整的-collote-fn-函数" class="header-anchor">#</a> 完整的 collote_fn 函数</h2> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">collote_fn</span><span class="token punctuation">(</span>batch_samples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    batch_sentence<span class="token punctuation">,</span> batch_char_labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    
    <span class="token comment"># 从batch samples中提取句子并生成字符级标签</span>
    <span class="token keyword">for</span> sample <span class="token keyword">in</span> batch_samples<span class="token punctuation">:</span>
        sentence <span class="token operator">=</span> sample<span class="token punctuation">[</span><span class="token string">'sentence'</span><span class="token punctuation">]</span>
        batch_sentence<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
        
        <span class="token comment"># 生成字符级BIO标签序列</span>
        char_labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'O'</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>  <span class="token comment"># 初始化为'O'</span>
        
        <span class="token comment"># 根据实体标注信息填充标签</span>
        <span class="token keyword">for</span> start<span class="token punctuation">,</span> end<span class="token punctuation">,</span> text<span class="token punctuation">,</span> label_type <span class="token keyword">in</span> sample<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> pos <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>start<span class="token punctuation">,</span> end <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> pos <span class="token operator">==</span> start<span class="token punctuation">:</span>
                    char_labels<span class="token punctuation">[</span>pos<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f'B-</span><span class="token interpolation"><span class="token punctuation">{</span>label_type<span class="token punctuation">}</span></span><span class="token string">'</span></span>
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                    char_labels<span class="token punctuation">[</span>pos<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f'I-</span><span class="token interpolation"><span class="token punctuation">{</span>label_type<span class="token punctuation">}</span></span><span class="token string">'</span></span>
        
        batch_char_labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span>char_labels<span class="token punctuation">)</span>
    
    <span class="token comment"># 对文本进行分词</span>
    batch_inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>
        batch_sentence<span class="token punctuation">,</span>
        padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> 
        max_length<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span>
        return_tensors<span class="token operator">=</span><span class="token string">&quot;pt&quot;</span><span class="token punctuation">,</span>
        is_split_into_words<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token comment"># 重要：告诉tokenizer我们处理的是字符级任务</span>
        return_offsets_mapping<span class="token operator">=</span><span class="token boolean">True</span>  <span class="token comment"># 获取字符到token的映射关系</span>
    <span class="token punctuation">)</span>
    
    <span class="token comment"># 对齐标签：将字符级标签映射到token级标签</span>
    aligned_labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>batch_sentence<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        word_ids <span class="token operator">=</span> batch_inputs<span class="token punctuation">.</span>word_ids<span class="token punctuation">(</span>batch_index<span class="token operator">=</span>i<span class="token punctuation">)</span>  <span class="token comment"># 获取每个token对应的原始字符位置</span>
        char_labels <span class="token operator">=</span> batch_char_labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span>  <span class="token comment"># 该句子的字符级标签</span>
        token_labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 用于存储token级标签</span>
        
        previous_word_idx <span class="token operator">=</span> <span class="token boolean">None</span>
        <span class="token keyword">for</span> word_idx <span class="token keyword">in</span> word_ids<span class="token punctuation">:</span>
            <span class="token comment"># 处理特殊token: [CLS], [SEP], [PAD]等，标签设为-100（PyTorch忽略的索引）</span>
            <span class="token keyword">if</span> word_idx <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                token_labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token comment"># 直接使用对应字符位置的标签</span>
                label <span class="token operator">=</span> char_labels<span class="token punctuation">[</span>word_idx<span class="token punctuation">]</span>
                token_labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span>label2id<span class="token punctuation">[</span>label<span class="token punctuation">]</span><span class="token punctuation">)</span>
            
            previous_word_idx <span class="token operator">=</span> word_idx
        
        aligned_labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span>token_labels<span class="token punctuation">)</span>
    
    <span class="token comment"># 将标签转换为tensor</span>
    batch_inputs<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>aligned_labels<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>
    
    <span class="token comment"># 移除offsets_mapping，因为训练时不需要</span>
    <span class="token keyword">if</span> <span class="token string">'offset_mapping'</span> <span class="token keyword">in</span> batch_inputs<span class="token punctuation">:</span>
        batch_inputs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">'offset_mapping'</span><span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> batch_inputs
</code></pre></div><h2 id="如果你想要在dataset中预先生成char-labels"><a href="#如果你想要在dataset中预先生成char-labels" class="header-anchor">#</a> 如果你想要在Dataset中预先生成char_labels</h2> <p>这样可以提高训练时的效率：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">NERDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_file<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>data <span class="token operator">=</span> self<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span>data_file<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">load_data</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_file<span class="token punctuation">)</span><span class="token punctuation">:</span>
        Data <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>data_file<span class="token punctuation">,</span> <span class="token string">'rt'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            df <span class="token operator">=</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\n\n'</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> idx<span class="token punctuation">,</span> line <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> <span class="token keyword">not</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    <span class="token keyword">continue</span>
                    
                sentence<span class="token punctuation">,</span> labels <span class="token operator">=</span> <span class="token string">''</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
                items <span class="token operator">=</span> <span class="token punctuation">[</span>item <span class="token keyword">for</span> item <span class="token keyword">in</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span> <span class="token keyword">if</span> item<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
                
                <span class="token comment"># 首先构建句子和实体标注</span>
                <span class="token keyword">for</span> i<span class="token punctuation">,</span> item <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>items<span class="token punctuation">)</span><span class="token punctuation">:</span>
                    char<span class="token punctuation">,</span> tag <span class="token operator">=</span> item<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
                    sentence <span class="token operator">+=</span> char
                    <span class="token keyword">if</span> tag<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'B'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                        labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>i<span class="token punctuation">,</span> i<span class="token punctuation">,</span> char<span class="token punctuation">,</span> tag<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
                    <span class="token keyword">elif</span> tag<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'I'</span><span class="token punctuation">)</span> <span class="token keyword">and</span> labels<span class="token punctuation">:</span>
                        labels<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> i
                        labels<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">+=</span> char
                
                <span class="token comment"># 生成字符级标签序列</span>
                char_labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'O'</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
                <span class="token keyword">for</span> start<span class="token punctuation">,</span> end<span class="token punctuation">,</span> text<span class="token punctuation">,</span> label_type <span class="token keyword">in</span> labels<span class="token punctuation">:</span>
                    <span class="token keyword">for</span> pos <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>start<span class="token punctuation">,</span> end <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                        <span class="token keyword">if</span> pos <span class="token operator">==</span> start<span class="token punctuation">:</span>
                            char_labels<span class="token punctuation">[</span>pos<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f'B-</span><span class="token interpolation"><span class="token punctuation">{</span>label_type<span class="token punctuation">}</span></span><span class="token string">'</span></span>
                        <span class="token keyword">else</span><span class="token punctuation">:</span>
                            char_labels<span class="token punctuation">[</span>pos<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f'I-</span><span class="token interpolation"><span class="token punctuation">{</span>label_type<span class="token punctuation">}</span></span><span class="token string">'</span></span>
                
                Data<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
                    <span class="token string">'sentence'</span><span class="token punctuation">:</span> sentence<span class="token punctuation">,</span>
                    <span class="token string">'labels'</span><span class="token punctuation">:</span> labels<span class="token punctuation">,</span>
                    <span class="token string">'char_labels'</span><span class="token punctuation">:</span> char_labels  <span class="token comment"># 预先生成的字符级标签</span>
                <span class="token punctuation">}</span>
        
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'数据集中包含的实体类型有：</span><span class="token interpolation"><span class="token punctuation">{</span>categories<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> Data
    
    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>

<span class="token comment"># 简化版的collote_fn</span>
<span class="token keyword">def</span> <span class="token function">collote_fn</span><span class="token punctuation">(</span>batch_samples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    batch_sentence <span class="token operator">=</span> <span class="token punctuation">[</span>sample<span class="token punctuation">[</span><span class="token string">'sentence'</span><span class="token punctuation">]</span> <span class="token keyword">for</span> sample <span class="token keyword">in</span> batch_samples<span class="token punctuation">]</span>
    batch_char_labels <span class="token operator">=</span> <span class="token punctuation">[</span>sample<span class="token punctuation">[</span><span class="token string">'char_labels'</span><span class="token punctuation">]</span> <span class="token keyword">for</span> sample <span class="token keyword">in</span> batch_samples<span class="token punctuation">]</span>
    
    batch_inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>
        batch_sentence<span class="token punctuation">,</span>
        padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        max_length<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span>
        return_tensors<span class="token operator">=</span><span class="token string">&quot;pt&quot;</span><span class="token punctuation">,</span>
        is_split_into_words<span class="token operator">=</span><span class="token boolean">True</span>
    <span class="token punctuation">)</span>
    
    aligned_labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> char_labels <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>batch_char_labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        word_ids <span class="token operator">=</span> batch_inputs<span class="token punctuation">.</span>word_ids<span class="token punctuation">(</span>batch_index<span class="token operator">=</span>i<span class="token punctuation">)</span>
        token_labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        
        <span class="token keyword">for</span> word_idx <span class="token keyword">in</span> word_ids<span class="token punctuation">:</span>
            <span class="token keyword">if</span> word_idx <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                token_labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                token_labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span>label2id<span class="token punctuation">[</span>char_labels<span class="token punctuation">[</span>word_idx<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        
        aligned_labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span>token_labels<span class="token punctuation">)</span>
    
    batch_inputs<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>aligned_labels<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> batch_inputs
</code></pre></div><h2 id="关键点说明"><a href="#关键点说明" class="header-anchor">#</a> 关键点说明</h2> <ol><li><strong>标签对齐</strong>：使用 <code>word_ids()</code> 方法获取每个token对应的原始字符位置</li> <li><strong>特殊token处理</strong>：<code>[CLS]</code>, <code>[SEP]</code>, <code>[PAD]</code> 的标签设为 <code>-100</code>，训练时会被忽略</li> <li><strong>你的label2id映射</strong>：完全正确，包含了所有10个实体类型的BIO标签</li> <li><strong>字符级到token级映射</strong>：由于中文BERT通常是字符级分词，所以大多数情况下是1:1映射</li></ol> <p>这样实现后，你的模型就能正确学习到中医文本中的实体识别任务了！</p> <hr> <p>您观察得很仔细！这是一个非常典型的 <strong>Python 解包（Unpacking）</strong> 用法，完全合法且很常用。让我详细解释：</p> <hr> <h2 id="📦-解包机制解析"><a href="#📦-解包机制解析" class="header-anchor">#</a> <strong>📦 解包机制解析</strong></h2> <h3 id="数据源结构"><a href="#数据源结构" class="header-anchor">#</a> <strong>数据源结构</strong></h3> <div class="language-python extra-class"><pre class="language-python"><code>labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token string">'口苦'</span><span class="token punctuation">,</span> <span class="token string">'临床表现'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token comment"># 每个子列表有4个元素：</span>
<span class="token comment"># 索引0: 3 → start (起始位置)</span>
<span class="token comment"># 索引1: 4 → end (结束位置)  </span>
<span class="token comment"># 索引2: '口苦' → 实体文本</span>
<span class="token comment"># 索引3: '临床表现' → 标签类型</span>
</code></pre></div><h3 id="循环中的解包过程"><a href="#循环中的解包过程" class="header-anchor">#</a> <strong>循环中的解包过程</strong></h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">for</span> start<span class="token punctuation">,</span> end<span class="token punctuation">,</span> _<span class="token punctuation">,</span> label_type <span class="token keyword">in</span> labels<span class="token punctuation">:</span>
    <span class="token comment"># 等价于：</span>
    <span class="token comment"># temp = [3, 4, '口苦', '临床表现']  # 取出第一个子列表</span>
    <span class="token comment"># start = temp[0]   # 3</span>
    <span class="token comment"># end = temp[1]     # 4  </span>
    <span class="token comment"># _ = temp[2]       # '口苦' (用_表示忽略这个变量)</span>
    <span class="token comment"># label_type = temp[3]  # '临床表现'</span>
</code></pre></div><hr> <h2 id="🎯-参数对应关系"><a href="#🎯-参数对应关系" class="header-anchor">#</a> <strong>🎯 参数对应关系</strong></h2> <table><thead><tr><th>循环变量</th> <th>对应数据</th> <th>作用</th> <th>是否必需</th></tr></thead> <tbody><tr><td><code>start</code></td> <td><code>3</code></td> <td>实体起始位置</td> <td>✅ 必需</td></tr> <tr><td><code>end</code></td> <td><code>4</code></td> <td>实体结束位置</td> <td>✅ 必需</td></tr> <tr><td><code>_</code></td> <td><code>'口苦'</code></td> <td><strong>实体文本</strong></td> <td>❌ 用<code>_</code>忽略</td></tr> <tr><td><code>label_type</code></td> <td><code>'临床表现'</code></td> <td>实体类型</td> <td>✅ 必需</td></tr></tbody></table> <hr> <h2 id="🔍-代码执行过程"><a href="#🔍-代码执行过程" class="header-anchor">#</a> <strong>🔍 代码执行过程</strong></h2> <h3 id="步骤分解"><a href="#步骤分解" class="header-anchor">#</a> <strong>步骤分解</strong></h3> <div class="language-python extra-class"><pre class="language-python"><code>sentence <span class="token operator">=</span> <span class="token string">'现头昏口苦'</span>  <span class="token comment"># 长度5，索引: 0:现, 1:头, 2:昏, 3:口, 4:苦</span>

<span class="token comment"># 初始化: ['O', 'O', 'O', 'O', 'O']</span>
char_labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'O'</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>  

<span class="token comment"># 循环开始:</span>
start<span class="token punctuation">,</span> end<span class="token punctuation">,</span> _<span class="token punctuation">,</span> label_type <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token string">'口苦'</span><span class="token punctuation">,</span> <span class="token string">'临床表现'</span>

<span class="token keyword">for</span> pos <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># range(3, 4+1) → [3, 4]</span>
    <span class="token keyword">if</span> pos <span class="token operator">==</span> <span class="token number">3</span><span class="token punctuation">:</span>  <span class="token comment"># 第一个位置 → '口'</span>
        char_labels<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'B-临床表现'</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>         <span class="token comment"># pos == 4 → '苦'  </span>
        char_labels<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'I-临床表现'</span>
</code></pre></div><h3 id="最终结果"><a href="#最终结果" class="header-anchor">#</a> <strong>最终结果</strong></h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">print</span><span class="token punctuation">(</span>char_labels<span class="token punctuation">)</span>  
<span class="token comment"># ['O', 'O', 'O', 'B-临床表现', 'I-临床表现']</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
<span class="token comment">#  现    头    昏    口        苦</span>
</code></pre></div><hr> <h2 id="💡-为什么用"><a href="#💡-为什么用" class="header-anchor">#</a> <strong>💡 为什么用 <code>_</code> ？</strong></h2> <p><code>_</code> 是 Python 约定俗成的 <strong>&quot;忽略变量&quot;</strong>：</p> <ul><li>这个位置的数据 (<code>'口苦'</code>) 在后续代码中<strong>不会使用</strong></li> <li>用 <code>_</code> 明确告诉阅读者：&quot;我知道这里有数据，但故意不用&quot;</li> <li>避免创建无用的变量名污染命名空间</li></ul> <h3 id="如果不用"><a href="#如果不用" class="header-anchor">#</a> <strong>如果不用 <code>_</code>：</strong></h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 方式1：全部接收（浪费一个变量名）</span>
<span class="token keyword">for</span> start<span class="token punctuation">,</span> end<span class="token punctuation">,</span> entity_text<span class="token punctuation">,</span> label_type <span class="token keyword">in</span> labels<span class="token punctuation">:</span>
    <span class="token comment"># entity_text 根本用不到，但还占着变量名</span>

<span class="token comment"># 方式2：用_明确忽略（推荐）</span>
<span class="token keyword">for</span> start<span class="token punctuation">,</span> end<span class="token punctuation">,</span> _<span class="token punctuation">,</span> label_type <span class="token keyword">in</span> labels<span class="token punctuation">:</span>
    <span class="token comment"># 清晰表达意图</span>

<span class="token comment"># 方式3：索引访问（不优雅）</span>
<span class="token keyword">for</span> item <span class="token keyword">in</span> labels<span class="token punctuation">:</span>
    start<span class="token punctuation">,</span> end <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> item<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    label_type <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>
</code></pre></div><hr> <h2 id="🚀-这种用法的优势"><a href="#🚀-这种用法的优势" class="header-anchor">#</a> <strong>🚀 这种用法的优势</strong></h2> <ol><li><strong>代码简洁</strong>：一行完成多个变量赋值</li> <li><strong>意图清晰</strong>：直接看出数据结构</li> <li><strong>类型安全</strong>：如果数据格式不对会立即报错</li> <li><strong>Pythonic</strong>：符合 Python 的优雅风格</li></ol> <hr> <h2 id="📚-类似的应用场景"><a href="#📚-类似的应用场景" class="header-anchor">#</a> <strong>📚 类似的应用场景</strong></h2> <h3 id="遍历字典的键值对"><a href="#遍历字典的键值对" class="header-anchor">#</a> <strong>遍历字典的键值对</strong></h3> <div class="language-python extra-class"><pre class="language-python"><code>person <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'name'</span><span class="token punctuation">:</span> <span class="token string">'张三'</span><span class="token punctuation">,</span> <span class="token string">'age'</span><span class="token punctuation">:</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token string">'city'</span><span class="token punctuation">:</span> <span class="token string">'北京'</span><span class="token punctuation">}</span>

<span class="token keyword">for</span> key<span class="token punctuation">,</span> value <span class="token keyword">in</span> person<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;</span><span class="token interpolation"><span class="token punctuation">{</span>key<span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span>value<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
</code></pre></div><h3 id="函数返回多值"><a href="#函数返回多值" class="header-anchor">#</a> <strong>函数返回多值</strong></h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">get_coordinates</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">300</span>  <span class="token comment"># 返回元组</span>

x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> z <span class="token operator">=</span> get_coordinates<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 直接解包</span>
</code></pre></div><h3 id="嵌套解包"><a href="#嵌套解包" class="header-anchor">#</a> <strong>嵌套解包</strong></h3> <div class="language-python extra-class"><pre class="language-python"><code>data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'张三'</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">25</span><span class="token punctuation">,</span> <span class="token string">'工程师'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'李四'</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">,</span> <span class="token string">'医生'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

<span class="token keyword">for</span> name<span class="token punctuation">,</span> <span class="token punctuation">(</span>age<span class="token punctuation">,</span> job<span class="token punctuation">)</span> <span class="token keyword">in</span> data<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;</span><span class="token interpolation"><span class="token punctuation">{</span>name<span class="token punctuation">}</span></span><span class="token string">今年</span><span class="token interpolation"><span class="token punctuation">{</span>age<span class="token punctuation">}</span></span><span class="token string">岁，职业是</span><span class="token interpolation"><span class="token punctuation">{</span>job<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
</code></pre></div><p><strong>总结</strong>：您看到的代码是标准的 Python 解包语法，<code>start, end, _, label_type</code> 分别对应列表中的四个元素，用 <code>_</code> 忽略不需要的实体文本数据。这是处理序列标注任务时的常见模式！</p></div></section> <footer class="page-edit"><!----> <!----></footer> <!----> <div class="comments-wrapper"><!----></div></main></div> <!----></div> <ul class="sub-sidebar sub-sidebar-wrapper" style="width:12rem;" data-v-7115df4a data-v-1c636796><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#_1-llamaindex-最流行的替代品" class="sidebar-link reco-side-_1-llamaindex-最流行的替代品" data-v-7115df4a>1. LlamaIndex（最流行的替代品）</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#_2-haystack-企业级选择" class="sidebar-link reco-side-_2-haystack-企业级选择" data-v-7115df4a>2. Haystack（企业级选择）</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#_3-semantic-kernel-微软出品" class="sidebar-link reco-side-_3-semantic-kernel-微软出品" data-v-7115df4a>3. Semantic Kernel（微软出品）</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#_4-autogpt-agentgpt-自主代理" class="sidebar-link reco-side-_4-autogpt-agentgpt-自主代理" data-v-7115df4a>4. AutoGPT / AgentGPT（自主代理）</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#_5-transformers-agents-hugging-face" class="sidebar-link reco-side-_5-transformers-agents-hugging-face" data-v-7115df4a>5. Transformers Agents（Hugging Face）</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#_6-langchain-lite-替代方案" class="sidebar-link reco-side-_6-langchain-lite-替代方案" data-v-7115df4a>6. LangChain Lite 替代方案</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#minichain-极简替代" class="sidebar-link reco-side-minichain-极简替代" data-v-7115df4a>MiniChain（极简替代）</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#chainlit-专注于ui" class="sidebar-link reco-side-chainlit-专注于ui" data-v-7115df4a>Chainlit（专注于UI）</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#_7-专业领域替代方案" class="sidebar-link reco-side-_7-专业领域替代方案" data-v-7115df4a>7. 专业领域替代方案</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#对于数据分析-pandas-ai" class="sidebar-link reco-side-对于数据分析-pandas-ai" data-v-7115df4a>对于数据分析：Pandas AI</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#对于对话ai-rasa-botpress" class="sidebar-link reco-side-对于对话ai-rasa-botpress" data-v-7115df4a>对于对话AI：Rasa / Botpress</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#对于搜索引擎-weaviate-chroma" class="sidebar-link reco-side-对于搜索引擎-weaviate-chroma" data-v-7115df4a>对于搜索引擎：Weaviate / Chroma</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#详细对比表格" class="sidebar-link reco-side-详细对比表格" data-v-7115df4a>详细对比表格</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#选择建议" class="sidebar-link reco-side-选择建议" data-v-7115df4a>选择建议</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#根据需求选择" class="sidebar-link reco-side-根据需求选择" data-v-7115df4a>根据需求选择：</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#简单项目推荐直接使用sdk" class="sidebar-link reco-side-简单项目推荐直接使用sdk" data-v-7115df4a>简单项目推荐直接使用SDK：</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#迁移示例" class="sidebar-link reco-side-迁移示例" data-v-7115df4a>迁移示例</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#从-langchain-迁移到-llamaindex" class="sidebar-link reco-side-从-langchain-迁移到-llamaindex" data-v-7115df4a>从 LangChain 迁移到 LlamaIndex：</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#从-langchain-迁移到-haystack" class="sidebar-link reco-side-从-langchain-迁移到-haystack" data-v-7115df4a>从 LangChain 迁移到 Haystack：</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#总结" class="sidebar-link reco-side-总结" data-v-7115df4a>总结</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#💡-如何选择适合的模型" class="sidebar-link reco-side-💡-如何选择适合的模型" data-v-7115df4a>💡 如何选择适合的模型？</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#一、核心思想-从-硬提示-到-软提示" class="sidebar-link reco-side-一、核心思想-从-硬提示-到-软提示" data-v-7115df4a>一、核心思想：从“硬提示”到“软提示”</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#二、prompt-tuning-的主要优势" class="sidebar-link reco-side-二、prompt-tuning-的主要优势" data-v-7115df4a>二、Prompt-tuning 的主要优势</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#三、prompt-tuning-的家族成员" class="sidebar-link reco-side-三、prompt-tuning-的家族成员" data-v-7115df4a>三、Prompt-tuning 的家族成员</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#四、一个简单的类比" class="sidebar-link reco-side-四、一个简单的类比" data-v-7115df4a>四、一个简单的类比</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#总结-2" class="sidebar-link reco-side-总结-2" data-v-7115df4a>总结</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#一、核心思想-在每一层之前添加可学习的-前缀" class="sidebar-link reco-side-一、核心思想-在每一层之前添加可学习的-前缀" data-v-7115df4a>一、核心思想：在每一层之前添加可学习的“前缀”</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#二、技术细节-它是如何工作的" class="sidebar-link reco-side-二、技术细节-它是如何工作的" data-v-7115df4a>二、技术细节：它是如何工作的？</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#三、prefix-tuning-的主要优势" class="sidebar-link reco-side-三、prefix-tuning-的主要优势" data-v-7115df4a>三、Prefix-Tuning 的主要优势</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#四、与相关技术的对比" class="sidebar-link reco-side-四、与相关技术的对比" data-v-7115df4a>四、与相关技术的对比</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#总结-3" class="sidebar-link reco-side-总结-3" data-v-7115df4a>总结</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#运行方式" class="sidebar-link reco-side-运行方式" data-v-7115df4a>运行方式</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#_1-直接运行-推荐网络条件好的情况" class="sidebar-link reco-side-_1-直接运行-推荐网络条件好的情况" data-v-7115df4a>1. 直接运行（推荐网络条件好的情况）</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#_2-模型和数据集下载问题" class="sidebar-link reco-side-_2-模型和数据集下载问题" data-v-7115df4a>2. 模型和数据集下载问题</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#本地下载方案" class="sidebar-link reco-side-本地下载方案" data-v-7115df4a>本地下载方案</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#下载模型到本地" class="sidebar-link reco-side-下载模型到本地" data-v-7115df4a>下载模型到本地</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#修改脚本使用本地路径" class="sidebar-link reco-side-修改脚本使用本地路径" data-v-7115df4a>修改脚本使用本地路径</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#注意事项" class="sidebar-link reco-side-注意事项" data-v-7115df4a>注意事项</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#替代方案-如果下载困难" class="sidebar-link reco-side-替代方案-如果下载困难" data-v-7115df4a>替代方案（如果下载困难）</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#langchain-练习" class="sidebar-link reco-side-langchain-练习" data-v-7115df4a>langchain 练习</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#_1-完整的-langchain-prompt-实现" class="sidebar-link reco-side-_1-完整的-langchain-prompt-实现" data-v-7115df4a>1. 完整的 Langchain Prompt 实现</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#_2-使用方式" class="sidebar-link reco-side-_2-使用方式" data-v-7115df4a>2. 使用方式</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#_3-更简洁的版本-使用字符串模板" class="sidebar-link reco-side-_3-更简洁的版本-使用字符串模板" data-v-7115df4a>3. 更简洁的版本（使用字符串模板）</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#_4-使用-lcel-链式调用-推荐" class="sidebar-link reco-side-_4-使用-lcel-链式调用-推荐" data-v-7115df4a>4. 使用 LCEL 链式调用（推荐）</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#主要变化说明" class="sidebar-link reco-side-主要变化说明" data-v-7115df4a>主要变化说明：</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#问题分析" class="sidebar-link reco-side-问题分析" data-v-7115df4a>问题分析</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#验证方法" class="sidebar-link reco-side-验证方法" data-v-7115df4a>验证方法</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#解决方案" class="sidebar-link reco-side-解决方案" data-v-7115df4a>解决方案</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#方法1-直接使用-json-处理" class="sidebar-link reco-side-方法1-直接使用-json-处理" data-v-7115df4a>方法1：直接使用 JSON 处理</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#方法2-增强提示词约束" class="sidebar-link reco-side-方法2-增强提示词约束" data-v-7115df4a>方法2：增强提示词约束</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#方法3-使用-langchain-的-json-解析器" class="sidebar-link reco-side-方法3-使用-langchain-的-json-解析器" data-v-7115df4a>方法3：使用 Langchain 的 JSON 解析器</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#验证代码正确性" class="sidebar-link reco-side-验证代码正确性" data-v-7115df4a>验证代码正确性</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#_10-03" class="sidebar-link reco-side-_10-03" data-v-7115df4a>10.03</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#完整的-collote-fn-函数" class="sidebar-link reco-side-完整的-collote-fn-函数" data-v-7115df4a>完整的 collote_fn 函数</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#如果你想要在dataset中预先生成char-labels" class="sidebar-link reco-side-如果你想要在dataset中预先生成char-labels" data-v-7115df4a>如果你想要在Dataset中预先生成char_labels</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#关键点说明" class="sidebar-link reco-side-关键点说明" data-v-7115df4a>关键点说明</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#📦-解包机制解析" class="sidebar-link reco-side-📦-解包机制解析" data-v-7115df4a>📦 解包机制解析</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#数据源结构" class="sidebar-link reco-side-数据源结构" data-v-7115df4a>数据源结构</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#循环中的解包过程" class="sidebar-link reco-side-循环中的解包过程" data-v-7115df4a>循环中的解包过程</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#🎯-参数对应关系" class="sidebar-link reco-side-🎯-参数对应关系" data-v-7115df4a>🎯 参数对应关系</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#🔍-代码执行过程" class="sidebar-link reco-side-🔍-代码执行过程" data-v-7115df4a>🔍 代码执行过程</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#步骤分解" class="sidebar-link reco-side-步骤分解" data-v-7115df4a>步骤分解</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#最终结果" class="sidebar-link reco-side-最终结果" data-v-7115df4a>最终结果</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#💡-为什么用" class="sidebar-link reco-side-💡-为什么用" data-v-7115df4a>💡 为什么用 `_` ？</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#如果不用" class="sidebar-link reco-side-如果不用" data-v-7115df4a>如果不用 `_`：</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#🚀-这种用法的优势" class="sidebar-link reco-side-🚀-这种用法的优势" data-v-7115df4a>🚀 这种用法的优势</a></li><li class="level-2" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#📚-类似的应用场景" class="sidebar-link reco-side-📚-类似的应用场景" data-v-7115df4a>📚 类似的应用场景</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#遍历字典的键值对" class="sidebar-link reco-side-遍历字典的键值对" data-v-7115df4a>遍历字典的键值对</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#函数返回多值" class="sidebar-link reco-side-函数返回多值" data-v-7115df4a>函数返回多值</a></li><li class="level-3" data-v-7115df4a><a href="/hmblog/modelstudy/temp.html#嵌套解包" class="sidebar-link reco-side-嵌套解包" data-v-7115df4a>嵌套解包</a></li></ul></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-65133105 data-v-65133105><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-65133105><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-65133105></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-65133105></path></svg></div><!----></div></div>
    <script src="/hmblog/assets/js/app.ba48173d.js" defer></script><script src="/hmblog/assets/js/3.ac02bfbd.js" defer></script><script src="/hmblog/assets/js/1.ba4d6411.js" defer></script><script src="/hmblog/assets/js/70.bed5cdee.js" defer></script><script src="/hmblog/assets/js/9.d5a05a45.js" defer></script>
  </body>
</html>
